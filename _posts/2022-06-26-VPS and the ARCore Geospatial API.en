[MUSIC PLAYING]


BILAWAL SIDHU: Welcometo our Tech Talk.
I'm Bilawal Sidhu,a product manager,
and I'm joined today by SimonLynen, a software engineer.
And we're from theGoogle Maps team.
Today, we're reallyexcited to introduce you
all to the ARCoreGeospatial API, which
will allow you to buildglobal scale, immersive,
location-based AR experienceson Android and iOS.
We've been mapping the worldin immaculate detail and scale
over the past 15 years usingsatellites, aerial, and ground
level imagery to build anunprecedented understanding
of the dynamic physical world.
In totality, we've coveredmore than 10 million miles
of Street View, a distancethat can circle the globe
more than 400 times.
We've also covered morethan 36 million square miles
of HD satellite imagery,covering more than 98%
of the entire population.
From this massive corpusof billions of images,
we have fused them togetherinto a 3D world model
that geometrically andsemantically understands
the world.
And it is the underpinningfoundation for our first party
applications likeGoogle Maps and Earth.
This 3D world model is optimizedfor visualization, analysis,
and localization-- inother, words maps for humans
and machines alike.
Today, we are here to talk toyou about the machine readable
3D model and, in particular,the smartphone camera
in your pocket andhow we're enriching it
with Google's understandingof the world to allow you,
the developercommunity, to create
immersive, world-scaleAR experiences.
We're excited to partnerwith the Google AR teams
to bring this 3D understandingof the world to you
through Google's ARdeveloper platform, ARCore,
which allows Android andiOS developers to build
immersive ARexperiences for mobile.
This technology is calledGlobal Localization
and has been stresstested in production,
powering the AR Live Viewmode inside of Google Maps
and the AR PlacesFilter in Google Lens.
And today, we're excitedto open up the same core
capability to you, ourdeveloper community,
to create immersive locationbased AR experiences
in your own applications.
This capability is availablein over 93 countries
across the globe everywherewe have Street View.
With that background in mind,let's get right into it.
We'll start off by discussingdifferent options for building
location-based AR experiences.
Then, we'll provide backgroundon the technical capabilities
on our roadmap aswell as walk you
through the fundamentalsof using this API
and just how easy itis to get started.
And finally, we'll share whatour early partners are already
doing with the Geospatial APIto address a range of verticals
and use cases.
Let's take a step back.
If you want to buildlocation-based AR experiences
today, you have acouple of options.
Use built-in sensors like theGPS and compass on your phone.
Use spatial anchors like theARCore Cloud Anchors API.
And finally, use theGeospatial API, which
is the subject of today's talk.
Let's understand thebenefits and trade offs
of using these various options.
You've got GPS, whichis a global scale
system, great for buildinglocation-based experiences.
But if you've ever dealt withyour blue jumping around,
especially in anurban canyon, you
know that the accuracy'sa far cry from what
you need to build ARexperiences that reliably
augment the camera view.
Even after you do that crazyeight pattern for calibrating
your compass, withLocation Services,
you'll typically get 5 to 10meters of positional accuracy
and 30 to 45 degreesof rotational accuracy.
This means that yourcamera may not even
be looking in theright direction,
or your AR elements arecompletely out of frame.
You also have the ability to usespatial anchoring capabilities
like ARCore Cloud Anchors.
In this case, youneed to explicitly map
a space or place of interestto attach content to it
and then can reliablylocalize against it.
Cloud Anchors works reallywell at near-field distances,
for private spaces, or smallerevent-scale experiences where
you can physically showup and map the space
before attaching AR content.
But with larger scaledeployments of Cloud Anchors,
discovering content is achallenge and so is placement.
We've heard from you,the developer community,
that you want to guideusers to the right location,
to be able to remotely placecontent without physically
going to thoselocations, both of which
are hard to do withCloud Anchors today.
Enter visual positioningsystem and global localization.
Thanks to Google's decadeplus of ground level imagery,
we've already mapped theworld in immaculate detail.
By working in conjunctionwith Location Services,
we can take a goodGPS estimate and make
it great, ready for AR.
So with the ARCoreGeospatial API,
you are able to remotely attachcontent to the world and guide
users to it, allowingyou to create
immersive, location-based ARexperiences almost everywhere
we have Street View.
Let's summarize the differences.
With GPS, you get globalscale with lower accuracy
and variable reliability.
With the Cloud AnchorsAPI, you get high accuracy
within a limited scalebecause you explicitly
need to map a space.
And with the Geospatial API,you get the best of both worlds,
remotely placing contentin the world and offering
nearly ubiquitous,accurate localization
and heading without needingto manually map the space.
We hope to surface additionalcapabilities over time
to help you build trulynext gen experiences.
I will now hand it over toSimon to unpack the underlying
technologies poweringthe Geospatial
API and thecapabilities it gives
you to turn the worldinto your canvas.
SIMON LYNEN: Thanks, Bilawal.
In the followingminutes, I'll walk you
through the three pillarsof the Geospatial API.
Geo localization, geometryand anchoring, as well as
world understanding.
Localization is the foundationof the Geospatial API.
It is key to bring your ARexperiences to the global scale
by allowing you to placevirtual content in relation
to the globe.
To provide thiscapability, the device
makes a server call to thevisual positioning service,
VPS, where your geographiccoordinates and images
are used to match againsthigh-resolution 3D data
from Google Maps.
This process is calledVisual Localization.
And it preciselylocates your device
with respect to the environmentmuch more accurately
than what was previouslypossible with GPS alone.
I want to take a moment to runthrough how all this works.
Street View images-- which havebeen captured around the globe
for more than 15 years--
are the foundation of VPS.
Deep neural networksidentify and describe
those parts of theimages that are
likely to be recognizableover long periods of time.
You can see that thealgorithm has learned to focus
on buildings instead of cars.
We then combine these salientpoints across tens of billions
of images to compute a 3Dpoint cloud of the environment.
This localization modelconsists of trillions
of points and spansnearly all countries,
with future coverage.
When your device makes arequest to the Geospatial API,
a similar process isapplied to the image.
A neural networkprocesses the pixels
to find recognizableparts of the environment
and matches them tothe localization model.
Computer visionalgorithms then compute
the position and orientationof the device that
is sent back to you.
This process makes use of TPUs--
Google's machinelearning accelerators--
and it takes less than a second.
Using the response fromVPS, the Geospatial API
takes care of mergingyour local coordinates
with the geographiccoordinates so you can work
in a single coordinate system.
As Bilawal mentionedearlier, this launch
offers a very rare combination.
The Geospatial API builds onthe visual positioning service,
which is in a verymature state, and we
make the API available fornearly all areas covered
by Google Street View,which is very widely scaled.
One key challenge whenbuilding AR experiences
is the accurate placementof content in relation
to real world geometry.
The API we launch todayallows for anchor placement
at a given latitude,longitude, and altitude.
We expect to launch terrainanchors later this year,
which will allow youto create anchors
by providing onlylatitude and longitude
information, while otherinformation from Google Maps
is leveraged to preciselyplace the content
at the right altitudeabove ground.
The image on theright shows an example
where the precisealtitude information
is key to a delightfuluser experience.
In the following, Iwould like to give you
a behind-the-sceneslook as a technology
that the team iscurrently working on.
These capabilities arenot launching today,
but we are exploringways to make
them available fordevelopers in the future.
Their experience hasbecome truly magical
when they seamlessly integratewith the real world--
for instance, through occlusionsand physics into action.
We believe thatone key enabler is
given by abstract buildinggeometry, as shown
in the image on the right.
Another angle we are exploringis to bring already familiar AR
concepts to a global scale.
For example, ARCoreprovides the ability
to anchor elementsto physical locations
and snap them to plane geometrydetected by the device.
For the GeospatialAPI, we are thinking
about a similar concept whichwe call Geometric Anchors.
It consists of two parts.
The first part is tocapture and persist
intent, such as keepinganchors that were attached
to a wall sticking to the wall.
The second part isabout maintaining
anchor poses so that even if ourmodels are refined over time,
anchors remain atthe location that you
intended them to be at.
Lastly, we will hopeto gradually expose
more of our underlying3D semantic model, which
will allow you to buildeven richer experiences.
In particular, in combinationwith existing Geospatial
offerings, such asGoogle Maps platforms,
adding semantic understandingto the Geospatial API
will allow you to procedurallyplace content at places
in the world, such as aspecific fountain in a park
or your favorite coffee store.
We are lookinginto making pieces
of the semantic3D model available
in the coming quarters.
After this explorationin the future,
let's take a quickmoment to look
at what we are launching today.
This code exampleshows you how easy
it is to bring your ARexperiences to a global scale.
To obtain Geospatialdata, you need
to enable the Geospatial APIby changing the Geospatial
mode in your sessionconfiguration to Enabled.
To determine an anchor locationfor remote anchor creation,
you can for instance samplepoints from Google Earth
or Google Maps.
You can then startcreating anchors
in the global frameusing these coordinates.
Another exampleI want to show is
how you obtain a Geospatialpose in your app.
A Geospatial pose consistsof latitude, longitude,
and altitude information, aswell as device orientation.
All these quantitiesare provided
with estimated uncertainties.
So you can adjust yourexperience accordingly.
You see that only a fewlines of additional code
are needed to build globalscale AR experiences
with the new Geospatial API.
And with that, I'mheading back to Bilawal
to walk you throughsome use cases.
BILAWAL SIDHU: Thanks, Simon.
We've seen developer interestfor a range of use cases
and verticals.
Today, we'll focus onthree sets of applications.
The first vertical isridesharing and micromobility.
Both demand highaccuracy location
for a range of use caseswhere GPS just doesn't cut it.
Thanks to our new API, partnersare removing the friction
from parking docklesse-scooters and e-bikes,
adding pinpointaccuracy so that riders
know exactly when their vehicleis in a valid parking spot.
The result is greaterpeace of mind for riders
and more properly parkedscooters on city streets,
leading to better relationshipswith the communities
that our partners serve.
Conversely, vehiclediscovery gets easier,
especially in dense urbancorridors with the increased
location accuracy,which our partners are
using to help customersfind vehicles,
thus improving theiruser experience
and increasingvehicle rental rates.
The next vertical islocation-based AR experiences.
Thanks to our API,developers can
focus on creating compellinguser experiences that
provide utility anddelight without needing
to build and maintain mapsof multiple locations.
Telstra and Accenture arecreating a companion app
for Marvel Stadium that bringscustomers to their seats
while showcasing engaging,immersive content
along the way.
DoCoMo and Curiosity areturning Tokyo hotspots
into an immersiveworld where you
can fend off virtual dragonswith your favorite robot
companion.
Finally, we have gamingand self-expression.
With the Geospatial API, youcan literally turn the globe
into a canvas for creativity.
In Balloon Pop, youcan place balloons
as targets in thereal world and try
to pop them using aphysics-enabled ball that
reacts to distancein world space.
Nearby users canjoin the experience
and pop the same balloons via asimple Firebase implementation.
And with Pocket Garden, youcan adorn your neighborhood
with a colorful ARcommunity garden,
accurately placing seedsacross the real world at scale,
planting vines, puffysucculents, and more.
We've also given Snapearly access to this API
to help explore entertainingand educational use cases.
All of these are great examplesof what is possible when you
turn the globe into a canvas.
And we're excited to sharethat Balloon Pop and Pocket
Garden will be open sourcedand available to you
to bootstrap yourown creativity.
We look forward to seeingwhat developers build
with the ARCore Geospatial API.
So to summarize, with theintroduction of the Geospatial
API, we're providingthe foundation
for building globalscale AR experiences.
The API is matureand production-ready,
with the underlying technologydeployed at Google scale
for more than three years andwith a range of partners using
it in their own experiences.
The Geospatial APIis available today
on all supported ARCore-enableddevices across Android and iOS.
Get started with ournew Geospatial codelab,
or check out our samplesfor Android, Unity, and iOS,
and the ARCore SDK.
We're excited tosee what you create
when the world is your canvas.
[MUSIC PLAYING]


