1
00:00:01,800 --> 00:00:03,833
Now approaching your destination.

2
00:00:31,633 --> 00:00:34,800
Hi! Welcome to NVIDIA.

3
00:01:41,533 --> 00:01:43,700
Welcome to GTC!

4
00:01:43,700 --> 00:01:46,300
I hope all of you are well.

5
00:01:46,300 --> 00:01:50,733
We have really big announcements and
cool things to show you today.

6
00:01:50,733 --> 00:01:55,300
But first, let me share the new I AM AI.

7
00:01:55,300 --> 00:02:03,800
It’s a work of love by NVIDIA’s creative team
and beautifully tells the stories of the impactful work you do.

8
00:02:30,300 --> 00:02:34,533
I am a visionary.

9
00:02:36,700 --> 00:02:42,500
Expanding our understanding of the smallest particles,

10
00:02:46,433 --> 00:02:50,833
And the infinite possibilities of the universe.

11
00:02:57,733 --> 00:03:00,533
I am a guardian.

12
00:03:01,600 --> 00:03:05,633
Protecting us on all of our journeys,

13
00:03:09,400 --> 00:03:13,133
And insuring our most precious passengers

14
00:03:15,200 --> 00:03:17,533
make it home safely.

15
00:03:20,300 --> 00:03:23,733
I am a healer.

16
00:03:23,733 --> 00:03:29,700
Searching for hidden threats in every cell,

17
00:03:35,000 --> 00:03:41,400
And delivering precise care with every breath.

18
00:03:43,133 --> 00:03:46,433
I am a helper.

19
00:03:48,333 --> 00:03:51,800
Taking on complex tasks

20
00:03:53,900 --> 00:03:57,333
in the most challenging environments

21
00:03:59,000 --> 00:04:03,133
and giving our crops room to grow.

22
00:04:06,600 --> 00:04:09,333
I am a creator.

23
00:04:09,333 --> 00:04:15,300
Transforming the very fabric of our everyday lives,

24
00:04:15,300 --> 00:04:23,000
And using the creative DNA of the masters
to inspire a new generation of art.

25
00:04:24,900 --> 00:04:28,033
I am a learner.

26
00:04:28,600 --> 00:04:38,400
Taking just minutes to discover how to
crawl, walk, and stand on my own.

27
00:04:39,500 --> 00:04:42,133
I am a storyteller.

28
00:04:43,033 --> 00:04:46,400
Giving emotion to words

29
00:04:48,700 --> 00:04:53,000
and breaking down the language barrier.

30
00:04:53,000 --> 00:04:58,100
I am even the composer of the music.

31
00:05:06,133 --> 00:05:09,100
I am AI.

32
00:05:09,100 --> 00:05:18,433
Brought to life by NVIDIA, deep-learning,
and brilliant minds everywhere.

33
00:05:25,100 --> 00:05:30,400
Doctors can now sequence the human DNA in a couple of hours.

34
00:05:30,400 --> 00:05:36,200
And predict the 3D structure of the DNA
from the amino acid sequence.

35
00:05:36,200 --> 00:05:39,633
Researchers can use computers to
generate new drug candidates.

36
00:05:39,633 --> 00:05:44,033
And inside a computer test the new
drug against a target disease.

37
00:05:44,033 --> 00:05:50,600
AI is learning biology and chemistry, just as AI has learned images, sounds, and language.

38
00:05:50,600 --> 00:05:56,300
Once in the realm of computers, fields like
drug discovery will undergo the same revolution

39
00:05:56,300 --> 00:05:59,733
we are witnessing in other areas impacted by AI.

40
00:05:59,733 --> 00:06:04,600
None of these capabilities were remotely possible a decade ago.

41
00:06:04,600 --> 00:06:15,633
Accelerated computing, at data center scale, and combined with machine learning, has sped-up computing by a Million-X.

42
00:06:15,633 --> 00:06:21,200
Accelerated computing has enabled
revolutionary AI models like the Transformer

43
00:06:21,200 --> 00:06:24,400
and made self-supervised learning possible.

44
00:06:24,400 --> 00:06:30,600
AI has fundamentally changed what software
can make and how you make software.

45
00:06:30,600 --> 00:06:38,933
Companies are processing, refining their data, making AI software, becoming intelligence manufacturers.

46
00:06:38,933 --> 00:06:43,100
Their data centers are becoming AI factories.

47
00:06:43,100 --> 00:06:49,933
The first wave of AI learned perception and inference, like recognizing images, understanding speech,

48
00:06:49,933 --> 00:06:53,433
recommending a video, or an item to buy.

49
00:06:53,433 --> 00:06:59,500
The next wave of AI is robotics – AI planning actions.

50
00:06:59,500 --> 00:07:06,633
 Digital robots, avatars, and physical robots
will perceive, plan and act.

51
00:07:06,633 --> 00:07:12,233
And just as AI frameworks like TensorFlow and PyTorch
have become integral to AI software,

52
00:07:12,233 --> 00:07:20,400
Omniverse will be essential to making robotics software. Omniverse will enable the next wave of AI.

53
00:07:20,400 --> 00:07:26,433
We will talk about the next Million-X and other
dynamics shaping our industry this GTC.

54
00:07:26,433 --> 00:07:33,100
Over the past decade, NVIDIA accelerated computing
delivered a Million-X speed-up in AI

55
00:07:33,100 --> 00:07:36,700
and started the modern AI revolution.

56
00:07:36,700 --> 00:07:40,200
Now, AI will revolutionize all industries.

57
00:07:40,200 --> 00:07:46,000
The CUDA libraries, the NVIDIA SDKs, are at the
heart of accelerated computing.

58
00:07:46,000 --> 00:07:55,900
With each new SDK, new science, new applications, and new industries can tap into the power of NVIDIA computing.

59
00:07:55,900 --> 00:08:04,333
These SDKs tackle the immense complexity at the
intersection of computing, algorithms, and science.

60
00:08:04,333 --> 00:08:10,800
The compound effect of NVIDIA's full-stack approach
resulted in a Million-X speed-up.

61
00:08:10,800 --> 00:08:17,833
Today, NVIDIA accelerates millions of developers and tens of thousands of companies and startups.

62
00:08:17,833 --> 00:08:21,100
GTC is for all of you.

63
00:08:21,100 --> 00:08:28,400
It is always inspiring to see leading computer scientists, AI researchers, roboticists, and autonomous vehicle designers

64
00:08:28,400 --> 00:08:31,000
present their work at GTC.

65
00:08:31,000 --> 00:08:38,633
We can see AI and accelerated computing's expanding reach and impact from the new attendees and talks.

66
00:08:38,633 --> 00:08:47,200
This year, we see Best Buy, Home Depot, Walmart,
Kroeger, and Lowe's working with AI.

67
00:08:47,200 --> 00:08:55,500
LinkedIn, Snap, Salesforce, DoorDash, Pinterest,
ServiceNow, American Express, and Visa

68
00:08:55,500 --> 00:08:58,100
will talk about using AI at scale.

69
00:08:58,100 --> 00:09:06,000
And you can look forward to seeing talks from healthcare companies GSK, AstraZeneca, Merck, Bristol Myers Squibb,

70
00:09:06,000 --> 00:09:10,033
Mayo Clinic, McKesson, and Eli Lilly.

71
00:09:10,033 --> 00:09:13,900
GTC 2022 is going to be terrific.

72
00:09:13,900 --> 00:09:17,133
The GPU revolutionized AI.

73
00:09:17,133 --> 00:09:23,133
Now, AI on GPUs is revolutionizing industries and science.

74
00:09:23,133 --> 00:09:27,233
One of the most impactful to humanity is climate science.

75
00:09:27,233 --> 00:09:34,000
Scientists predict that a supercomputer
a billion times larger than today's

76
00:09:34,000 --> 00:09:38,033
is needed to effectively simulate regional climate change.

77
00:09:38,033 --> 00:09:42,800
Yet, it is vital to predict now the
impact of our industrial decisions

78
00:09:42,800 --> 00:09:47,000
and the effectiveness of mitigation and adaptation strategies.

79
00:09:47,000 --> 00:09:55,633
NVIDIA is going to tackle this grand challenge with our Earth-2, the world’s first AI digital twin supercomputer,

80
00:09:55,633 --> 00:10:04,400
and invent new AI and computing technologies to
give us a Billion-X boost before it’s too late.

81
00:10:04,400 --> 00:10:07,500
There is early evidence we can succeed.

82
00:10:07,500 --> 00:10:14,133
Researchers at NVIDIA, Caltech, Berkeley lab,
Purdue, Michigan, and Rice Universities

83
00:10:14,133 --> 00:10:19,333
have developed a weather forecasting
AI model called FourCastNet.

84
00:10:19,333 --> 00:10:25,800
FourCastNet is a physics-informed deep learning model
that can predict weather events such as hurricanes,

85
00:10:25,800 --> 00:10:28,800
atmospheric rivers, and extreme rain.

86
00:10:28,800 --> 00:10:37,800
FourCastNet learned to predict weather from 40 years of simulation-enhanced ground truth data from ECMWF,

87
00:10:37,800 --> 00:10:41,400
the European Center of Medium Weather Forecasting.

88
00:10:41,400 --> 00:10:48,733
For the first time, a deep learning model has achieved better accuracy and skill on precipitation forecasting

89
00:10:48,733 --> 00:10:58,133
than state-of-the-art numerical models,
and makes predictions 4 to 5 orders of magnitude faster -

90
00:10:58,133 --> 00:11:03,100
what takes a classical numerical
simulation a year now take minutes.

91
00:11:03,100 --> 00:11:11,200
Atmospheric rivers are enormous rivers of water vapor in the sky – each carrying more water than the Amazon.

92
00:11:11,200 --> 00:11:19,033
They provide a key source of precipitation for the western U.S., but these large, powerful storms can also cause

93
00:11:19,033 --> 00:11:22,333
catastrophic flooding and massive snowfalls.

94
00:11:22,333 --> 00:11:28,300
NVIDIA has created a physics-ML model that
emulates the dynamics of global weather patterns

95
00:11:28,300 --> 00:11:35,433
and predicts extreme weather events, like atmospheric rivers, with unprecedented speed and accuracy.

96
00:11:35,433 --> 00:11:43,133
Powered by the Fourier Neural Operator, this GPU-accelerated AI-enabled digital twin, called FourCastNet,

97
00:11:43,133 --> 00:11:46,800
is trained on 10 TB of Earth system data.

98
00:11:46,800 --> 00:11:53,933
Using this data, together with NVIDIA Modulus and Omniverse, we are able to forecast the precise path

99
00:11:53,933 --> 00:11:58,400
of catastrophic atmospheric rivers a full week in advance.

100
00:11:58,400 --> 00:12:03,700
FourCastNet takes only a fraction of a
second on a single NVIDIA GPU.

101
00:12:03,700 --> 00:12:10,933
With such enormous speed, we can generate thousands of simulations, to explore all possible outcomes.

102
00:12:10,933 --> 00:12:18,033
Allowing us to quantify the risk of catastrophic flooding with greater confidence than was ever possible before.

103
00:12:18,600 --> 00:12:25,700
NVIDIA is pioneering accelerated computing,
an approach that demands full-stack expertise.

104
00:12:25,700 --> 00:12:32,200
We built NVIDIA like a computing stack,
a neural network – in four layers –

105
00:12:32,200 --> 00:12:38,900
hardware, system software, platform software, and applications.

106
00:12:38,900 --> 00:12:43,300
Each layer is open to computer makers,
service providers, and developers

107
00:12:43,300 --> 00:12:46,800
to integrate into their offering however best for them.

108
00:12:46,800 --> 00:12:50,200
I will announce new products at each of these layers today.

109
00:12:50,200 --> 00:12:51,533
Let's get started.

110
00:12:52,000 --> 00:12:55,600
The progress of AI is stunning.

111
00:12:55,600 --> 00:13:02,600
Transformers opened self-supervised learning
and unblocked the need for human-labeled data.

112
00:13:02,600 --> 00:13:06,400
We can use enormous training sets with Transformers

113
00:13:06,400 --> 00:13:10,400
and learn more robust
and more complete representations.

114
00:13:10,400 --> 00:13:17,533
Because of Transformers, model and data size grew,
and model skills and accuracy took off.

115
00:13:17,533 --> 00:13:24,500
Google BERT for language understanding, NVIDIA MegaMolBart for drug discovery, and DeepMind AlphaFold

116
00:13:24,500 --> 00:13:27,433
are all breakthroughs traced to Transformers.

117
00:13:27,433 --> 00:13:34,700
Transformers made self-supervised learning possible,
and AI jumped to warp speed.

118
00:13:34,700 --> 00:13:42,300
Natural language understanding models can learn without supervision from vast amounts of text,

119
00:13:42,300 --> 00:13:47,433
which is then refined with a small
amount of human-labeled data

120
00:13:47,433 --> 00:13:55,933
to develop good skills for translation,
Q&A, summarization, writing, and so much more.

121
00:13:55,933 --> 00:14:03,333
Multi-model learning with language supervision has
added another dimension to computer vision.

122
00:14:03,333 --> 00:14:11,533
Reinforcement learning models, like NVIDIA NVCell,
are doing chip layout – AI is building chips.

123
00:14:11,533 --> 00:14:18,633
Like FourCastNet and Orbnet, physics-ML models
are learning physics and quantum physics.

124
00:14:18,633 --> 00:14:23,033
The conditions are prime for
significant breakthroughs in science.

125
00:14:23,033 --> 00:14:28,000
Generative Models are transforming
 creative design, helping build virtual worlds,

126
00:14:28,000 --> 00:14:31,300
and soon, revolutionizing communications.

127
00:14:31,300 --> 00:14:37,800
Like Nerf, Neural Graphics networks that learn 3D representations from 2D images

128
00:14:37,800 --> 00:14:42,500
will elevate photography and help us
create digital twins of our world.

129
00:14:42,500 --> 00:14:52,700
AI is racing in every direction – new architectures,
new learning strategies, larger and more robust models,

130
00:14:52,700 --> 00:14:58,400
 new science, new applications, new industries
– all at the same time.

131
00:14:58,400 --> 00:15:00,233
Here’s an amazing example.

132
00:15:00,233 --> 00:15:06,600
This AI-powered character is animated using a
physics-based reinforcement learning model.

133
00:15:06,600 --> 00:15:07,800
Let’s take a look.

134
00:15:09,533 --> 00:15:16,600
We are using reinforcement learning to develop more life-like and responsive physically simulated characters.

135
00:15:16,600 --> 00:15:21,333
Our character learns to perform life-like motions
by imitating human motion data,

136
00:15:21,333 --> 00:15:24,600
such as walking, running, and sword swings.

137
00:15:24,600 --> 00:15:29,500
Our character is put through an intense
training regimen for 10 years in simulation.

138
00:15:29,500 --> 00:15:36,200
Thanks to NVIDIA’s massively parallel GPU simulator,
this just takes 3 days of real world time.

139
00:15:36,200 --> 00:15:40,400
The character then learns to perform
a large variety of motor skills.

140
00:15:40,400 --> 00:15:46,600
Once the character has been trained, it can use those skills that it has learned to perform more complex tasks.

141
00:15:46,600 --> 00:15:51,033
Here, the character is trained to run to a
target object and knock it over.

142
00:15:51,033 --> 00:15:56,500
We can also steer the character to walk in different directions like you would with a game character.

143
00:15:56,500 --> 00:16:03,600
Our model allows the character to automatically synthesize life-like responsive behaviors to new situations.

144
00:16:03,600 --> 00:16:07,733
We can also control the character
using natural language commands.

145
00:16:07,733 --> 00:16:13,633
For example, we can tell the character
to do a shield bash or swing its sword.

146
00:16:14,500 --> 00:16:19,000
We hope this technology will eventually
make animating simulated characters

147
00:16:19,000 --> 00:16:22,800
as easy and seamless as talking to a real actor.

148
00:16:25,000 --> 00:16:32,033
NVIDIA AI is the engine behind these innovations, and we are all-hands-on-deck to advance the platform –

149
00:16:32,033 --> 00:16:37,500
solving new problems, getting it everywhere,
and making AI more accessible.

150
00:16:37,500 --> 00:16:47,333
NVIDIA AI is a suite of libraries that span the entire AI workflow - from data processing and ETL feature engineering

151
00:16:47,333 --> 00:16:54,700
to graph, classical ML, and deep learning
model training to large-scale inference.

152
00:16:54,700 --> 00:17:03,000
NVIDIA DALI, RAPIDS, cuDNN Triton, and Magnum IO
are among the most popular libraries.

153
00:17:03,000 --> 00:17:08,900
We use the libraries to create specialized AI frameworks
that include state-of-the-art pre-trained models

154
00:17:08,900 --> 00:17:12,099
and data pipelines that make it easy to scale out.

155
00:17:12,099 --> 00:17:15,799
Let me touch on a few of our updates at GTC.

156
00:17:15,800 --> 00:17:22,300
Hundreds of billions of web interactions
a day – like search, shopping, and social –

157
00:17:22,300 --> 00:17:25,933
generate trillions of machine learning model inferences.

158
00:17:25,933 --> 00:17:35,100
NVIDIA Triton is an open-source hyperscale model inference server – the grand central station of AI deployment.

159
00:17:35,100 --> 00:17:41,400
Triton deploys models on every generation of NVIDIA GPUs,
x86 and Arm CPUs

160
00:17:41,400 --> 00:17:46,400
and has interfaces to support accelerators
such as AWS Inferentia.

161
00:17:46,400 --> 00:17:53,900
Triton supports any model – CNNs, RNNs,
Transformers, GNN, decision trees, any framework.

162
00:17:53,900 --> 00:17:58,300
Tensor Flow, PyTorch, Python, ONNX, XGBoost.

163
00:17:58,300 --> 00:18:05,033
Triton supports any query type – real-time, offline,
batched, or streaming audio and video.

164
00:18:05,033 --> 00:18:15,733
Triton supports all ML platforms – AWS, Azure, Google, Alibaba, VMWare, Domino Data Lab, OctoML, and more.

165
00:18:15,733 --> 00:18:22,100
And Triton runs in any location –
cloud, on-prem, edge, or embedded.

166
00:18:22,100 --> 00:18:25,500
Amazon Shopping is doing real-time spell checking with Triton.

167
00:18:25,500 --> 00:18:29,500
And Microsoft is using Triton for its Translator service.

168
00:18:29,500 --> 00:18:35,200
Triton has been downloaded over a
million times by 25,000 customers.

169
00:18:35,200 --> 00:18:41,900
NVIDIA Riva is a state-of-the-art speech AI
that is end-to-end based on deep learning.

170
00:18:41,900 --> 00:18:43,600
Riva is tunable.

171
00:18:43,600 --> 00:18:50,233
Riva is pre-trained with world-class recognition rates,
and then customers can refine with custom data

172
00:18:50,233 --> 00:18:54,300
to learn industry, country, or company-specific jargon.

173
00:18:54,300 --> 00:18:58,600
Riva speech AI is ideal for conversational AI services.

174
00:18:58,600 --> 00:19:04,833
Snap, RingCentral, Kore.ai, and many others are using Riva.

175
00:19:04,833 --> 00:19:08,633
Today we are announcing the general availability of Riva.

176
00:19:08,633 --> 00:19:15,933
Release 2.0 has speech recognition in 7 languages,
neural text to speech with male and female voices,

177
00:19:15,933 --> 00:19:19,800
and custom tuning with our TAO transfer learning tool.

178
00:19:19,800 --> 00:19:26,133
Riva runs on any cloud and anywhere
with NVIDIA GPUs, basically everywhere.

179
00:19:26,133 --> 00:19:33,000
Maxine is an SDK featuring state-of-the-art AI
algorithms for reinventing communications.

180
00:19:33,000 --> 00:19:40,400
Video conferencing encodes, transmits,
then decodes images and sound.

181
00:19:40,400 --> 00:19:47,800
Computer vision will replace image encoding,
and computer graphics will replace image decoding.

182
00:19:47,800 --> 00:19:54,800
Speech recognition will replace audio encoding,
and speech synthesis will replace audio decoding.

183
00:19:56,400 --> 00:20:02,533
Fifty-five years after AT&T demonstrated the Picturephone
at the World's Fair in New York,

184
00:20:02,533 --> 00:20:05,933
AI will reinvent video conferencing.

185
00:20:05,933 --> 00:20:11,300
Remote work is here to stay.
We need virtual live interactions more than ever.

186
00:20:11,300 --> 00:20:19,933
Maxine is an AI model toolkit used by developers
to reinvent communications and collaborations.

187
00:20:19,933 --> 00:20:22,600
Maxine has 30 models today.

188
00:20:22,600 --> 00:20:30,333
The GTC release adds new models for acoustic
echo cancellation and audio super-resolution.

189
00:20:30,333 --> 00:20:32,400
Let’s take a look at what Maxine can do.

190
00:20:32,400 --> 00:20:37,933
NVIDIA Maxine reinvents real-time video
communication with the magic of AI.

191
00:20:37,933 --> 00:20:44,600
Thanks to Maxine, we can now hear and see each other better, and feel more connected and included —

192
00:20:44,600 --> 00:20:47,400
even when language becomes a barrier.

193
00:20:47,400 --> 00:20:53,600
To stay engaged with my audience, Maxine helps me keep eye contact with everyone on the call,

194
00:20:53,600 --> 00:20:58,733
whether it’s one person or one hundred -
and even if I’m reading a script.

195
00:20:58,733 --> 00:21:02,800
(In Spanish) How can you overcome the language barrier with Maxine?

196
00:21:02,800 --> 00:21:07,000
While I don’t speak Spanish, with Maxine’s help, now I can!

197
00:21:08,500 --> 00:21:13,200
(In Spanish) Now I can now speak your language in my own voice. Not bad, is it?

198
00:21:13,200 --> 00:21:14,733
(In Spanish) Magnificent.

199
00:21:14,733 --> 00:21:19,200
(In French) That’s great. But can Maxine translate
into more than one language?

200
00:21:19,200 --> 00:21:21,800
Oh yes, absolutely.

201
00:21:22,933 --> 00:21:26,533
(In French) Maxine also allows me to speak French.

202
00:21:26,533 --> 00:21:28,700
(In French) And many more languages.

203
00:21:30,400 --> 00:21:36,700
(In German) We’d tell you more about Maxine’s magic,
but you’ll have to wait until the next GTC.

204
00:21:36,700 --> 00:21:38,733
(In German) Stay tuned so you don’t miss anything!

205
00:21:38,733 --> 00:21:41,400
(In German) Wonderful! I’ll be there

206
00:21:44,133 --> 00:21:47,200
Recommenders are personalization engines.

207
00:21:47,200 --> 00:21:55,300
The internet has trillions of items and is constantly changing – news, social videos, new products.

208
00:21:55,300 --> 00:21:58,100
How do we even know what is out there?

209
00:21:58,100 --> 00:22:04,033
Recommenders learn the features of items,
your explicit and implicit preferences,

210
00:22:04,033 --> 00:22:09,833
and recommend things likely of interest to you –
a personalized internet.

211
00:22:09,833 --> 00:22:16,200
Advanced recommendation engines drive
the world’s consumer internet services.

212
00:22:16,200 --> 00:22:23,100
In the future, it will also drive financial services,
healthcare services, vacation planners, and much more.

213
00:22:23,100 --> 00:22:28,400
NVIDIA Merlin is an AI framework for recommender systems.

214
00:22:28,400 --> 00:22:33,300
Merlin consists of end-to-end components
of a recommender pipeline,

215
00:22:33,300 --> 00:22:37,933
including feature transforms, retrieval, to ranking models.

216
00:22:37,933 --> 00:22:46,533
With NVIDIA Merlin, companies can quickly build, deploy, and scale state-of-the-art deep learning recommender systems.

217
00:22:46,533 --> 00:22:53,000
Snap uses Merlin to improve ad and
content recommendations while reducing cost by 50%

218
00:22:53,000 --> 00:22:56,900
and decreasing serving latency by 2x.

219
00:22:56,900 --> 00:23:06,833
Tencent Wechat uses Merlin to achieve 4 times lower latency and 10 times throughput for short video recommendations.

220
00:23:06,833 --> 00:23:11,100
Tencent's cost is halved moving from CPU to GPU.

221
00:23:11,100 --> 00:23:18,200
At GTC, we are announcing the 1.0 release,
and general availability of Merlin.

222
00:23:18,200 --> 00:23:22,533
Transformers revolutionized natural language processing.

223
00:23:22,533 --> 00:23:29,333
Training large language models is not for the faint of heart –
it is a grand computer science challenge.

224
00:23:29,333 --> 00:23:39,200
OpenAI’s GPT-3 is 175 billion parameters.
NVIDIA Megatron is 530 billion.

225
00:23:39,200 --> 00:23:45,000
And Google's new Switch Transformer is 1.6 trillion parameters.

226
00:23:45,000 --> 00:23:54,333
Nemo Megatron is a specialized AI framework for training large language models – up to trillions of parameters.

227
00:23:54,333 --> 00:24:01,633
To get the best performance possible on the target infrastructure, Nemo Megatron does automatic data, tensor,

228
00:24:01,633 --> 00:24:08,500
and pipeline parallelism, orchestration and scheduling,
and auto precision adaptation.

229
00:24:08,500 --> 00:24:14,100
Nemo Megatron now supports any NVIDIA systems.
And automatically does hyper-parameter tuning

230
00:24:14,100 --> 00:24:16,100
for your target infrastructure.

231
00:24:16,100 --> 00:24:22,300
Nemo Megatron is also cloud-native and supports Azure,
with AWS coming soon.

232
00:24:22,300 --> 00:24:30,800
AI, the creation and production of intelligence, is a giant undertaking and touches every aspect of computing

233
00:24:30,800 --> 00:24:32,633
and every industry.

234
00:24:32,633 --> 00:24:41,333
NVIDIA AI libraries and SDKs accelerate software, platforms, and services throughout the AI ecosystem.

235
00:24:41,333 --> 00:24:47,833
Even with excellent tools and libraries, developers and NVIDIA must dedicate significant engineering

236
00:24:47,833 --> 00:24:53,100
to ensure performance, scalability, reliability, and security.

237
00:24:53,100 --> 00:25:00,400
So, we have created the NVIDIA AI Accelerated program
to work with developers in the AI ecosystem

238
00:25:00,400 --> 00:25:06,333
to engineer solutions together that
customers can deploy with confidence.

239
00:25:06,333 --> 00:25:15,533
NVIDIA AI democratizes AI so that every industry
and company can apply AI to reinvent themselves.

240
00:25:15,533 --> 00:25:20,300
One of the most impactful is the revolution in digital biology.

241
00:25:20,300 --> 00:25:30,033
AI accelerates DNA sequencing, protein structure prediction, novel drug synthesis, and virtual drug testing.

242
00:25:30,033 --> 00:25:36,800
Funding for AI drug discovery startups surpassed
$40 billion in the past couple of years.

243
00:25:36,800 --> 00:25:43,800
Insilico Medicine has just sent its first AI
discovered drug to enter human clinical trials.

244
00:25:43,800 --> 00:25:50,933
The novel drug and target was discovered in less than 18 months, years faster than previously possible.

245
00:25:50,933 --> 00:25:55,600
The conditions are prime for the digital biology revolution.

246
00:25:55,600 --> 00:26:00,033
I can't imagine a greater purpose for NVIDIA AI.

247
00:26:00,033 --> 00:26:05,333
AI applications like speech, conversation,
customer service, and recommenders

248
00:26:05,333 --> 00:26:08,800
are driving fundamental changes in data center design.

249
00:26:08,800 --> 00:26:15,933
AI data centers process mountains of
continuous data to train and refine AI models.

250
00:26:15,933 --> 00:26:20,900
Raw data comes in, is refined, and intelligence goes out.

251
00:26:20,900 --> 00:26:26,800
Companies are manufacturing intelligence
and operating giant AI factories.

252
00:26:26,800 --> 00:26:32,733
The factory operation is 24/7 and intense –
minor improvements in quality

253
00:26:32,733 --> 00:26:37,900
drive a significant increase in customer
engagement and company profits.

254
00:26:37,900 --> 00:26:42,900
New organizations called MLOps are
showing up in companies around the world.

255
00:26:42,900 --> 00:26:52,700
Their fundamental mission is to efficiently and reliably transform data into predictive models - into intelligence.

256
00:26:52,700 --> 00:27:00,700
The data they process is growing exponentially – the more predictive the model, the more customers engage the services,

257
00:27:00,700 --> 00:27:02,833
the more data is collected.

258
00:27:02,833 --> 00:27:12,333
The computing infrastructure of MLOps is fundamental,
and its engine is the Ampere-architecture A100.

259
00:27:16,000 --> 00:27:20,133
Today we are announcing the next generation.

260
00:27:20,133 --> 00:27:26,400
The engine of the world's AI computing
infrastructure makes a giant leap.

261
00:27:26,400 --> 00:27:30,200
Introducing NVIDIA H100!

262
00:27:30,200 --> 00:27:37,500
The H100 is a massive 80 billion transistor chip
using TSMC 4N process.

263
00:27:37,500 --> 00:27:46,233
We designed the H100 for scale-up and scale-out infrastructures, so bandwidth, memory, networking,

264
00:27:46,233 --> 00:27:49,900
and NVLINK chip-to-chip data rates are vital.

265
00:27:49,900 --> 00:27:57,133
H100 is the first Gen5 PCI-E GPU and the first HBM3 GPU.

266
00:27:57,133 --> 00:28:03,800
A single H100 sustains 40 terabits per second of IO bandwidth.

267
00:28:03,800 --> 00:28:13,100
To put it in perspective, 20 H100s can sustain the
equivalent of the entire world's internet traffic.

268
00:28:13,100 --> 00:28:16,800
The Hopper architecture is a giant leap over Ampere.

269
00:28:16,800 --> 00:28:21,433
Let me highlight 5 groundbreaking inventions.

270
00:28:21,433 --> 00:28:26,433
First, the H100 has incredible performance.

271
00:28:26,433 --> 00:28:30,633
A new Tensor Processing format – FP8.

272
00:28:30,633 --> 00:28:31,700
H100 has:

273
00:28:31,700 --> 00:28:35,433
4 PetaFLOPS of FP8

274
00:28:35,433 --> 00:28:38,600
2 PetaFLOPS of FP16

275
00:28:38,600 --> 00:28:42,000
1 PetaFLOPS of TF32

276
00:28:42,000 --> 00:28:47,433
60 TeraFLOPS of FP64 and FP32

277
00:28:47,433 --> 00:28:57,033
Designed for air and liquid cooling, H100 is also the
first GPU to scale in performance to 700W.

278
00:28:57,033 --> 00:29:06,900
Over the past six years, through Pascal, Volta, Ampere, and now Hopper, we developed technologies to train with FP32,

279
00:29:06,900 --> 00:29:11,300
then FP16, and now FP8.

280
00:29:11,300 --> 00:29:23,900
For AI processing, Hopper H100’s 4 PF of FP8 is an amazing six times the performance of Ampere A100’s FP16 -

281
00:29:23,900 --> 00:29:27,733
our largest generational leap ever.

282
00:29:27,733 --> 00:29:32,933
The Transformer is unquestionably the most
important deep learning model invented.

283
00:29:32,933 --> 00:29:36,900
Hopper introduces a Transformer Engine.

284
00:29:36,900 --> 00:29:45,600
The Hopper Transformer Engine combines a new Tensor Core and software that uses FP8 and FP16 numerical formats,

285
00:29:45,600 --> 00:29:49,400
 and dynamically processes layers of a Transformer network.

286
00:29:49,400 --> 00:29:54,800
Transformer model training can be reduced from weeks to days.

287
00:29:54,800 --> 00:30:01,633
For cloud computing, multi-tenant infrastructure
translates directly to revenues and cost of service.

288
00:30:01,633 --> 00:30:08,700
A service can partition H100 up to 7 instances –
Ampere can also do this.

289
00:30:08,700 --> 00:30:16,500
However, Hopper added complete per-instance
isolation and per-instance IO virtualization

290
00:30:16,500 --> 00:30:19,700
to support multi-tenancy in the cloud.

291
00:30:19,700 --> 00:30:26,400
H100 can host seven cloud tenants,
while A100 can only host one.

292
00:30:26,400 --> 00:30:34,300
Each one is equivalent in performance to two full T4 GPUs,
our most popular cloud inference GPU.

293
00:30:34,300 --> 00:30:40,800
Each Hopper multi-instance supports Confidential Computing with Trusted Execution Environment.

294
00:30:40,800 --> 00:30:48,500
Sensitive data is often encrypted at-rest and in-transit
over the network but unprotected during use.

295
00:30:48,500 --> 00:30:55,500
Data can be an AI model that results from millions of dollars of investment, trained on years of domain knowledge or

296
00:30:55,500 --> 00:30:59,533
company-proprietary data, and is valuable or secret.

297
00:30:59,533 --> 00:31:04,733
Hopper Confidential Computing, a combination
of processor architecture and software,

298
00:31:04,733 --> 00:31:10,700
addresses this gap by protecting
both data and application during use.

299
00:31:10,700 --> 00:31:14,200
Confidential Computing today is only CPU-based.

300
00:31:14,200 --> 00:31:19,033
Hopper introduces the first GPU Confidential Computing.

301
00:31:19,033 --> 00:31:26,400
Hopper Confidential Computing protects the confidentiality and integrity of AI models and algorithms of the owners.

302
00:31:26,400 --> 00:31:33,000
Software developers and services can now distribute
and deploy their proprietary and valuable AI models

303
00:31:33,000 --> 00:31:40,400
on shared or remote infrastructure, protecting their
intellectual property and scaling their business models.

304
00:31:40,400 --> 00:31:42,000
And there’s more.

305
00:31:42,000 --> 00:31:53,333
Hopper introduces a new set of instructions called DPX. Designed to accelerate dynamic programming algorithms.

306
00:31:53,333 --> 00:31:59,533
Many real-world algorithms grow with
combinatorial or exponential complexity.

307
00:31:59,533 --> 00:32:01,300
Examples include -

308
00:32:01,300 --> 00:32:05,200
The famous traveling salesperson optimization problems,

309
00:32:05,200 --> 00:32:10,200
Floyd-Warshall for shortest
route optimization used for mapping,

310
00:32:10,200 --> 00:32:16,433
Smith-Waterman pattern-matching
for gene sequencing and protein folding,

311
00:32:16,433 --> 00:32:19,233
and many graph optimization algorithms.

312
00:32:19,233 --> 00:32:25,833
Dynamic programming breaks complex problems down to simpler subproblems that are solved recursively,

313
00:32:25,833 --> 00:32:29,700
reducing complexity and time to polynomial scale.

314
00:32:29,700 --> 00:32:35,733
Hopper DPX instructions will speed-up
these algorithms up to 40 times.

315
00:32:35,733 --> 00:32:40,200
H100 is the newest engine of AI infrastructures.

316
00:32:40,200 --> 00:32:50,200
H100s are packaged with HBM3 memories using TSMC CoWoS 2.5D packaging and integrated with voltage regulation

317
00:32:50,200 --> 00:32:54,700
into a superchip module called SXM.

318
00:32:54,700 --> 00:32:59,500
Let me now show you how we built up a
state-of-the-art AI computing infrastructure.

319
00:32:59,500 --> 00:33:09,700
8 H100 SXM modules are connected by
4 NVLINK Switch chips on the HGX system board.

320
00:33:09,700 --> 00:33:17,300
The four-super high-speed NVSwitch chips each have 3.6 TFLOPS of SHARP in-network computing,

321
00:33:17,300 --> 00:33:21,100
first invented in Mellanox Quantum Infiniband Switches.

322
00:33:21,100 --> 00:33:26,000
For all-to-all reductions, used extensively in
deep learning and scientific computing,

323
00:33:26,000 --> 00:33:30,433
SHARP effectively boosts bandwidth by 3 times.

324
00:33:30,433 --> 00:33:36,400
The CPU subsystem consists of dual
Gen 5 CPUs and two networking modules,

325
00:33:36,400 --> 00:33:45,533
each with four 400Gbps CX7 IB or 400Gbps
ethernet networking chips.

326
00:33:45,533 --> 00:33:52,300
CX7 has 8 billion transistors and is the
world's most advanced networking chip.

327
00:33:52,300 --> 00:33:59,633
A total of 64 billion transistors deliver
3.2 terabits per second of networking.

328
00:33:59,633 --> 00:34:07,233
Introducing the DGX H100 - our new AI computing system.

329
00:34:07,233 --> 00:34:18,433
DGX has been spectacularly successful and is the AI infrastructure for 8 of the top 10 and 44 of the Fortune 100.

330
00:34:18,433 --> 00:34:26,333
Connected by NVLINK,
DGX makes the eight H100s into one giant GPU:

331
00:34:26,333 --> 00:34:29,400
640 billion transistors

332
00:34:29,400 --> 00:34:32,100
32 petaflops of AI performance

333
00:34:32,100 --> 00:34:35,500
640 GB of HBM3

334
00:34:35,500 --> 00:34:39,800
and 24 terabytes per second of memory bandwidth.

335
00:34:39,800 --> 00:34:44,733
DGX H100 is a spectacular leap.

336
00:34:44,733 --> 00:34:46,100
And there's more!

337
00:34:46,100 --> 00:34:49,900
We have a brand-new way to scale up DGX.

338
00:34:49,900 --> 00:34:54,300
We can connect up to 32 DGXs with NVLINK.

339
00:34:54,300 --> 00:34:59,533
Today, we are announcing the NVIDIA NVLINK Switch system.

340
00:34:59,533 --> 00:35:04,200
For AI factories, DGX is the smallest unit of computing.

341
00:35:04,200 --> 00:35:14,300
With NVLINK Switch system, we can scale up
into one giant 32-node, 256-GPU DGX POD,

342
00:35:14,300 --> 00:35:25,400
with a whopping 20.5 terabytes of HBM3 memory, and 768 terabytes per second of memory bandwidth.

343
00:35:25,400 --> 00:35:29,033
768 terabytes per second!

344
00:35:29,033 --> 00:35:34,600
In comparison, the entire internet is 100 terabytes per second.

345
00:35:34,600 --> 00:35:41,200
Each DGX connects to the NVLINK Switch
with a Quad-Port Optical transceiver.

346
00:35:41,200 --> 00:35:50,600
Each port has eight channels of 100G-PAM4
signaling carrying 100GB per second.

347
00:35:50,600 --> 00:35:57,300
32 NVLINK transceivers connect to a
one rack unit NVLINK Switch system.

348
00:35:57,300 --> 00:36:03,433
The H100 DGX POD is essentially one mind-blowing GPU:

349
00:36:03,433 --> 00:36:05,900
1 exaflops of AI computing

350
00:36:05,900 --> 00:36:08,300
20 TB of HBM3

351
00:36:08,300 --> 00:36:13,000
192 TF of SHARP in-network computing

352
00:36:13,000 --> 00:36:21,633
The bi-section bandwidth moving data
between the GPUs is an amazing 70TB per second.

353
00:36:21,633 --> 00:36:32,833
Multiple H100 DGX PODs connect to our new Quantum-2 400 Gbps Infiniband switch with SHARP in-network computing,

354
00:36:32,833 --> 00:36:42,800
performance isolation, and congestion control to scale to DGX SuperPODS with thousands of H100 GPUs.

355
00:36:42,800 --> 00:36:52,633
Quantum-2 switch is a 57 billion transistor chip with the ability to connect 64 ports of 400gbps each.

356
00:36:52,633 --> 00:36:57,600
DGX SuperPODs are modern AI factories.

357
00:36:57,600 --> 00:37:06,800
We are building Eos, the first Hopper AI factory,
at NVIDIA, and she's going to be a beauty.

358
00:37:06,800 --> 00:37:09,000
18 DGX PODs

359
00:37:09,000 --> 00:37:11,700
576 DGXs

360
00:37:11,700 --> 00:37:15,800
4608 H100 GPUs

361
00:37:15,800 --> 00:37:26,500
At traditional scientific computing, Eos is 275 petaFLOPS or 1.4x faster than the fastest science computer in the US –

362
00:37:26,500 --> 00:37:29,133
the A100 powered Summit.

363
00:37:29,133 --> 00:37:40,100
At AI, Eos is 18.4 Exaflops or 4 times the AI processing
of the world's largest supercomputer –

364
00:37:40,100 --> 00:37:42,600
the Fugaku in Japan.

365
00:37:42,600 --> 00:37:47,533
We expect Eos to be the fastest AI computer in the world.

366
00:37:47,533 --> 00:37:54,200
Eos will be the blueprint for the most advanced AI infrastructure for our OEM and cloud partners.

367
00:37:54,200 --> 00:38:00,200
Partners can take H100 DGX SuperPOD
as a whole or the technology components

368
00:38:00,200 --> 00:38:03,433
at any of the four layers of our platform.

369
00:38:03,433 --> 00:38:08,100
We are standing up Eos now and will be online in a few months.

370
00:38:08,100 --> 00:38:10,800
Let's take a look at Hopper's performance.

371
00:38:10,800 --> 00:38:14,300
The performance boost over Ampere is incredible.

372
00:38:14,300 --> 00:38:20,433
Training Transformer models, the compound benefits
of Hopper's raw horsepower,

373
00:38:20,433 --> 00:38:24,033
Hopper Transformer engine with FP8 Tensor Core

374
00:38:24,033 --> 00:38:34,000
NVLINK with SHARP in-network computing, NVLINK Switch scale-up to 256 GPUs, and the Quantum-2 InfiniBand,

375
00:38:34,000 --> 00:38:40,033
and all of our software results in a 9X speed-up!

376
00:38:40,033 --> 00:38:42,900
Weeks turn to days.

377
00:38:42,900 --> 00:38:50,900
For inferencing large language models, H100 throughput
is up to 30 times higher over A100.

378
00:38:50,900 --> 00:38:55,300
H100 is the most significant leap we've ever delivered.

379
00:38:55,300 --> 00:39:02,133
NVIDIA H100, the new engine of the world's AI infrastructure.

380
00:39:02,133 --> 00:39:06,200
Hopper is going to be a game-changer
for mainstream systems as well.

381
00:39:06,200 --> 00:39:13,700
As you've seen with Hopper HGX and DGX, networking and interconnects are critical to computing –

382
00:39:13,700 --> 00:39:18,800
moving data to keep the lightning-fast GPUs
fed is a most serious concern.

383
00:39:18,800 --> 00:39:23,933
So, how do we bring Hopper's superfast
compute to mainstream servers?

384
00:39:23,933 --> 00:39:31,500
Moving data in traditional servers’ overloads CPU and
system memory and are bottlenecked by PCI-Express.

385
00:39:31,500 --> 00:39:36,200
The solution is to attach the network directly to the GPU.

386
00:39:36,200 --> 00:39:45,600
This is the H100 CNX, combining the most advanced GPU
and the most advanced networking processor, CX7,

387
00:39:45,600 --> 00:39:47,600
into a single module.

388
00:39:47,600 --> 00:39:56,800
Data from the network is DMA'd directly to H100 at 50 gigabytes per second and avoids the bottlenecks at the CPU,

389
00:39:56,800 --> 00:40:01,200
system memory, and multiple passes across PCI express.

390
00:40:01,200 --> 00:40:09,133
H100 CNX avoids bandwidth bottlenecks while freeing the CPU and system memory to process other parts of the application.

391
00:40:09,133 --> 00:40:15,300
An incredible amount of technology in a tiny
little package designed for mainstream servers.

392
00:40:15,300 --> 00:40:23,500
Hopper H100 powers systems at every scale – from the PCI express accelerator for mainstream servers

393
00:40:23,500 --> 00:40:29,200
to DGX, DGX Pod, and DGX SuperPOD.

394
00:40:29,200 --> 00:40:36,933
These systems run NVIDIA HPC and NVIDIA AI
and the rich ecosystem of CUDA libraries.

395
00:40:36,933 --> 00:40:41,900
Let me update you on Grace - our first data center CPU.

396
00:40:41,900 --> 00:40:48,000
I am pleased to report that Grace is progressing
fantastically and on track to ship next year.

397
00:40:48,000 --> 00:40:52,800
We designed Grace to process giant amounts of data.

398
00:40:52,800 --> 00:40:57,100
Grace will be the ideal CPU for AI factories.

399
00:40:57,100 --> 00:41:00,200
And this is Grace-Hopper.

400
00:41:00,200 --> 00:41:07,700
A single superchip module with direct chip-to-chip
connection between the CPU and GPU.

401
00:41:07,700 --> 00:41:15,833
One of the critical enabling technologies of Grace-Hopper is the memory coherent chip-to-chip NVLINK interconnect –

402
00:41:15,833 --> 00:41:19,300
a 900 gigabytes per second link!

403
00:41:19,300 --> 00:41:22,100
But I only told you half the story.

404
00:41:22,100 --> 00:41:25,900
The full Grace is truly amazing.

405
00:41:25,900 --> 00:41:36,800
The Grace CPU can also be a superchip made up of two CPU chips connected, coherently, over NVLINK chip-to-chip.

406
00:41:36,800 --> 00:41:42,600
Grace superchip has 144 CPU cores!

407
00:41:42,600 --> 00:41:47,900
And an insane 1 terabyte per second of memory bandwidth -

408
00:41:47,900 --> 00:41:54,600
over two to three times the top Gen 5 CPUs
that have yet to even ship.

409
00:41:54,600 --> 00:42:05,033
We estimate the Grace superchip to have a SPECint 2017
rate of 740. Nothing close to that ships today.

410
00:42:05,033 --> 00:42:13,533
And the amazing thing is the entire module,
including a terabyte of memory, is only 500 Watts.

411
00:42:13,533 --> 00:42:19,300
We expect the Grace superchip to be the
highest performance and twice the energy efficiency

412
00:42:19,300 --> 00:42:21,833
of the best CPU at that time.

413
00:42:21,833 --> 00:42:28,900
Grace will be amazing at AI, data analytics,
scientific computing, and hyperscale computing.

414
00:42:28,900 --> 00:42:40,500
And Grace will be welcomed by all of NVIDIA's software platforms – NVIDIA RTX, HPC, NVIDIA AI, and Omniverse.

415
00:42:40,500 --> 00:42:47,300
The enabler for Grace-Hopper and Grace superchip
is the ultra-energy-efficient, low-latency,

416
00:42:47,300 --> 00:42:52,200
high-speed memory coherent NVLINK chip-to-chip link.

417
00:42:52,200 --> 00:42:59,200
With NVLINK that scales from die-to-die,
chip-to-chip, and system-to-system,

418
00:42:59,200 --> 00:43:04,833
we can configure Grace and Hopper
to address a large diversity of workloads.

419
00:43:04,833 --> 00:43:06,533
We can create systems with:

420
00:43:06,533 --> 00:43:09,633
A Two-Grace CPU Superchip

421
00:43:09,633 --> 00:43:13,500
A One-Grace, One-Hopper Superchip

422
00:43:13,500 --> 00:43:17,300
A One-Grace, Two-Hopper Superchip

423
00:43:17,300 --> 00:43:21,900
And systems with Two-Grace, Two Hoppers

424
00:43:21,900 --> 00:43:24,633
Two-Grace and Four Hoppers

425
00:43:24,633 --> 00:43:27,633
Two-Grace and Eight Hoppers

426
00:43:27,633 --> 00:43:35,900
The composability of Grace and Hopper’s NVLINK,
and the Gen 5 PCI express switch inside CX7,

427
00:43:35,900 --> 00:43:41,400
give us a vast number of ways to address
customer’s diverse computing needs.

428
00:43:41,400 --> 00:43:52,800
Future NVIDIA chips – CPUs, GPUs, DPUs, NICs, and SOCs –
will integrate NVLINK just like Grace and Hopper.

429
00:43:52,800 --> 00:43:55,500
Our SERDES technology is world-class.

430
00:43:55,500 --> 00:44:00,733
From years of designing high-speed memory interfaces, NVLINKs, and networking switches,

431
00:44:00,733 --> 00:44:04,433
NVIDIA has world-class expertise in high-speed SERDES.

432
00:44:04,433 --> 00:44:11,733
NVIDIA is making NVLINK and SERDES available to customers and partners who want to implement custom chips

433
00:44:11,733 --> 00:44:13,933
that connect to NVIDIA's platforms.

434
00:44:13,933 --> 00:44:21,533
These high-speed links have opened a new world to build semi-custom chips and systems with NVIDIA computing.

435
00:44:21,533 --> 00:44:31,300
NVIDIA has accelerated computing a Million-X
over the past decade by GPU-accelerating algorithms,

436
00:44:31,300 --> 00:44:38,033
optimizing across the full-stack,
and scaling across the entire data center.

437
00:44:38,033 --> 00:44:44,000
The computer science and engineering
is captured in NVIDIA SDKs.

438
00:44:44,000 --> 00:44:51,133
NVIDIA SDKs with CUDA libraries are the
heart and soul of accelerated computing.

439
00:44:51,133 --> 00:44:58,400
NVIDIA SDKs connect us to new challenges in
science and new opportunities in industry.

440
00:44:58,400 --> 00:45:07,800
RAPIDS is a suite of SDKs for data scientists using popular Python APIs for DataFrames, SQL, arrays,

441
00:45:07,800 --> 00:45:10,700
machine learning, and graph analytics.

442
00:45:10,700 --> 00:45:16,800
RAPIDS is one of NVIDIA’s most popular SDKs,
second only to cuDNN for deep learning.

443
00:45:16,800 --> 00:45:23,500
RAPIDS has been downloaded 2M times
and has grown 3 times year-over-year.

444
00:45:23,500 --> 00:45:29,100
It is used by over 5,000 GitHub projects
and over 2,000 Kaggle notebooks,

445
00:45:29,100 --> 00:45:33,800
and is integrated into 35 commercial software packages.

446
00:45:33,800 --> 00:45:38,533
NVIDIA RAPIDS for Spark is a plug-in
for accelerating Apache Spark.

447
00:45:38,533 --> 00:45:45,700
Spark is the leading data processing engine used by 80%
of the Fortune 500 companies.

448
00:45:45,700 --> 00:45:51,300
Users of Spark can transparently
accelerate Spark data-frame and SQL.

449
00:45:51,300 --> 00:45:55,333
Operations that take hours now take minutes.

450
00:45:55,333 --> 00:46:04,633
NVIDIA cuOpt, previously called ReOpt, is an SDK for multi-agent, multi-constraint route planning optimization

451
00:46:04,633 --> 00:46:09,900
used for delivery services or
autonomous mobile robots inside warehouses.

452
00:46:09,900 --> 00:46:17,400
With NVIDIA cuOpt, businesses can, for the first time, do real-time planning of thousands of packages

453
00:46:17,400 --> 00:46:23,400
to thousands of locations in
seconds with world-record accuracy.

454
00:46:23,400 --> 00:46:28,033
Over 175 companies are testing NVIDIA cuOpt.

455
00:46:28,033 --> 00:46:36,900
Graphs are one of the most used data structures to represent real-world data, like maps, social networks, the web,

456
00:46:36,900 --> 00:46:40,933
proteins and molecules, and financial transactions.

457
00:46:40,933 --> 00:46:48,900
The NVIDIA DGL container lets you train large graph neural networks across multiple GPUs and nodes.

458
00:46:48,900 --> 00:46:54,200
NVIDIA Morpheus is a deep learning
framework for cybersecurity.

459
00:46:54,200 --> 00:47:02,033
Morpheus helps cybersecurity developers build and
scale solutions that use deep learning to identify,

460
00:47:02,033 --> 00:47:06,833
capture, and act on threats previously impossible.

461
00:47:06,833 --> 00:47:11,300
Every company needs to move to a Zero Trust architecture.

462
00:47:11,300 --> 00:47:15,100
NVIDIA can for sure use Morpheus.

463
00:47:15,100 --> 00:47:20,433
cuQuantum is an SDK for accelerating
Quantum Circuit Simulators

464
00:47:20,433 --> 00:47:24,633
so researchers can develop quantum
computing algorithms of the future

465
00:47:24,633 --> 00:47:29,533
that are impossible to explore on quantum computers today.

466
00:47:29,533 --> 00:47:35,933
cuQuantum accelerates the top QC
simulators Google Cirq, IBM Qiskit,

467
00:47:35,933 --> 00:47:42,700
Xanadu’s Pennylane, Quantinuum TKET,
and Oak Ridge National Laboratory ExaTN.

468
00:47:42,700 --> 00:47:49,100
cuQuantum on DGX is the ideal
development system for quantum computing.

469
00:47:49,100 --> 00:47:56,100
Aerial is an SDK for CUDA-accelerated
software-defined 5G radio.

470
00:47:56,100 --> 00:48:03,000
With Aerial, any data center, cloud, on-prem,
or edge, can be a 5G radio network

471
00:48:03,000 --> 00:48:08,633
and provision AI services on 5G to places not served by WIFI.

472
00:48:08,633 --> 00:48:12,900
The 6G standard will emerge around 2026.

473
00:48:12,900 --> 00:48:19,400
The megatrends shaping 6G are clear -
hundreds of billions of machines and robots

474
00:48:19,400 --> 00:48:22,433
will be the overwhelming users of the network.

475
00:48:22,433 --> 00:48:27,633
6G is taking shape around a few foundational technologies.

476
00:48:27,633 --> 00:48:31,700
Like networking, 6G will be highly software-defined.

477
00:48:31,700 --> 00:48:34,400
The network will be AI-driven.

478
00:48:34,400 --> 00:48:40,100
Digital twins performing ray tracing
and AI will help optimize the network.

479
00:48:40,100 --> 00:48:42,900
NVIDIA can make contributions in these areas.

480
00:48:42,900 --> 00:48:52,400
We are excited to announce a new framework, Sionna, an AI framework for 6G communications research.

481
00:48:52,400 --> 00:48:58,500
Modulus is an AI framework for developing physics-ML models.

482
00:48:58,500 --> 00:49:06,500
These deep neural network models can learn physics
and make predictions that obey the laws of physics

483
00:49:06,500 --> 00:49:12,000
at many orders of magnitude faster than numerical methods.

484
00:49:12,000 --> 00:49:16,000
We are using Modulus to build the Earth-2 digital twin.

485
00:49:16,000 --> 00:49:20,233
Monai is an open-source AI framework for medical imaging.

486
00:49:20,233 --> 00:49:31,100
The NVIDIA Monai container includes AI-assisted labeling for 2D and 3D models, transfer learning, and autoML training;

487
00:49:31,100 --> 00:49:34,100
and it’s easy to deploy through DICOM.

488
00:49:34,100 --> 00:49:42,000
Monai is used by the world’s top 30 academic
medical centers and has over 250,000 downloads.

489
00:49:42,000 --> 00:49:51,900
FLARE is NVIDIA’s open-source SDK for federated learning, letting researchers collaborate in a privacy-preserving way –

490
00:49:51,900 --> 00:49:54,933
sharing models but not data.

491
00:49:54,933 --> 00:50:02,400
Millions of developers and tens of thousands of companies use NVIDIA SDKs to accelerate their workload.

492
00:50:02,400 --> 00:50:09,100
We updated 60 SDKs with more features
and acceleration at this GTC.

493
00:50:09,100 --> 00:50:14,300
The same NVIDIA systems you own just got faster

494
00:50:14,300 --> 00:50:21,200
and scientists doing Operations Research,
quantum algorithm research, 6G research,

495
00:50:21,200 --> 00:50:26,733
or graph analytics can tap into
NVIDIA acceleration for the first time.

496
00:50:26,733 --> 00:50:30,400
And for the companies doing computer
aided design or engineering,

497
00:50:30,400 --> 00:50:35,100
the software tools you depend on from Ansys, Altair,

498
00:50:35,100 --> 00:50:42,033
Siemens, Synopsys, Cadence, and more,
just got a massive speed-up.

499
00:50:42,033 --> 00:50:46,500
From first-hand experience, it has transformed our engineering.

500
00:50:46,500 --> 00:50:55,000
So, go to NGC, NVIDIA GPU Cloud, and download our SDKs
and frameworks that are full-stack optimized

501
00:50:55,000 --> 00:50:58,400
and data-center-scale accelerated.

502
00:51:04,500 --> 00:51:10,033
The Apollo 13 crew was
136,000 miles from Earth

503
00:51:10,033 --> 00:51:17,100
when a faulty electrical wire caused
one of the two oxygen tanks to explode.

504
00:51:17,100 --> 00:51:22,300
And the now infamous words radioed back to NASA -
“Houston, we’ve had a problem.”

505
00:51:22,300 --> 00:51:28,433
To “work the problem”, NASA engineers tested oxygen-preserving and power-cycling procedures

506
00:51:28,433 --> 00:51:31,800
on a replica of the Odyssey spacecraft.

507
00:51:31,800 --> 00:51:38,833
Apollo 13 would have ended in disaster if not
for the fully functional replica on Earth.

508
00:51:38,833 --> 00:51:41,733
This was an important moment.

509
00:51:41,733 --> 00:51:48,233
NASA realized the power of the replica,
but not everything can have a physical twin.

510
00:51:48,233 --> 00:51:57,500
So NASA coined the term “digital twin,” a living virtual representation of something physical.

511
00:51:57,500 --> 00:52:06,033
Extended to vast scales, a digital twin is a
virtual world that’s connected to the physical world.

512
00:52:06,033 --> 00:52:10,900
And in the context of the internet, it is the next evolution.

513
00:52:10,900 --> 00:52:20,600
And that’s what NVIDIA Omniverse is about – digital twins, virtual worlds, and the next evolution of the internet.

514
00:52:20,600 --> 00:52:30,033
Over 20 years of NVIDIA graphics, physics, simulation, AI, and computing technologies made Omniverse possible.

515
00:52:30,033 --> 00:52:33,800
Simulating the world is the ultimate grand challenge.

516
00:52:33,800 --> 00:52:37,533
Omniverse is a simulation engine of virtual worlds.

517
00:52:37,533 --> 00:52:42,400
Omniverse worlds are physically accurate,
obeying the laws of physics.

518
00:52:42,400 --> 00:52:44,933
Omniverse operates at vast scales.

519
00:52:44,933 --> 00:52:50,800
And Omniverse is sharable, connecting designers,
viewers, AIs, and robots.

520
00:52:50,800 --> 00:52:53,200
But what are the applications of Omniverse?

521
00:52:53,200 --> 00:52:57,100
I will highlight several immediate use-cases today.

522
00:52:57,100 --> 00:53:00,800
Remote Collaboration of designers using different tools.

523
00:53:00,800 --> 00:53:04,700
Sim2Real Gyms where AI and robots learn.

524
00:53:04,700 --> 00:53:06,633
And industrial Digital Twins.

525
00:53:06,633 --> 00:53:11,200
But first, let me show you the
technologies that make Omniverse possible.

526
00:54:26,100 --> 00:54:30,500
Omniverse technology will transform the way you create!

527
00:55:11,300 --> 00:55:16,300
Omniverse is scalable from RTX PCs to large systems.

528
00:55:16,300 --> 00:55:23,400
RTX PCs connected to someone hosting the Omniverse Nucleus are sufficient for creative collaboration.

529
00:55:23,400 --> 00:55:29,200
Industrial digital twins, however, need a new type
of purpose-built computer.

530
00:55:29,200 --> 00:55:36,733
Digital twin simulations involve multiple autonomous systems interacting in the same space-time.

531
00:55:36,733 --> 00:55:42,800
Data centers process data in the
lowest possible time, not precise time.

532
00:55:42,800 --> 00:55:52,000
So for digital twins, the Omniverse software and computer need to be scalable, low latency, and support precise time.

533
00:55:52,000 --> 00:55:55,800
We need to create a synchronous data center.

534
00:55:55,800 --> 00:56:01,933
Just as we have DGX for AI, we now have OVX for Omniverse.

535
00:56:01,933 --> 00:56:13,700
The first-generation NVIDIA OVX Omniverse computer consists of eight NVIDIA A40 RTX GPUs, 3 CX6 200 Gbps NICs,

536
00:56:13,700 --> 00:56:16,300
and dual Intel Ice Lake CPUs.

537
00:56:16,300 --> 00:56:28,233
And the NVIDIA Spectrum-3 200 gigabytes per second switch fabric connects 32 OVX servers to form the OVX SuperPOD.

538
00:56:28,233 --> 00:56:34,000
Most importantly, the network and computers
are synchronized using Precision Timing Protocol,

539
00:56:34,000 --> 00:56:37,533
and RDMA minimizes packet transfer latency.

540
00:56:37,533 --> 00:56:41,200
OVX servers are now available from
the world’s top computer makers.

541
00:56:41,200 --> 00:56:47,500
And for customers wanting to try Omniverse on OVX,
NVIDIA LaunchPads are located around the world.

542
00:56:47,500 --> 00:56:52,500
Generation one OVX are running at NVIDIA and early customers.

543
00:56:52,500 --> 00:56:57,333
We are building our second-generation OVX,
starting with the backbone.

544
00:56:57,333 --> 00:57:01,000
Today, we are introducing the Spectrum-4 switch.

545
00:57:01,000 --> 00:57:10,400
At 51.2 terabytes per second, the 100-billion transistor Spectrum-4 is the most advanced switch ever built.

546
00:57:10,400 --> 00:57:16,400
Spectrum-4 introduces fair bandwidth
distribution across all ports, adaptive routing,

547
00:57:16,400 --> 00:57:20,733
and congestion control for the
highest overall data center throughput.

548
00:57:20,733 --> 00:57:27,033
With CX7 and Bluefield-3 adaptors, and the
DOCA data center infrastructure software,

549
00:57:27,033 --> 00:57:35,400
this is the world’s first 400 gigabytes per second
end-to-end networking platform.

550
00:57:35,400 --> 00:57:39,933
And Spectrum-4 can achieve timing
precision to a few nanoseconds

551
00:57:39,933 --> 00:57:49,600
versus the many milliseconds of jitter in a typical data center – that is a 5 to 6 orders of magnitude improvement.

552
00:57:49,600 --> 00:57:56,700
Hyperscalers will enjoy increased throughput, quality of service, and security, while reducing power and cost.

553
00:57:56,700 --> 00:58:04,300
Spectrum-4 enables a new class of computers for Omniverse digital twins in cloud and edge data centers.

554
00:58:04,300 --> 00:58:10,100
NVIDIA Spectrum-4, the world’s most
advanced ethernet networking platform

555
00:58:10,100 --> 00:58:15,700
and the backbone of our Omniverse
computer, samples in late Q4.

556
00:58:15,700 --> 00:58:20,000
Omniverse is a network-of-networks connecting virtual worlds.

557
00:58:20,000 --> 00:58:29,300
The value of the network amplifies when diverse ecosystems connect through Omniverse into a unified workflow.

558
00:58:29,300 --> 00:58:35,533
Since last year’s GTC, we’ve increased connections from 8 to 82.

559
00:58:35,533 --> 00:58:41,100
We have connectors with Chaos Vray,
Autodesk Arnold, and Blender.

560
00:58:41,100 --> 00:58:47,033
Adobe’s 3D Substance Painter, Epic’s Unreal Engine 5,
and Maxon’s Cinema 4D.

561
00:58:47,033 --> 00:58:52,700
Many developers want to OEM and connect
Omniverse directly into their software suite.

562
00:58:52,700 --> 00:58:58,400
Bentley Systems is the leading infrastructure design, construction, and management platform.

563
00:58:58,400 --> 00:59:07,100
They integrated Omniverse into their LumenRT platform to do interactive, engineering-grade, millimeter-accurate,

564
00:59:07,100 --> 00:59:12,100
4D visualization of massive infrastructure digital twins.

565
00:59:12,100 --> 00:59:16,000
Bentley’s LumenRT with Omniverse is available now.

566
00:59:16,000 --> 00:59:18,733
We are launching a major release at GTC.

567
00:59:18,733 --> 00:59:24,833
Omniverse Kit for building Omniverse extensions,
apps, and microservices.

568
00:59:24,833 --> 00:59:32,500
We are releasing 26 manufacturing format converters to connect industrial workflows to Omniverse.

569
00:59:32,500 --> 00:59:42,033
DeepSearch is an AI search engine for massive, untagged, 3D asset libraries using either natural language or images.

570
00:59:42,033 --> 00:59:51,433
Omniverse Replicator, a framework for generating physically accurate synthetic data to train and test AI models.

571
00:59:51,433 --> 01:00:00,900
And Omnigraph, a multi-GPU, multi-node, compute engine to run data-center-scale Omniverse applications.

572
01:00:00,900 --> 01:00:08,900
And, a very big project, Omniverse Avatar,
a framework for building avatars, or digital humans.

573
01:00:08,900 --> 01:00:15,400
Let me welcome back Toy Jensen,
an application we built with Omniverse Avatar.

574
01:00:15,400 --> 01:00:20,500
Remember, Toy Jensen is not recorded.
He is completely real-time.

575
01:00:20,500 --> 01:00:26,600
Making eye contact, making conversation, and fully animated.

576
01:00:26,600 --> 01:00:31,400
Hey TJ! I have a few questions for you.

577
01:00:31,400 --> 01:00:33,700
Sure! Ask me anything.

578
01:00:33,700 --> 01:00:35,933
What is synthetic biology?

579
01:00:37,300 --> 01:00:44,000
Synthetic Biology is about designing biological systems at multiple levels from individual molecules up to whole cells

580
01:00:44,000 --> 01:00:48,700
and even multicellular assemblies like
tissues and organs to perform specific functions.

581
01:00:48,700 --> 01:00:53,200
It is also known as SynBio which stands for 'synthetic life'.

582
01:00:53,200 --> 01:00:55,700
Can you give me some examples?

583
01:00:57,000 --> 01:01:03,933
Some current uses of synthetic biology involve creating biofuels; engineering bacteria with useful properties not found

584
01:01:03,933 --> 01:01:09,433
in naturally occurring organisms; developing biosensors
capable of detecting environmental toxins;

585
01:01:09,433 --> 01:01:15,800
producing biopharmaceuticals; and manufacturing chemicals via fermentation rather than petrochemicals.

586
01:01:16,533 --> 01:01:19,900
What are its medical applications?

587
01:01:19,900 --> 01:01:27,200
Synthetic biology has many medical applications. For example, synthetic biology is being used to develop new vaccines,

588
01:01:27,200 --> 01:01:30,833
new antibiotics, and new treatments for cancer.

589
01:01:30,833 --> 01:01:36,000
TJ that was great! Can you tell us how you were made?

590
01:01:36,000 --> 01:01:39,533
Avatar is a framework built on the Omniverse platform.

591
01:01:39,533 --> 01:01:44,733
It lets you quickly build and deploy
Avatars like me for a wide range of uses.

592
01:01:44,733 --> 01:01:50,200
It starts with my voice. It is fully synthesized
by Riva’s Text to Speech RADTTS

593
01:01:50,200 --> 01:01:55,333
and is also used to drive my
facial animation using Omniverse Audio2Face.

594
01:01:55,333 --> 01:02:00,400
Next, Omniverse animation’s animation graph
is used to define and govern my movement,

595
01:02:00,400 --> 01:02:04,400
from hand and arm movements to subtle head and body motion.

596
01:02:04,400 --> 01:02:10,000
NVIDIA’s open-source Material Definition Language, MDL,
adds the touches that make my cool jacket

597
01:02:10,000 --> 01:02:17,033
look like synthetic leather and not just plastic, while the RTX renderer brings me to life in high-fidelity—in real-time.

598
01:02:17,033 --> 01:02:22,700
Finally, I can listen and talk to you thanks to the latest in conversational AI technologies from Riva

599
01:02:22,700 --> 01:02:30,133
and our Megatron 530B NLP model, one of the
largest language models ever trained.

600
01:02:30,133 --> 01:02:34,900
Megatron helps me answer all those
tough questions Jensen throws at me.

601
01:02:34,900 --> 01:02:41,000
What’s also exciting is that I can be run from the cloud,
the data center, or any other disaggregated system,

602
01:02:41,000 --> 01:02:43,000
all thanks to Tokkio.

603
01:02:43,000 --> 01:02:49,200
Tokkio is an application built with Omniverse Avatar
and it brings customer service AI to retail stores,

604
01:02:49,200 --> 01:02:51,700
quick-service restaurants, and even the web.

605
01:02:51,700 --> 01:03:00,033
It comes to life using NVIDIA AI models and technology like computer vision, Riva speech AI, and NVIDIA NeMO.

606
01:03:00,033 --> 01:03:05,933
And because it runs on our unified computing framework,
or UCF, Tokkio can scale-out from the cloud

607
01:03:05,933 --> 01:03:09,333
and go wherever customers need helpful avatars like me,

608
01:03:09,333 --> 01:03:13,633
with senses that are fully acute
and responsive, and above all, natural.

609
01:03:13,633 --> 01:03:18,600
I hope you enjoyed a quick overview of how I was made.
Back to you, Jensen!

610
01:03:19,600 --> 01:03:27,800
Today’s AI centers around perception and pattern recognition, like recognizing an image, understanding speech,

611
01:03:27,800 --> 01:03:32,433
suggesting a video to watch, or recommending an item to buy.

612
01:03:32,433 --> 01:03:39,400
The next wave of AI is robotics, where AI will also plan and act.

613
01:03:39,400 --> 01:03:45,233
NVIDIA is building several robotics platforms –
DRIVE for autonomous vehicles,

614
01:03:45,233 --> 01:03:52,833
Isaac for maneuvering and manipulation systems,
Metropolis for autonomous infrastructures,

615
01:03:52,833 --> 01:03:57,200
and Holoscan for robotic medical instruments.

616
01:03:57,200 --> 01:04:06,233
And just as NASA recognized, we will need digital twins in order to operate fleets of robots that are far away.

617
01:04:06,233 --> 01:04:12,700
The workflow of a robotic system is complex.
I’ve simplified it here to four pillars:

618
01:04:12,700 --> 01:04:15,900
Collecting and generating ground truth data,

619
01:04:15,900 --> 01:04:17,933
creating the AI model,

620
01:04:17,933 --> 01:04:20,633
simulating with a digital twin,

621
01:04:20,633 --> 01:04:22,733
operating the robot.

622
01:04:22,733 --> 01:04:25,533
Omniverse is central throughout.

623
01:04:25,533 --> 01:04:31,800
DRIVE is our autonomous vehicle system,
it’s essentially an AI chauffeur.

624
01:04:31,800 --> 01:04:37,200
As with all of our platforms,
NVIDIA DRIVE is full-stack, end-to-end,

625
01:04:37,200 --> 01:04:41,600
and open for developers to use in-whole or in-parts.

626
01:04:41,600 --> 01:04:49,500
For ground truth data, we use our DeepMap HD mapping, human-labeled data, and Omniverse Replicator.

627
01:04:49,500 --> 01:04:54,633
To train the AI models, we use NVIDIA AI and DGX.

628
01:04:54,633 --> 01:04:59,833
DRIVE Sim in Omniverse, running on OVX, is the digital twin.

629
01:04:59,833 --> 01:05:07,600
And DRIVE AV is the autonomous driving application
running on our Orin computer in the car.

630
01:05:07,600 --> 01:05:11,700
Let’s enjoy a ride with the latest build of NVIDIA Drive.

631
01:05:11,700 --> 01:05:15,300
We will take you through a highway and urban route in San Jose.

632
01:05:15,300 --> 01:05:19,333
You can see what the car sees
from the confidence view rendering

633
01:05:19,333 --> 01:05:24,300
We will navigate complex situations
such as crowded intersections,

634
01:05:24,300 --> 01:05:29,100
And your AI chauffeur will be a friendly driving companion.

635
01:05:45,300 --> 01:05:49,300
Welcome Daniel. I see a text from Hubert asking,

636
01:05:49,300 --> 01:05:53,333
“Can you pick me up from the San Jose Civic?”
Should I take you there?

637
01:05:53,333 --> 01:05:54,933
Yes, please.

638
01:05:55,333 --> 01:05:58,400
Okay, taking you to San Jose Civic.

639
01:05:59,200 --> 01:06:00,700
StartDRIVE Pilot.

640
01:06:00,900 --> 01:06:03,800
OK, starting DRIVE Pilot.

641
01:06:08,900 --> 01:06:10,600
Can you tell Hubert we’re on our way?

642
01:06:11,600 --> 01:06:13,900
Sure, I’ll send him a text.

643
01:06:44,000 --> 01:06:45,700
I see Hubert.

644
01:06:49,933 --> 01:06:52,500
Can you please take me to Rivermark Hotel?

645
01:06:52,500 --> 01:06:55,433
Okay, taking you to Rivermark Hotel.

646
01:06:55,433 --> 01:06:56,700
Thanks for picking me up!

647
01:06:56,700 --> 01:06:59,600
Definitely. Start DRIVE Pilot.

648
01:06:59,600 --> 01:07:02,000
Ok, starting DRIVE Pilot.

649
01:07:05,700 --> 01:07:07,433
What building is that there?

650
01:07:07,433 --> 01:07:10,633
That building is San Jose Center for the Performing Arts

651
01:07:10,633 --> 01:07:12,600
What shows are playing there?

652
01:07:12,600 --> 01:07:14,600
Cats is playing tonight.

653
01:07:14,600 --> 01:07:17,600
Can you get me two tickets for Saturday night?

654
01:07:17,600 --> 01:07:19,400
Yes I can.

655
01:07:44,633 --> 01:07:46,733
You have arrived at your destination.

656
01:07:46,733 --> 01:07:48,800
Please park the vehicle.

657
01:07:49,233 --> 01:07:52,933
OK, finding a parking spot.

658
01:08:14,000 --> 01:08:23,100
Hyperion 8 is the hardware architecture of our self-driving car and it’s what we build our entire DRIVE platform on.

659
01:08:23,100 --> 01:08:31,600
It consists of sensors, networks, two chauffeur AV computers, one concierge AI computer, a mission recorder,

660
01:08:31,600 --> 01:08:34,100
and safety and cybersecurity systems.

661
01:08:34,100 --> 01:08:36,500
And it’s open.

662
01:08:36,500 --> 01:08:46,800
Hyperion 8 can achieve full self-driving with a 360-degree camera, radar, lidar, and ultrasonic sensor suite.

663
01:08:46,800 --> 01:08:54,500
Hyperion 8 will ship in Mercedes Benz cars starting in 2024, followed by Jaguar Land Rover in 2025.

664
01:08:54,500 --> 01:09:01,200
Today, we are announcing Hyperion 9
for cars shipping starting in 2026.

665
01:09:01,200 --> 01:09:08,633
Hyperion 9 will have 14 cameras,
9 radars, 3 lidars, and 20 ultrasonics.

666
01:09:08,633 --> 01:09:15,600
Overall, Hyperion 9 will process twice the amount
of sensor data compared to Hyperion 8,

667
01:09:15,600 --> 01:09:21,700
further enhancing safety and extending the
operating domains of full self-driving.

668
01:09:21,700 --> 01:09:28,832
NVIDIA DRIVE Map is a multi-modal map engine
and includes camera, radar, and lidar.

669
01:09:28,832 --> 01:09:35,232
You can localize to each layer of the map independently,
which provides diversity and redundancy

670
01:09:35,233 --> 01:09:37,399
for the highest level of safety.

671
01:09:37,399 --> 01:09:45,332
Drive Map has two map engines – ground truth survey mapping and crowdsourced fleet mapping.

672
01:09:45,332 --> 01:09:54,433
By the end of 2024, we expect to map and create a digital twin of all major highways in North America, Western Europe,

673
01:09:54,433 --> 01:09:59,000
and Asia – about 500,000 kilometers.

674
01:09:59,000 --> 01:10:03,600
The map will be expanded and updated
by millions of passenger cars.

675
01:10:04,533 --> 01:10:11,300
We are building an earth-scale digital twin of our AV fleet
to explore new algorithms and designs,

676
01:10:11,300 --> 01:10:15,033
and test software before deploying to the fleet.

677
01:10:15,033 --> 01:10:21,100
We are developing two methods to simulate scenarios – each reconstructs the world in different ways.

678
01:10:21,100 --> 01:10:26,200
One method starts from NVIDIA Drive Map,
a multi-modal map engine

679
01:10:26,200 --> 01:10:31,133
that creates a highly accurate 3D representation of the world.

680
01:10:31,133 --> 01:10:34,133
The map is loaded into Omniverse.

681
01:10:38,100 --> 01:10:43,800
Buildings, vegetation, and
other roadside objects are generated.

682
01:10:48,100 --> 01:10:54,300
From previous drives, the dynamic objects, cars, and pedestrians, are inferred, localized,

683
01:10:54,300 --> 01:10:57,700
and placed into the digital twin.

684
01:11:02,600 --> 01:11:09,233
Each dynamic object can be animated or
assigned an AI behavior model.

685
01:11:12,600 --> 01:11:19,733
Domain randomization can be applied to generate
diverse and plausible challenging scenarios.

686
01:11:26,600 --> 01:11:34,133
A second approach uses Neural Graphics AI and
Omniverse to transform a pre-recorded drive video

687
01:11:34,133 --> 01:11:38,200
into a reenactable and modifiable drive.

688
01:11:38,200 --> 01:11:41,800
We start by reconstructing the scene in 3D.

689
01:11:41,800 --> 01:11:46,733
Dynamic objects are recognized and removed,
and the background is restored.

690
01:11:46,733 --> 01:11:51,933
After scene reconstruction, we can
change the behavior of existing vehicles

691
01:11:51,933 --> 01:11:57,000
or add fully controllable vehicles
that behave realistically to traffic.

692
01:11:57,000 --> 01:12:05,133
The regenerated drive, with 3D geometry, and physically based materials, allow us to properly re-illuminate the scene,

693
01:12:05,133 --> 01:12:09,133
apply physics, and simulate sensors, like LIDAR.

694
01:12:09,133 --> 01:12:16,300
The pre-recorded scene is now reenactable and can be
used for closed-loop simulation and testing.

695
01:12:17,000 --> 01:12:24,300
DRIVE Map and DRIVE Sim, with AI breakthroughs by NVIDIA research, showcase the power of Omniverse digital twin

696
01:12:24,300 --> 01:12:27,433
to advance the development of autonomous vehicles.

697
01:12:29,200 --> 01:12:38,200
NVIDIA DRIVE Map, DRIVE Sim,
Hyperion 8 with Orin, and DRIVE AV stacks

698
01:12:38,200 --> 01:12:41,900
are available independently or together as a whole.

699
01:12:41,900 --> 01:12:46,200
Electric vehicles have forced a
complete redesign of car architectures.

700
01:12:46,200 --> 01:12:54,500
Future cars will be highly programmable, evolving from many embedded controllers to highly centralized computers.

701
01:12:54,500 --> 01:13:01,200
The AI and AV functionalities will be delivered in
software and enhanced for the life of the car.

702
01:13:01,200 --> 01:13:06,500
NVIDIA Orin has been enormously
successful with companies building this future.

703
01:13:06,500 --> 01:13:14,600
Orin is the ideal centralized AV and AI computer
and is the engine of new-generation EVs,

704
01:13:14,600 --> 01:13:17,500
robotaxis, shuttles, and trucks.

705
01:13:17,500 --> 01:13:20,800
Orin started shipping this month.

706
01:13:20,800 --> 01:13:28,600
Today we are thrilled to announce that BYD,
the second-largest EV maker globally,

707
01:13:28,600 --> 01:13:36,100
will adopt the DRIVE Orin computer for cars
starting production in the first half of 2023.

708
01:13:36,100 --> 01:13:42,400
NVIDIA’s self-driving car computer, software,
and robotics AI is essentially

709
01:13:42,400 --> 01:13:47,800
 the same computing pipeline as
next-generation medical systems.

710
01:13:47,800 --> 01:13:54,300
Let me show you what Holoscan can do for an incredible instrument called a lightsheet microscope.

711
01:13:54,300 --> 01:14:01,633
Invented by Nobel laureate Eric Betzig,
lightsheet microscopes use high-resolution fluorescence

712
01:14:01,633 --> 01:14:09,200
to create a movie of cells moving and dividing, giving researchers the ability to study biology in motion.

713
01:14:09,200 --> 01:14:22,100
The problem is that lightsheet microscopes produce 3TB
of data per hour – the equivalent of 30 4K movies.

714
01:14:22,100 --> 01:14:26,100
It takes up to a day to process the 3TB of data.

715
01:14:26,100 --> 01:14:32,000
With NVIDIA Clara Holoscan,
we can process the data in real-time.

716
01:14:34,100 --> 01:14:41,333
Now with Clara Holoscan and NVIDIA index we can
visualize the entire large volume of living cells in real time

717
01:14:41,333 --> 01:14:45,000
as the data is being recorded directly from the microscope.

718
01:14:45,000 --> 01:14:49,533
Watching these living cancer cells move about,
we can see normal healthy biology

719
01:14:49,533 --> 01:14:52,400
and maligent processes at the same time.

720
01:14:52,400 --> 01:14:59,300
The fluorescent marker rendered in blue marks nuclei,
which we see splitting to form two cells from one cell.

721
01:14:59,300 --> 01:15:06,533
A hallmark of cancer is cell division occurring more frequently and with less error checking than normal, healthy cells.

722
01:15:06,533 --> 01:15:10,733
Using Berkeley’s lattice light sheet microscope,
the ultimate-high resolution

723
01:15:10,733 --> 01:15:16,733
allows scientists to see what is hidden to normal light optics – not seen using traditional microscopes.

724
01:15:16,733 --> 01:15:23,433
As we zoom in, watch cancer cells display what is thought to be a rare event even for cancer cell lines –

725
01:15:23,433 --> 01:15:26,233
see one cell split into 3 cells.

726
01:15:26,233 --> 01:15:32,500
This phenomenon has only been reported
anecdotally in a couple of scientific publications.

727
01:15:32,500 --> 01:15:39,400
Scientists do not yet know what we will see – but this technique, enabled with real-time processing and visualization,

728
01:15:39,400 --> 01:15:44,600
now allows the scientific community
to discover new unseen events like this.

729
01:15:44,600 --> 01:15:47,400
Let’s see what the future has in store.

730
01:15:47,400 --> 01:15:52,800
Clara Holoscan is an open, scalable robotics platform.

731
01:15:52,800 --> 01:16:00,600
Clara Holoscan is designed to the
IEC-62304 medical-grade specification

732
01:16:00,600 --> 01:16:04,300
and for the highest device safety and security level.

733
01:16:04,300 --> 01:16:13,100
The amount of computation in Holoscan is insane.
The core computer is Orin and CX7, with an optional GPU.

734
01:16:13,100 --> 01:16:19,733
Holoscan development platforms are available for early
access customers today, general availability in May,

735
01:16:19,733 --> 01:16:24,400
and medical-grade readiness in Q1 2023.

736
01:16:24,400 --> 01:16:30,300
Future medical devices will be AI instruments,
assisting diagnostics or surgery.

737
01:16:30,300 --> 01:16:40,000
Just as NVIDIA DRIVE is a platform for robotic vehicles, Clara Holoscan is a platform for robotic medical instruments.

738
01:16:40,000 --> 01:16:45,833
We are delighted to see the enthusiasm around Holoscan
and to partner with leading medical device makers

739
01:16:45,833 --> 01:16:48,300
and robotic surgery companies.

740
01:16:48,300 --> 01:16:52,933
The demand for robotics and
automation is increasing exponentially.

741
01:16:52,933 --> 01:16:58,000
Some robots move, and other robots watch things that move.

742
01:16:58,000 --> 01:17:05,733
NVIDIA is working with thousands of customers and developers, building robots for manufacturing, retail, healthcare,

743
01:17:05,733 --> 01:17:10,900
agriculture, construction, airports, and entire cities.

744
01:17:10,900 --> 01:17:15,733
NVIDIA’s robotics platforms consist of Metropolis and Isaac –

745
01:17:15,733 --> 01:17:19,400
Isaac is a platform for things that move.

746
01:17:19,400 --> 01:17:24,400
Metropolis is a stationary robot tracking moving things.

747
01:17:24,400 --> 01:17:34,300
Metropolis and Isaac platforms, like DRIVE, consist of 4 pillars – Ground Truth generation, AI model training,

748
01:17:34,300 --> 01:17:40,900
Omniverse digital twin, and the robot with
robotic software and computer.

749
01:17:40,900 --> 01:17:49,500
Metropolis has been a phenomenal success – has been downloaded 300,000 times, has over 1,000 ecosystem partners,

750
01:17:49,500 --> 01:17:55,733
and operates in over a million facilities,
including USPS, Walmart,

751
01:17:55,733 --> 01:18:04,700
cities including Tel Aviv and London, the Heathrow airport, Veolia recycling plants, and the Gillette football stadium.

752
01:18:04,700 --> 01:18:13,300
And now, customers can use Omniverse to create digital twins of their facilities to drive better safety and efficiency.

753
01:18:13,300 --> 01:18:18,133
Let’s take a look at how the Pepsi company
is using Metropolis and Omniverse.

754
01:18:18,133 --> 01:18:21,600
PepsiCo’s products are enjoyed
1B times a day around the world.

755
01:18:21,600 --> 01:18:27,633
Getting this many products to their 200 regional markets requires over 600 distribution centers.

756
01:18:27,633 --> 01:18:33,400
Improving the efficiency and environmental sustainability of their supply chain is a key goal for Pepsi Co.

757
01:18:33,400 --> 01:18:37,700
To achieve this, they are building digital twins to
simulate their packaging and distribution centers

758
01:18:37,700 --> 01:18:40,400
using NVIDIA Omniverse and Metropolis.

759
01:18:40,400 --> 01:18:45,000
This allows them to test variations in layout
and optimize workflows to accelerate throughput

760
01:18:45,000 --> 01:18:47,300
before making any physical investments.

761
01:18:47,300 --> 01:18:52,333
As new products and processes are introduced, Omniverse Replicator and NVIDIA TAO can be used to create

762
01:18:52,333 --> 01:18:57,233
photorealistic synthetic data to re-train the real-time AI models.

763
01:18:57,233 --> 01:19:01,500
These updated models and optimizations
are then transferred to the physical world.

764
01:19:01,500 --> 01:19:06,500
From here, NVIDIA Metropolis applications monitor
and adjust conveyer belt speed in real-time

765
01:19:06,500 --> 01:19:12,700
using AI enabled computer vision helping prevent
congestion and downtime across miles of conveyor belts.

766
01:19:12,700 --> 01:19:17,000
What’s more, with NVIDIA Fleet Command,
all these applications can be securely deployed

767
01:19:17,000 --> 01:19:21,100
and managed across hundreds of
distribution centers from one central plane.

768
01:19:21,100 --> 01:19:27,000
By leveraging NVIDIA Omniverse, Metropolis, and Fleet Command, PepsiCo is streamlining supply chain operations,

769
01:19:27,000 --> 01:19:31,500
reducing energy usage, and advancing
their mission towards sustainability.

770
01:19:34,800 --> 01:19:41,900
One of the fastest-growing segments of robotics is AMR – autonomous mobile robots –

771
01:19:41,900 --> 01:19:45,200
essentially driverless cars for indoors.

772
01:19:45,200 --> 01:19:49,333
The speed is lower, but the environment is highly unstructured.

773
01:19:49,333 --> 01:19:53,500
There are 10’s of millions of factories, stores, and restaurants.

774
01:19:53,500 --> 01:19:59,000
And 100’s of millions of square feet of
warehouse and fulfillment centers.

775
01:19:59,000 --> 01:20:05,600
Today, we have a major release of Isaac – Isaac for AMRs.

776
01:20:05,600 --> 01:20:08,733
Let me highlight some of the key elements of the release.

777
01:20:08,733 --> 01:20:18,900
Isaac for AMRs, like the DRIVE platform, has four major pillars, each individually available, and completely open.

778
01:20:18,900 --> 01:20:28,800
New NVIDIA DeepMap for Ground Truth generation, NVIDIA AI for training models, a reference AMR robot powered by Orin,

779
01:20:28,800 --> 01:20:35,933
new gems in the Isaac robot stack,
and the new Isaac Sim on Omniverse.

780
01:20:35,933 --> 01:20:46,700
First, Isaac Nova, like DRIVE Hyperion, is a reference AMR robot system on which the entire Isaac stack is built.

781
01:20:46,700 --> 01:20:54,700
Nova has 2 cameras, 2 lidars, 8 ultrasonics,
and 4 fisheye cameras for teleoperation.

782
01:20:54,700 --> 01:21:01,500
We’re announcing Jetson Orin developer
kits are available today.

783
01:21:01,500 --> 01:21:04,700
Nova AMR will be available in Q2.

784
01:21:04,700 --> 01:21:12,033
Nova AMRs can be outfitted with NVIDIA’s new
DeepMap LIDAR mapping system so you can scan

785
01:21:12,033 --> 01:21:17,700
and reconstruct your environment for route
planning and digital twin simulations.

786
01:21:17,700 --> 01:21:27,000
Isaac robot SDK includes perception, localization,
mapping, planning, and navigation modules.

787
01:21:27,000 --> 01:21:32,633
And today we’re announcing major updates to build an AMR.

788
01:21:32,633 --> 01:21:36,500
Isaac includes gems like object and person detection,

789
01:21:36,500 --> 01:21:42,133
3D pose estimation, LIDAR and
visual SLAM localization and mapping,

790
01:21:42,133 --> 01:21:49,100
3D environment reconstruction, free space perception,
dolly docking using reinforcement learning,

791
01:21:49,100 --> 01:21:55,500
a navigation stack, integration with
NVIDIA cuOpt for real-time planning,

792
01:21:55,500 --> 01:22:00,200
and robotic arm motion planning and kinematics, and more.

793
01:22:00,200 --> 01:22:03,033
There is even an SDK for teleoperation.

794
01:22:03,033 --> 01:22:08,700
Finally, Omniverse is used to build
Isaac Replicator for synthetic data generation,

795
01:22:08,700 --> 01:22:14,400
Isaac Gym to train robots, and Isaac Sim for digital twins.

796
01:22:14,400 --> 01:22:18,600
The Isaac development flow integrates Omniverse throughout.

797
01:22:18,600 --> 01:22:23,833
Isaac Gym highlights the importance of
Omniverse’s physics simulation accuracy.

798
01:22:23,833 --> 01:22:31,133
In Isaac Gym, a new robot learns a new skill
by performing it thousands to millions of times

799
01:22:31,133 --> 01:22:33,600
using deep reinforcement learning.

800
01:22:33,600 --> 01:22:42,700
The trained AI brain is then downloaded into the physical robot. And since Omniverse is physically accurate, the robot,

801
01:22:42,700 --> 01:22:48,500
after getting its bearings,
should adopt the skills of its digital twin.

802
01:22:48,500 --> 01:22:49,800
Let’s take a look.

803
01:22:50,300 --> 01:22:55,400
Successful development, training, and testing of
complex robots for real-world applications

804
01:22:55,400 --> 01:22:59,100
demand high-fidelity simulation and accurate physics.

805
01:22:59,100 --> 01:23:06,000
Built on NVIDIA's Omniverse platform, Isaac Sim combines immersive, physically accurate, photorealistic environments

806
01:23:06,000 --> 01:23:08,700
with complex virtual robots.

807
01:23:08,700 --> 01:23:15,033
Let’s look at three very different AI-based robots being developed by our partners using Isaac Sim.

808
01:23:15,033 --> 01:23:22,800
Fraunhofer IML, a technology leader in logistics, uses NVIDIA Isaac Sim for the virtual development of Obelix—

809
01:23:22,800 --> 01:23:27,933
a highly dynamic indoor/outdoor
Autonomous Mobile Robot, or AMR.

810
01:23:27,933 --> 01:23:32,933
After importing over 5400 parts from CAD
and rigging with Omniverse PhysX,

811
01:23:32,933 --> 01:23:38,100
the virtual robot moves just as deftly in
simulation as it does in the real world.

812
01:23:38,100 --> 01:23:44,000
This not only accelerates virtual development,
but also enables scaling to larger scenarios.

813
01:23:44,000 --> 01:23:50,000
Next, Festo, well known for industrial automation,
uses Isaac Sim to develop intelligent skills

814
01:23:50,000 --> 01:23:57,300
for collaborative robots, or cobots, requiring acute awareness of their environment, human partners, and tasks.

815
01:23:57,300 --> 01:24:03,900
Festo uses Cortex, an Isaac Sim tool that
dramatically simplifies programming cobot skills.

816
01:24:03,900 --> 01:24:11,500
For perception, AI models used in this task were trained using only synthetic data generated by Isaac Replicator.

817
01:24:11,500 --> 01:24:19,233
Finally, there is Anymal, a robot dog developed by a leading robotics research group from ETH Zurich and Swiss-Mile.

818
01:24:19,233 --> 01:24:25,133
Using end-to-end GPU accelerated Reinforcement Learning, Anymal, whose feet were replaced with wheels,

819
01:24:25,133 --> 01:24:31,100
learned to 'walk' over urban terrain within minutes rather
than weeks using NVIDIA's Isaac Gym training tool.

820
01:24:31,100 --> 01:24:36,500
The locomotion policy was verified in
Isaac Sim and deployed on a real Anymal.

821
01:24:36,500 --> 01:24:41,300
This is a compelling demonstration of
simulator training for real-world-deployment.

822
01:24:41,300 --> 01:24:47,833
From training perception and policies to hardware-in-loop,
Isaac Sim is the tool to build AI-based robots

823
01:24:47,833 --> 01:24:53,000
that are born in simulation to work and play in the real-world.

824
01:24:54,100 --> 01:25:03,733
Modern fulfillment centers are evolving into technical marvels – facilities operated by humans and robots working together.

825
01:25:03,733 --> 01:25:13,033
The warehouse is also a robot, orchestrating the flow of materials and the route plans of the AMRs inside.

826
01:25:13,033 --> 01:25:16,600
Let’s look at how Amazon uses Omniverse digital twin

827
01:25:16,600 --> 01:25:21,500
to design and optimize their incredible
fulfillment center operations.

828
01:25:22,400 --> 01:25:26,900
Every day, hundreds of Amazon’s facilities
handle tens of millions of packages,

829
01:25:26,900 --> 01:25:30,800
with more than two thirds of these
customer orders handled by robots.

830
01:25:30,800 --> 01:25:36,200
To support this highly complex operation,
we deployed hundreds of thousands mobile drive robots,

831
01:25:36,200 --> 01:25:38,100
and associated storage pods,

832
01:25:38,100 --> 01:25:42,300
which allow us to store far more inventory
in our buildings than traditional shelving.

833
01:25:42,300 --> 01:25:46,500
And which help us move inventory in a safer, more efficient way.

834
01:25:46,500 --> 01:25:49,800
Key to the scaling has been our
ability to simulate these buildings

835
01:25:49,800 --> 01:25:53,133
and understand their performance before we build them.

836
01:25:53,133 --> 01:25:59,900
Let’s look at how NVIDIA Omniverse is helping us
optimize and simplify these processes.

837
01:25:59,900 --> 01:26:06,900
At Amazon Robotics, we are able create full-scale “digital twins” of our warehouses in NVIDIA Omniverse,

838
01:26:06,900 --> 01:26:14,000
helping us optimize warehouse design, train more intelligent robot assistants, and gain operational efficiencies.

839
01:26:14,000 --> 01:26:19,433
In Omniverse, we are uniquely able to aggregate
datasets from many different CAD applications

840
01:26:19,433 --> 01:26:23,133
and visualize these massive models in full-fidelity realism,

841
01:26:23,133 --> 01:26:29,700
enabled by Omniverse's RTX-accelerated
ray tracing, materials, and physics.

842
01:26:29,700 --> 01:26:33,300
Digital twins are an integral part of
future warehouses and factories,

843
01:26:33,300 --> 01:26:37,100
enabling continuous integration and continuous delivery.

844
01:26:37,100 --> 01:26:39,533
With each new software and layout optimization,

845
01:26:39,533 --> 01:26:43,433
we can test in the digital twin before
releasing to the physical warehouse,

846
01:26:43,433 --> 01:26:48,733
preventing system downtime or failure
while maximizing operational efficiencies.

847
01:26:48,733 --> 01:26:56,233
Next, packages of every shape, size, weight, and material
move rapidly through our fulfillment centers.

848
01:26:56,233 --> 01:27:02,100
We use NVIDIA Omniverse to better train
autonomous robotic sorting and picking solutions.

849
01:27:02,100 --> 01:27:07,300
Training these robots' perception systems
accurately enough to prevent system failures

850
01:27:07,300 --> 01:27:14,700
requires massive amounts of high-quality data, but often,
the data doesn't exist, or there isn't enough.

851
01:27:14,700 --> 01:27:20,500
When we introduced more reflective tape to our packing materials, the perception systems failed.

852
01:27:20,500 --> 01:27:26,233
We retrained the models with physically accurate, photoreal synthetic data generated in Omniverse -

853
01:27:26,233 --> 01:27:33,500
indistinguishable from reality - saving weeks of
retraining time and increasing model accuracy.

854
01:27:33,500 --> 01:27:40,400
Finally, with digital twins of our facilities and the ability to quickly and accurately train robot perception systems

855
01:27:40,400 --> 01:27:48,000
we can also better configure human-robot workstations, simulating opportunities for better employee ergonomics.

856
01:27:48,000 --> 01:27:54,700
At Amazon Robotics, NVIDIA Omniverse digital twins are helping us as we reimagine warehouse logistics from end-to-end;

857
01:27:54,700 --> 01:28:02,100
and capturing a significant operational efficiencies which
enable us to deliver more value to our customers.

858
01:28:04,733 --> 01:28:11,700
Just like NASA and Amazon, our customers
in robotics and industrial automation

859
01:28:11,700 --> 01:28:18,400
are realizing the importance of digital twins
and are doing amazing things in Omniverse.

860
01:28:18,400 --> 01:28:24,000
You can see how important Omniverse is
throughout NVIDIA's work in AI and robotics.

861
01:28:24,000 --> 01:28:30,533
The next wave of AI - robotic systems -
needs a platform like Omniverse.

862
01:28:30,533 --> 01:28:41,233
We want Omniverse to reach every one of the 10’s of millions of designers, creators, roboticists, and AI researchers.

863
01:28:41,233 --> 01:28:46,400
So, today, we are announcing Omniverse Cloud.

864
01:28:46,400 --> 01:28:51,500
Just a few clicks and you and your collaborators are connected.

865
01:28:51,500 --> 01:28:59,500
In this demo, you are going to see 4 designers, all working remotely, connected by Omniverse Cloud,

866
01:28:59,500 --> 01:29:02,600
and collaborating to create a virtual world.

867
01:29:02,600 --> 01:29:05,533
Let’s take a look at how easy it works.

868
01:29:06,733 --> 01:29:13,500
3D design is a complex team sport, with different artists, apps and hardware, often working in different locations.

869
01:29:13,500 --> 01:29:16,900
With Omniverse Cloud, it’s much easier.

870
01:29:16,900 --> 01:29:23,133
Using NVIDIA RTX PCs, laptops, and workstations,
designers can work together in real-time.

871
01:29:23,133 --> 01:29:29,800
And if you don’t have an RTX computer, you can stream Omniverse from GeForce Now with just a single click.

872
01:29:29,800 --> 01:29:35,300
Let's watch as an architectural design team reviews a project using Omniverse View in a web conference.

873
01:29:36,100 --> 01:29:38,700
Alright, right here is the 5th floor patio.

874
01:29:39,200 --> 01:29:43,433
To get a better feel for the lighting,
let’s see what this space looks like at noon.

875
01:29:43,900 --> 01:29:45,433
Sure!

876
01:29:48,433 --> 01:29:53,400
Hmm... it’s a little sunny.
Let’s make some adjustments to the trellis.

877
01:29:53,400 --> 01:29:54,733
One sec…

878
01:29:55,733 --> 01:29:56,800
How’s that?

879
01:29:56,800 --> 01:29:59,700
Much better, let’s see if we can get Teresa on.

880
01:29:59,700 --> 01:30:03,100
Yep, sending that link now.

881
01:30:04,800 --> 01:30:05,833
Hey you two!

882
01:30:05,833 --> 01:30:12,133
Hi! So we did a sun study at mid-day and decided
it needed more shade. What do you think?

883
01:30:12,133 --> 01:30:16,033
Yeah that looks great but I still feel like it needs a little more.

884
01:30:16,033 --> 01:30:18,233
What if we add some trees?

885
01:30:18,233 --> 01:30:20,733
Yeah, let’s get TJ to help with that.

886
01:30:21,133 --> 01:30:23,000
Hi, how can I help?

887
01:30:23,000 --> 01:30:28,033
Hey TJ, can you add some medium-sized
trees in planters near the tables?

888
01:30:28,400 --> 01:30:30,800
Sure, let me add that for you.

889
01:30:31,400 --> 01:30:32,800
How does this look?

890
01:30:32,800 --> 01:30:38,500
Nice!... but TJ can we vary the trees, say size and type?

891
01:30:38,500 --> 01:30:40,033
OK, here you go.

892
01:30:40,733 --> 01:30:43,933
Hey TJ, let's go to the bar
and see what it looks like at night.

893
01:30:43,933 --> 01:30:45,600
You got it!

894
01:30:47,100 --> 01:30:48,400
Yeah, that looks great.

895
01:30:48,400 --> 01:30:51,500
I’ll send the link out for approval.

896
01:30:56,200 --> 01:30:58,333
See you in Omniverse.

897
01:30:59,666 --> 01:31:04,066
You may have noticed one of the designers is an AI.

898
01:31:04,066 --> 01:31:10,666
As AIs develop skills, we will not only invite them
to help us design buildings and factories,

899
01:31:10,666 --> 01:31:17,366
but also take orders at restaurants, help customers,
and even answer questions about our health.

900
01:31:17,366 --> 01:31:21,066
Omniverse, for the next wave of AI.

901
01:31:21,066 --> 01:31:25,700
We covered a lot of ground so let me do a fast recap.

902
01:31:25,700 --> 01:31:29,700
We announced new products across NVIDIA’s four-layer stack:

903
01:31:29,700 --> 01:31:34,866
hardware, system software and libraries, software platforms

904
01:31:34,866 --> 01:31:43,900
NVIDIA HPC, NVIDIA AI, and NVIDIA Omniverse;
and AI and robotics application frameworks.

905
01:31:43,900 --> 01:31:52,300
These are driving five dynamics shaping our industry - Million-X computing speed-up, Transformers turbocharging AI,

906
01:31:52,300 --> 01:31:58,866
data centers becoming AI Factories,
exponentially increasing demand for robotics systems,

907
01:31:58,866 --> 01:32:02,866
and digital twins for the next era of AI.

908
01:32:02,866 --> 01:32:06,366
Four layers, five dynamics.

909
01:32:06,366 --> 01:32:13,900
NVIDIA accelerated computing, full-stack engineering at data center scale, has sped-up computing by a Million-X.

910
01:32:13,900 --> 01:32:20,900
A Million-X opens the opportunities to tackle grand challenges, like drug discovery and climate science.

911
01:32:20,900 --> 01:32:26,966
And with the invention of self-learning Transformers,
AI jumped to warp speed.

912
01:32:26,966 --> 01:32:33,066
AI has fundamentally changed what software
can make and how you make software.

913
01:32:33,066 --> 01:32:42,400
Companies build AI by processing and refining data to manufacture intelligence - their data centers are AI factories.

914
01:32:42,400 --> 01:32:47,666
NVIDIA H100 is the new engine of the world’s AI infrastructure.

915
01:32:47,666 --> 01:32:57,700
NVIDIA’s NVLINK Switch system connects up to 32 DGXs into a massive 1 exaflops building block of the AI factory.

916
01:32:57,700 --> 01:33:06,766
Hopper H100 is the biggest generational leap ever - 9 times at-scale training performance over A100

917
01:33:06,766 --> 01:33:11,200
and 30 times large-language-model inference throughput.

918
01:33:11,200 --> 01:33:14,866
Hopper also accelerates mainstream servers.

919
01:33:14,866 --> 01:33:20,966
NVIDIA H100 CNX connects the
network directly into H100

920
01:33:20,966 --> 01:33:25,266
through the most advanced networking chip – NVIDIA CX7.

921
01:33:25,266 --> 01:33:31,466
NVIDIA H100, the engine of the world’s AI infrastructures.

922
01:33:31,466 --> 01:33:36,566
H100 is in production, with availability starting in Q3.

923
01:33:36,566 --> 01:33:39,400
Grace is on track for production next year.

924
01:33:39,400 --> 01:33:46,266
Grace is an amazing superchip –
two CPUs connected over a 900 gigabytes per second

925
01:33:46,266 --> 01:33:58,766
NVLINK chip-to-chip interconnect to make a 144-core CPU
with 1 terabytes per second of memory bandwidth.

926
01:33:58,766 --> 01:34:03,966
Grace is the ideal CPU for the world’s AI infrastructures.

927
01:34:03,966 --> 01:34:10,766
NVLINK now spans die-to-die,
chip-to-chip, and system-to-system,

928
01:34:10,766 --> 01:34:15,066
and gives us a multitude of
Grace-Hopper system configurations–

929
01:34:15,066 --> 01:34:21,400
from dual-Grace, to one-Grace one-Hopper,
to dual-Grace and eight Hoppers.

930
01:34:21,400 --> 01:34:29,366
NVLINK will be coming to all future NVIDIA chips –
CPUs, GPUs, DPUs, and SOCs.

931
01:34:29,366 --> 01:34:35,466
We will also make NVLINK available to customers
and partners to build companion chips.

932
01:34:35,466 --> 01:34:42,500
NVLINK opens a new world of opportunities for
customers to build semi-custom chips and systems

933
01:34:42,500 --> 01:34:46,500
that leverage NVIDIA’s platforms and ecosystems.

934
01:34:46,500 --> 01:34:53,466
NVIDIA AI platform, used by over 25,000 companies worldwide, got major updates.

935
01:34:53,466 --> 01:35:02,766
NVIDIA Omniverse is a platform for virtual worlds, digital twins, and robotic systems - the next wave of AI.

936
01:35:02,766 --> 01:35:08,100
Just as Tensorflow and PyTorch are essential
frameworks for perception-oriented AI,

937
01:35:08,100 --> 01:35:12,366
Omniverse will be integral for action-oriented AI.

938
01:35:12,366 --> 01:35:20,566
And as DGX is the infrastructure of AI factories,
OVX will be the infrastructure of digital twins.

939
01:35:20,566 --> 01:35:27,866
OVX runs Omniverse digital twins for large-scale
simulations with multiple autonomous systems

940
01:35:27,866 --> 01:35:30,000
operating in the same space-time.

941
01:35:30,000 --> 01:35:34,366
The backbone of OVX is its networking fabric.

942
01:35:34,366 --> 01:35:40,600
We announced NVIDIA Spectrum-4
51.2 terabits per second switch,

943
01:35:40,600 --> 01:35:49,166
and with CX7 and Bluefield-3, will be the first end-to-end 400 gigabytes per second networking platform.

944
01:35:49,166 --> 01:35:52,066
Spectrum-4 will sample in Q3.

945
01:35:52,066 --> 01:35:57,500
The next wave of AI is robotic systems that
perceive, plan, and act.

946
01:35:57,500 --> 01:36:07,466
NVIDIA Avatar, Drive, Metropolis, Isaac, and Holoscan are robotics platforms built end-to-end and full-stack

947
01:36:07,466 --> 01:36:16,900
around four pillars – ground truth data generation, AI model training, the robotic stack, and Omniverse digital twin.

948
01:36:16,900 --> 01:36:21,200
The platforms are open for developers
to adopt in part or in whole.

949
01:36:21,200 --> 01:36:24,466
Omniverse is central to our robotics platforms.

950
01:36:24,466 --> 01:36:30,300
And like NASA and Amazon, we and our
customers in robotics and industrial automation

951
01:36:30,300 --> 01:36:33,666
realize the importance of digital twins and Omniverse.

952
01:36:33,666 --> 01:36:36,166
Drive Orin is in full production.

953
01:36:36,166 --> 01:36:38,966
 Issac Orin developer kits are available now.

954
01:36:38,966 --> 01:36:42,466
Clara Holoscan devkits are available in May.

955
01:36:42,466 --> 01:36:45,600
We updated 60 SDKs at this GTC.

956
01:36:45,600 --> 01:36:48,966
For our three million developers, scientists, and AI researchers,

957
01:36:48,966 --> 01:36:51,900
and 10’s of thousands of startups and enterprises,

958
01:36:51,900 --> 01:36:56,666
the same NVIDIA systems you run just got faster.

959
01:36:56,666 --> 01:37:05,366
NVIDIA SDKs serve healthcare, energy, transportation, retail, finance, media, and entertainment –

960
01:37:05,366 --> 01:37:09,266
a combined $100 trillion of industries.

961
01:37:09,266 --> 01:37:13,666
Accelerating across the full-stack and at data center scale,

962
01:37:13,666 --> 01:37:17,766
we will strive for yet another Million-X in the next decade.

963
01:37:17,766 --> 01:37:21,266
I can’t wait to see what the next Million-X brings.

964
01:37:21,266 --> 01:37:28,200
I want to thank NVIDIA developers,
partners, customers, and the NVIDIA families

965
01:37:28,200 --> 01:37:32,100
for the amazing work you do to shape the world.

966
01:37:32,100 --> 01:37:39,700
But don’t leave just yet. Omniverse generated
every rendering and simulation you saw today.

967
01:37:39,700 --> 01:37:47,066
NVIDIA’s amazing creative team would like to take
you on one more trip into Omniverse.

968
01:37:47,066 --> 01:37:49,000
Engage.

