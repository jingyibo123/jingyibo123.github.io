1
00:00:01,800 --> 00:00:03,800
即将到达目的地

2
00:00:31,600 --> 00:00:34,800
您好！欢迎来到 NVIDIA

3
00:01:41,500 --> 00:01:43,700
欢迎来到 GTC！

4
00:01:43,700 --> 00:01:46,300
希望大家一切顺利

5
00:01:46,300 --> 00:01:50,700
今天我们将为您带来重要的发布和酷炫的内容

6
00:01:50,700 --> 00:01:55,300
首先还是请您与我一同观看新出炉的 I AM AI

7
00:01:55,300 --> 00:02:03,800
这是 NVIDIA 创意团队的热情之作，精彩地讲述了您富有影响力的工作

8
00:02:30,300 --> 00:02:34,500
我是远见者

9
00:02:36,700 --> 00:02:42,500
拓展人类对小到细微粒子

10
00:02:46,400 --> 00:02:50,800
大到无垠宇宙的理解

11
00:02:57,700 --> 00:03:00,500
我是守护者

12
00:03:01,600 --> 00:03:05,600
一路为人们保驾护航

13
00:03:09,400 --> 00:03:13,100
护送最珍贵的乘客

14
00:03:15,200 --> 00:03:17,500
安全到家

15
00:03:20,300 --> 00:03:23,700
我是治疗者

16
00:03:23,700 --> 00:03:29,700
搜寻隐藏在每个细胞中的潜在威胁

17
00:03:35,000 --> 00:03:41,400
为每一次呼吸提供精准的守护

18
00:03:43,100 --> 00:03:46,400
我是助力者

19
00:03:48,300 --> 00:03:51,800
在极具挑战的环境中执行

20
00:03:53,900 --> 00:03:57,300
复杂的任务

21
00:03:59,000 --> 00:04:03,100
为农作物提供生长空间

22
00:04:06,600 --> 00:04:09,300
我是创造者

23
00:04:09,300 --> 00:04:15,300
重新编织日常生活的每个细微之处

24
00:04:15,300 --> 00:04:23,000
运用大师充满创意的 DNA 去激发新一代艺术创作

25
00:04:24,900 --> 00:04:28,000
我是学习者

26
00:04:28,600 --> 00:04:38,400
只需几分钟即可了解如何爬行、走路以及站立

27
00:04:39,500 --> 00:04:42,100
我是讲述者

28
00:04:43,000 --> 00:04:46,400
为字句赋予情感

29
00:04:48,700 --> 00:04:53,000
为语言破除障碍

30
00:04:53,000 --> 00:04:58,100
我还是这段音乐的作曲人

31
00:05:06,100 --> 00:05:09,100
我是 AI

32
00:05:09,100 --> 00:05:18,400
由 NVIDIA、深度学习及无所不在的人类智慧联手打造

33
00:05:25,100 --> 00:05:30,400
如今，医生只需要几个小时就可以完成人类 DNA 的测序工作

34
00:05:30,400 --> 00:05:36,200
并根据氨基酸序列预测 DNA 的三维结构

35
00:05:36,200 --> 00:05:39,600
研究人员可以使用计算机来生成新的候选药物

36
00:05:39,600 --> 00:05:44,000
并且通过计算机，完成新药物对目标疾病的疗效测试

37
00:05:44,000 --> 00:05:50,600
AI 正在学习生物学和化学，正如 AI 已经学习了理解图像、声音和语言

38
00:05:50,600 --> 00:05:56,300
在 AI 进入计算机领域后，药物研发领域也将迎来一场新的革命

39
00:05:56,300 --> 00:05:59,700
正如我们在其他受 AI 影响的领域所见证的一样

40
00:05:59,700 --> 00:06:04,600
这些功能在十年前是遥不可及的

41
00:06:04,600 --> 00:06:15,600
数据中心规模的加速计算与机器学习相结合，可以将计算速度提高百万倍

42
00:06:15,600 --> 00:06:21,200
加速计算已经使像 Transformer 这样的革命性 AI 模型

43
00:06:21,200 --> 00:06:24,400
和自监督学习成为可能

44
00:06:24,400 --> 00:06:30,600
AI 已从根本上改变了软件的能力以及开发软件的方式

45
00:06:30,600 --> 00:06:38,900
各公司都在处理和完善自己的数据、开发 AI 软件并使自己成为智能的生产商

46
00:06:38,900 --> 00:06:43,100
他们的数据中心正在逐步演变为 AI 工厂

47
00:06:43,100 --> 00:06:49,900
第一波 AI 学习的是感知和推理，例如图像识别、语音理解

48
00:06:49,900 --> 00:06:53,400
推荐视频或者商品

49
00:06:53,400 --> 00:06:59,500
下一波 AI 的发展方向是机器人，也就是使用 AI 规划行动

50
00:06:59,500 --> 00:07:06,600
数字机器人、虚拟形象和实体机器人将完成感知、规划并采取行动

51
00:07:06,600 --> 00:07:12,200
如同 TensorFlow 和 PyTorch 等 AI 框架已经成为 AI 软件中不可或缺的一部分

52
00:07:12,200 --> 00:07:20,400
Omniverse 也将成为制作机器人软件时必不可少的工具。Omniverse 将掀起一波新的 AI 浪潮

53
00:07:20,400 --> 00:07:26,400
在本届 GTC 大会上，我们将探讨下一个百万倍加速，以及其他塑造我们所在行业的动态

54
00:07:26,400 --> 00:07:33,100
在过去十年中，NVIDIA 加速计算在 AI 领域中实现了百万倍的加速

55
00:07:33,100 --> 00:07:36,700
并引发了现代 AI 革命

56
00:07:36,700 --> 00:07:40,200
如今，AI 将会为所有行业带来翻天覆地的变化

57
00:07:40,200 --> 00:07:46,000
这些 CUDA 库和 NVIDIA SDK 是加速计算的核心

58
00:07:46,000 --> 00:07:55,900
伴随着每一个新的 SDK，新的科学领域、新的应用和行业都可以利用到 NVIDIA 强大的计算能力

59
00:07:55,900 --> 00:08:04,300
这些 SDK 解决了计算、算法和科学交叉领域中极其复杂的问题

60
00:08:04,300 --> 00:08:10,800
NVIDIA 的全栈方法产生的复合效应，实现了百万倍的加速

61
00:08:10,800 --> 00:08:17,800
如今，NVIDIA 帮助数百万开发者以及数以万计的成熟公司和初创企业实现了飞速发展

62
00:08:17,800 --> 00:08:21,100
GTC 大会是你们所有人的盛会

63
00:08:21,100 --> 00:08:28,400
当看到领先的计算机科学家、AI 研究人员、机器人专家和自动驾驶汽车设计师
在 GTC 上展示他们的成果时

64
00:08:28,400 --> 00:08:31,000
我们总会倍受鼓舞

65
00:08:31,000 --> 00:08:38,600
从新加入的与会者和演讲中，我们可以看到 AI 和加速计算的覆盖范围和影响正在不断扩大

66
00:08:38,600 --> 00:08:47,200
今年，我们看到了百思买、家得宝、沃尔玛、克罗格和劳氏公司如何使用 AI 来进行工作

67
00:08:47,200 --> 00:08:55,500
LinkedIn、Snap、Salesforce、DoorDash、Pinterest、ServiceNow、美国运通和 Visa

68
00:08:55,500 --> 00:08:58,100
将分享大规模使用 AI 的经验

69
00:08:58,100 --> 00:09:06,000
在这里你同样能够看到医疗健康公司葛兰素史克、阿斯利康、默克、百时美施贵宝

70
00:09:06,000 --> 00:09:10,000
梅奥医院、麦克森和礼来的演讲

71
00:09:10,000 --> 00:09:13,900
2022 年 GTC 大会将会非常精彩

72
00:09:13,900 --> 00:09:17,100
GPU 使 AI 发生了革命性的转变

73
00:09:17,100 --> 00:09:23,100
现在，基于 GPU 的 AI 正在革新各个行业和科学领域

74
00:09:23,100 --> 00:09:27,200
其中对人类最有影响力之一的便是气候科学

75
00:09:27,200 --> 00:09:34,000
科学家们预测，要想有效地模拟区域气候变化

76
00:09:34,000 --> 00:09:38,000
需要一台比现在大十亿倍的超级计算机

77
00:09:38,000 --> 00:09:42,800
但我们现在就必须对工业决策的影响

78
00:09:42,800 --> 00:09:47,000
以及减缓和适应策略的有效性作出预测

79
00:09:47,000 --> 00:09:55,600
NVIDIA 将使用我们的首台 AI 数字孪生超级计算机 Earth-2 来应对这一巨大挑战

80
00:09:55,600 --> 00:10:04,400
通过发明新的 AI 和计算技术，来让我们获得十亿倍的算力支持，并及时采取行动

81
00:10:04,400 --> 00:10:07,500
早期的证据表明我们能够成功

82
00:10:07,500 --> 00:10:14,100
来自 NVIDIA、加州理工学院、伯克利实验室、普渡大学、密歇根大学和莱斯大学的研究人员

83
00:10:14,100 --> 00:10:19,300
开发了一个名为 FourCastNet 的天气预报 AI 模型

84
00:10:19,300 --> 00:10:25,800
FourCastNet 是一种基于物理信息的深度学习模型，可以预测飓风

85
00:10:25,800 --> 00:10:28,800
大气河以及极端降水等天气事件

86
00:10:28,800 --> 00:10:37,800
FourCastNet 以欧洲中期天气预报中心 (ECMWF) 长达 40 年的模拟增强型真值数据为基础

87
00:10:37,800 --> 00:10:41,400
学会了如何预测天气

88
00:10:41,400 --> 00:10:48,700
深度学习模型首次在降水预测方面达到了比先进的数值模型更高的准确率和技能

89
00:10:48,700 --> 00:10:58,100
并使预测速度提高了 4 到 5 个数量级

90
00:10:58,100 --> 00:11:03,100
也就是说传统的数值模拟需要一年的时间，而现在只需要几分钟

91
00:11:03,100 --> 00:11:11,200
大气河是天空中巨大的水汽河流，每条河流的水量都比亚马逊河的还要多

92
00:11:11,200 --> 00:11:19,000
它们一方面为美国西部提供了关键的降水来源，但另一方面，这些巨大的强风暴也会导致

93
00:11:19,000 --> 00:11:22,300
灾难性的洪灾和暴雪

94
00:11:22,300 --> 00:11:28,300
NVIDIA 创建了 Physics-ML 模型，该模型可以模拟全球天气模式的动态变化

95
00:11:28,300 --> 00:11:35,400
以超乎想象的速度和准确性预测大气河等极端天气事件

96
00:11:35,400 --> 00:11:43,100
此 GPU 加速的 AI 数字孪生模型名为 FourCastNet，由傅里叶神经算子提供动力支持

97
00:11:43,100 --> 00:11:46,800
基于 10 TB 的地球系统数据进行训练

98
00:11:46,800 --> 00:11:53,900
依托这些数据，以及 NVIDIA Modulus 和 Omniverse，我们能够提前一周预测

99
00:11:53,900 --> 00:11:58,400
灾难性大气河的精确路线

100
00:11:58,400 --> 00:12:03,700
在一个 NVIDIA GPU 的助力下，FourCastNet 只需几分之一秒即可完成预测

101
00:12:03,700 --> 00:12:10,900
凭借如此快的速度，我们可以生成数千个模拟场景，探索所有可能的结果

102
00:12:10,900 --> 00:12:18,000
与以往相比，我们能够更加自信地量化灾难性洪灾的风险

103
00:12:18,600 --> 00:12:25,700
NVIDIA 是加速计算的先驱，这个领域需要全栈专业知识

104
00:12:25,700 --> 00:12:32,200
类似于一个计算堆栈或神经网络，我们从四个层级来构建 NVIDIA：

105
00:12:32,200 --> 00:12:38,900
硬件、系统软件、平台软件和应用

106
00:12:38,900 --> 00:12:43,300
每一层都对计算机制造商、服务提供商和开发者开放

107
00:12:43,300 --> 00:12:46,800
让他们以更适合的方式集成到其产品当中

108
00:12:46,800 --> 00:12:50,200
今天，我将在每一层级都宣布对应的新产品

109
00:12:50,200 --> 00:12:51,500
让我们开始吧

110
00:12:52,000 --> 00:12:55,600
AI 的进步令人惊叹

111
00:12:55,600 --> 00:13:02,600
Transformer 模型开启了自监督学习，并解除了人工标记数据的需求

112
00:13:02,600 --> 00:13:06,400
因此我们可以使用庞大的训练集来训练 Transformer 模型

113
00:13:06,400 --> 00:13:10,400
学习更充分且可靠的特征

114
00:13:10,400 --> 00:13:17,500
得益于 Transformer，模型和数据的规模皆已扩大增长，而模型技能和准确性也因此快速提升

115
00:13:17,500 --> 00:13:24,500
用于语言理解的 Google BERT，用于药物研发的 NVIDIA MegaMolBart，以及 DeepMind 的 AlphaFold

116
00:13:24,500 --> 00:13:27,400
都是基于 Transformer 模型的突破性成果

117
00:13:27,400 --> 00:13:34,700
Transformer 让自监督学习成为可能，也令 AI 飞速发展

118
00:13:34,700 --> 00:13:42,300
自然语言理解模型可以从大量的文本中学习，无需监督

119
00:13:42,300 --> 00:13:47,400
然后通过少量的人工标记数据来进行细化

120
00:13:47,400 --> 00:13:55,900
以发展其在翻译、问答、摘要、写作等方面的优秀技能

121
00:13:55,900 --> 00:14:03,300
具备语言监督的多模态学习已为计算机视觉开拓了新维度

122
00:14:03,300 --> 00:14:11,500
像 NVIDIA NVCell 这样的强化学习模型正在执行芯片布局，其也就表示 AI 正在构建芯片

123
00:14:11,500 --> 00:14:18,600
如同 FourCastNet 和 Orbnet，Physics-ML 模型也正在学习物理学和量子物理学

124
00:14:18,600 --> 00:14:23,000
这些是取得重大科学突破的首要条件

125
00:14:23,000 --> 00:14:28,000
生成模型正在改变创意设计、帮助构建虚拟世界

126
00:14:28,000 --> 00:14:31,300
并将革新通信方式

127
00:14:31,300 --> 00:14:37,800
如同 NeRF，从 2D 图像中学习 3D 表征的神经图形网络

128
00:14:37,800 --> 00:14:42,500
将扩大摄影应用场景，并帮助我们创造属于我们世界的数字孪生

129
00:14:42,500 --> 00:14:52,700
AI 正在各个方向加速发展，包括新的架构、新的学习策略、更大和更可靠的模型

130
00:14:52,700 --> 00:14:58,400
新的科学、新的应用、新的行业，所有这些都在同时进行

131
00:14:58,400 --> 00:15:00,200
接下来我展示一个令人惊叹的示例

132
00:15:00,200 --> 00:15:06,600
这个 AI 驱动的动画角色是基于物理规则的强化学习模型制作的

133
00:15:06,600 --> 00:15:07,800
一起来看一下

134
00:15:09,500 --> 00:15:16,600
我们正在利用强化学习开发更加栩栩如生、反应灵敏的物理模拟角色

135
00:15:16,600 --> 00:15:21,300
我们的角色通过模仿人类的动作数据，来学习执行逼真的动作

136
00:15:21,300 --> 00:15:24,600
例如行走、跑动和挥剑

137
00:15:24,600 --> 00:15:29,500
我们的角色在模拟环境中经过了长达 10 年的强化训练

138
00:15:29,500 --> 00:15:36,200
借助 NVIDIA GPU 驱动的大规模并行模拟器，这种训练在真实世界中只需花费 3 天即可完成

139
00:15:36,200 --> 00:15:40,400
这些虚拟角色随后会学习执行各种运动技能

140
00:15:40,400 --> 00:15:46,600
经过训练的虚拟角色可以利用这些技能来执行更复杂的任务

141
00:15:46,600 --> 00:15:51,000
现在，一个训练过的虚拟角色正跑向目标对象并将其击倒

142
00:15:51,000 --> 00:15:56,500
我们还可以引导它沿着不同的方向行走，就像您操控游戏角色那样

143
00:15:56,500 --> 00:16:03,600
基于我们的模型，虚拟角色可以在新环境中自动生成自然而连贯的行为

144
00:16:03,600 --> 00:16:07,700
我们还可以使用自然语言控制它

145
00:16:07,700 --> 00:16:13,600
例如，我们可以指示角色进行盾击或者挥剑

146
00:16:14,500 --> 00:16:19,000
我们希望这项技术最终能让基于虚拟角色的动画制作

147
00:16:19,000 --> 00:16:22,800
变得简单、流畅，就像和真实演员说话一样

148
00:16:25,000 --> 00:16:32,000
NVIDIA AI 是驱动这些创新的引擎，我们正在全力推动该平台的发展

149
00:16:32,000 --> 00:16:37,500
解决新问题，使其得到更广泛的应用，让 AI 触手可及

150
00:16:37,500 --> 00:16:47,300
NVIDIA AI 是一套涵盖整个 AI 工作流程的库，从数据处理和 ETL 特征工程

151
00:16:47,300 --> 00:16:54,700
到图形、经典机器学习、深度学习模型训练及大规模推理

152
00:16:54,700 --> 00:17:03,000
NVIDIA DALI、RAPIDS、cuDNN、Triton 和 Magnum IO 是其中最热门的库

153
00:17:03,000 --> 00:17:08,900
我们使用这些库来创建专用 AI 框架，包括先进的预训练模型

154
00:17:08,900 --> 00:17:12,099
和数据管道，使其易于横向扩展

155
00:17:12,099 --> 00:17:15,799
我们先了解一下 GTC 大会的更新内容

156
00:17:15,800 --> 00:17:22,300
网上交互每天多达数千亿，例如搜索、购物和社交

157
00:17:22,300 --> 00:17:25,900
产生了数万亿的机器学习模型推理

158
00:17:25,900 --> 00:17:35,100
NVIDIA Triton 是一款开源的、超大规模的模型推理服务器，是 AI 部署的“中央车站”

159
00:17:35,100 --> 00:17:41,400
Triton 支持在每一代 NVIDIA GPU、x86 和 Arm CPU 上部署模型

160
00:17:41,400 --> 00:17:46,400
并具备支持 AWS Inferentia 等加速器的接口

161
00:17:46,400 --> 00:17:53,900
Triton 支持各类模型：CNN、RNN、Transformer、GNN、决策树，还支持各类框架：

162
00:17:53,900 --> 00:17:58,300
TensorFlow、PyTorch、Python、ONNX、XGBoost

163
00:17:58,300 --> 00:18:05,000
Triton 支持各类查询类型：实时、离线、批处理，或串流视频和音频

164
00:18:05,000 --> 00:18:15,700
Triton 支持各类机器学习平台：
AWS，Azure，Google，阿里巴巴，VMWare，Domino Data Lab，OctoML 等

165
00:18:15,700 --> 00:18:22,100
Triton 可以在各个地方运行：云、本地、边缘或嵌入式设备

166
00:18:22,100 --> 00:18:25,500
Amazon Shopping 正在使用 Triton 进行实时拼写检查

167
00:18:25,500 --> 00:18:29,500
而微软正藉由 Triton 为翻译服务提供支持

168
00:18:29,500 --> 00:18:35,200
Triton 已被 25000 位客户下载超过 100 万次

169
00:18:35,200 --> 00:18:41,900
NVIDIA Riva 是一种先进且基于深度学习的端到端语音 AI

170
00:18:41,900 --> 00:18:43,600
Riva 可以自定义调整优化

171
00:18:43,600 --> 00:18:50,200
Riva 已经过预训练，具有世界一流的识别率，客户可以使用定制数据调优

172
00:18:50,200 --> 00:18:54,300
使其学习行业，国家和地区，或公司的特定话术

173
00:18:54,300 --> 00:18:58,600
Riva 是对话式 AI 服务的理想选择

174
00:18:58,600 --> 00:19:04,800
Snap、RingCentral、Kore.ai 等众多公司都在使用 Riva

175
00:19:04,800 --> 00:19:08,600
今天，我们正式宣布 Riva 全面发行

176
00:19:08,600 --> 00:19:15,900
2.0 版的 Riva 支持识别 7 种语言，可将神经文本转换为不同性别发声的语音

177
00:19:15,900 --> 00:19:19,800
并可以通过我们的 TAO 迁移学习工具包进行自定义调优

178
00:19:19,800 --> 00:19:26,100
Riva 可以在各类云上运行，也可以在各类有 NVIDIA GPU 的地方运行，几乎无所不在

179
00:19:26,100 --> 00:19:33,000
Maxine 是集合最先进 AI 算法的 SDK，它为重塑通讯方式而生

180
00:19:33,000 --> 00:19:40,400
视频会议系统需要对图像和声音进行编码、传输和解码操作

181
00:19:40,400 --> 00:19:47,800
计算机视觉将取代传统图像编码，而计算机图形将取代传统图像解码

182
00:19:47,800 --> 00:19:54,800
语音识别将取代传统音频编码，并且语音合成将取代传统音频解码

183
00:19:56,400 --> 00:20:02,500
在 AT&T 在纽约世博会上演示了可视电话之后的 55 年后

184
00:20:02,500 --> 00:20:05,900
AI 将为视频会议带来革新

185
00:20:05,900 --> 00:20:11,300
远程工作将常态化。我们对虚拟实时交互的需求已远超从前

186
00:20:11,300 --> 00:20:19,900
Maxine 是一个 AI 模型工具包，开发者可以使用它来重塑通信和协作方式

187
00:20:19,900 --> 00:20:22,600
Maxine 目前已拥有 30 个模型

188
00:20:22,600 --> 00:20:30,300
本次 GTC 发布的版本增加了用于回声消除和音频超分辨率的新模型

189
00:20:30,300 --> 00:20:32,400
我们来看看 Maxine 可以做什么

190
00:20:32,400 --> 00:20:37,900
NVIDIA Maxine 利用 AI 的强大功能重塑了实时视频通信

191
00:20:37,900 --> 00:20:44,600
借助 Maxine，我们现在可以更好地倾听和看到彼此，增加包容感和亲密度

192
00:20:44,600 --> 00:20:47,400
即使不同语言是障碍

193
00:20:47,400 --> 00:20:53,600
为了与观众保持互动，Maxine 可以帮我与会议上的所有人保持眼神交流

194
00:20:53,600 --> 00:20:58,700
不管是面对一个人，还是一百个人；即使我正在读稿

195
00:20:58,700 --> 00:21:02,800
如何借助 Maxine 克服语言障碍？

196
00:21:02,800 --> 00:21:07,000
虽然我不会说西班牙语，但借助 Maxine，我现在可以了

197
00:21:08,500 --> 00:21:11,433
现在，我可以用自己的声音说出您的语言。还不错吧？

198
00:21:11,433 --> 00:21:13,200
现在，我可以用自己的声音说出您的语言。还不错吧？

199
00:21:13,200 --> 00:21:14,700
太出色了

200
00:21:14,700 --> 00:21:19,200
太棒了。但是，Maxine 能否翻译多种语言呢？

201
00:21:19,200 --> 00:21:21,800
当然可以

202
00:21:22,900 --> 00:21:26,500
借助 Maxine，我还可以讲法语

203
00:21:26,500 --> 00:21:28,700
还有更多语言

204
00:21:30,400 --> 00:21:33,300
下次 GTC 时

205
00:21:33,300 --> 00:21:36,233
我们将向您介绍 Maxine 更多强大的功能

206
00:21:36,566 --> 00:21:38,700
请持续关注，以免错过精彩内容

207
00:21:38,700 --> 00:21:41,400
非常棒！我将会出席

208
00:21:44,100 --> 00:21:47,200
推荐系统是个性化引擎

209
00:21:47,200 --> 00:21:55,300
互联网上有着上万亿的内容并且日新月异，例如新闻、社交视频、新产品信息等

210
00:21:55,300 --> 00:21:58,100
我们怎么能够从这些海量信息中找到需要的内容呢？

211
00:21:58,100 --> 00:22:04,000
推荐系统学习物品的特征、您的显性或隐形偏好

212
00:22:04,000 --> 00:22:09,800
然后为您推荐可能感兴趣的内容，这就是个性化互联网

213
00:22:09,800 --> 00:22:16,200
先进的推荐引擎推动着全球消费互联网服务的发展

214
00:22:16,200 --> 00:22:23,100
未来，它还将推动金融服务、医疗健康服务、旅游等行业的发展

215
00:22:23,100 --> 00:22:28,400
NVIDIA Merlin 是用于推荐系统的 AI 框架

216
00:22:28,400 --> 00:22:33,300
Merlin 由推荐系统流程的端到端组件组成

217
00:22:33,300 --> 00:22:37,900
包括特征转换、召回和模型排序

218
00:22:37,900 --> 00:22:46,500
通过 NVIDIA Merlin，公司可以快速构建、部署和扩展先进的深度学习推荐系统

219
00:22:46,500 --> 00:22:53,000
Snap 使用 Merlin 来改善广告和内容推荐，在降低 50% 成本的同时

220
00:22:53,000 --> 00:22:56,900
服务延迟也缩短了一半

221
00:22:56,900 --> 00:23:06,800
腾讯微信基于 Merlin 将短视频推荐延迟缩短为原来的四分之一，并将吞吐量提升了十倍

222
00:23:06,800 --> 00:23:11,100
从 CPU 迁移到 GPU，腾讯在该业务上的成本减少了一半

223
00:23:11,100 --> 00:23:18,200
在这次 GTC，我们将正式发布 Merlin 的 1.0 版本

224
00:23:18,200 --> 00:23:22,500
Transformer 彻底革新了自然语言处理

225
00:23:22,500 --> 00:23:29,300
训练大型语言模型需要极大的勇气，因为这是一项巨大的计算机科学挑战

226
00:23:29,300 --> 00:23:39,200
OpenAI 的 GPT-3 有 1750 亿个参数。NVIDIA Megatron 有 5300 亿个

227
00:23:39,200 --> 00:23:45,000
Google 的新版 Switch Transformer 有 1.6 万亿个参数

228
00:23:45,000 --> 00:23:54,300
Nemo Megatron 是一款专门用于训练大型语言模型的 AI 框架，其支持的参数规模可高达数万亿

229
00:23:54,300 --> 00:24:01,600
为了在目标基础架构上实现最佳性能，Nemo Megatron 可以自动执行数据、张量

230
00:24:01,600 --> 00:24:08,500
及流水线并行、编排和调度，并且自动适应不同精度

231
00:24:08,500 --> 00:24:14,100
Nemo Megatron 现已支持各类 NVIDIA 系统，自动超参数调优

232
00:24:14,100 --> 00:24:16,100
针对您的目标基础架构

233
00:24:16,100 --> 00:24:22,300
Nemo Megatron 也是云原生的框架，现已支持 Azure，很快会支持 AWS

234
00:24:22,300 --> 00:24:30,800
AI 是智能的创造和生产者，这是一项具有重大意义的事业，涉及计算的方方面面

235
00:24:30,800 --> 00:24:32,600
和每个行业

236
00:24:32,600 --> 00:24:41,300
NVIDIA AI 库和 SDK 将加速整个 AI 生态系统中的软件、平台和服务

237
00:24:41,300 --> 00:24:47,800
即使拥有出色的工具和库，开发者和 NVIDIA 也必须投入大量的开发工程

238
00:24:47,800 --> 00:24:53,100
来确保其性能、可扩展性、可靠性和安全性

239
00:24:53,100 --> 00:25:00,400
因此，我们创建了 NVIDIA AI 加速计划，通过与 AI 生态系统中的开发者合作

240
00:25:00,400 --> 00:25:06,300
开发工程化解决方案，确保客户放心部署

241
00:25:06,300 --> 00:25:15,500
NVIDIA AI 使 AI 实现普及，让各个行业和公司都可以应用 AI 自我重塑

242
00:25:15,500 --> 00:25:20,300
其中，数字生物学的革命尤为引人瞩目

243
00:25:20,300 --> 00:25:30,000
AI 加速了 DNA 测序、蛋白质结构预测、新型药物合成和虚拟药物测试

244
00:25:30,000 --> 00:25:36,800
在过去几年中，AI 药物研发初创公司获得了超过 400 亿美元的投资

245
00:25:36,800 --> 00:25:43,800
Insilico Medicine 刚刚将其首个由 AI 研发的药物送入人体临床试验阶段

246
00:25:43,800 --> 00:25:50,900
发现新药和靶点仅用了不到 18 个月的时间，比之前快了数年

247
00:25:50,900 --> 00:25:55,600
数字生物学革命的条件已经成熟

248
00:25:55,600 --> 00:26:00,000
这将是 NVIDIA AI 迄今为止最伟大的使命

249
00:26:00,000 --> 00:26:05,300
语音、对话、客户服务和推荐系统等 AI 应用

250
00:26:05,300 --> 00:26:08,800
正在推动数据中心设计的根本性变化

251
00:26:08,800 --> 00:26:15,900
AI 数据中心会处理大量的连续数据来训练和完善 AI 模型

252
00:26:15,900 --> 00:26:20,900
原始数据进入其中，经过提炼，最终得到智能结果

253
00:26:20,900 --> 00:26:26,800
许多公司都致力于制造智能和运营大型 AI 工厂

254
00:26:26,800 --> 00:26:32,700
工厂需要 24 小时不停歇的持续密集运作，质量上的细微改进

255
00:26:32,700 --> 00:26:37,900
会使客户参与度和公司利润得到显著提高

256
00:26:37,900 --> 00:26:42,900
世界各地的公司中正在不断出现一个名为 MLOps 的新组织

257
00:26:42,900 --> 00:26:52,700
该组织的基本使命是高效、可靠地将数据转化为预测模型，也就是将其转化为智能

258
00:26:52,700 --> 00:27:00,700
它们处理的数据会呈指数级增长，这是因为模型的预测能力越强，参与服务的客户就越多

259
00:27:00,700 --> 00:27:02,800
收集的数据也会随之增长

260
00:27:02,800 --> 00:27:12,300
计算基础架构是 MLOps 的基石，其引擎是采用 Ampere 架构的 A100

261
00:27:16,000 --> 00:27:20,100
今天，我们将发布新一代产品

262
00:27:20,100 --> 00:27:26,400
这是全球 AI 计算基础架构引擎的巨大飞跃

263
00:27:26,400 --> 00:27:30,200
隆重推出 NVIDIA H100

264
00:27:30,200 --> 00:27:37,500
H100 是一款超大的芯片，采用 TSMC 4N 工艺，具有 800 亿个晶体管

265
00:27:37,500 --> 00:27:46,200
我们设计 H100 是为了用于纵向扩展和横向扩展，因此带宽，也就是内存、网络

266
00:27:46,200 --> 00:27:49,900
以及 NVLink 芯片之间的数据速率尤为重要

267
00:27:49,900 --> 00:27:57,100
H100 是首款支持 PCIe 5.0 标准的 GPU，也是首款采用 HBM3 标准的 GPU

268
00:27:57,100 --> 00:28:03,800
单个 H100 可支持 40 Tb/s 的 IO 带宽

269
00:28:03,800 --> 00:28:13,100
从另一个角度来说，20 块 H100 GPU 便可承托相当于全球互联网的流量

270
00:28:13,100 --> 00:28:16,800
Hopper 架构较之前一代 Ampere 架构，是一个巨大的飞跃

271
00:28:16,800 --> 00:28:21,400
我来着重介绍 5 项突破性的创新

272
00:28:21,400 --> 00:28:26,400
首先，H100 拥有强大的性能

273
00:28:26,400 --> 00:28:30,600
新的 Tensor 处理格式：FP8

274
00:28:30,600 --> 00:28:31,700
H100 具备以下运算能力：

275
00:28:31,700 --> 00:28:35,400
4 PetaFLOPS 的 FP8

276
00:28:35,400 --> 00:28:38,600
2 PetaFLOPS 的 FP16

277
00:28:38,600 --> 00:28:42,000
1 PetaFLOPS 的 TF32

278
00:28:42,000 --> 00:28:47,400
60 TeraFLOPS 的 FP64 和 FP32

279
00:28:47,400 --> 00:28:57,000
H100 采用风冷和液冷设计，是首个实现性能扩展至 700 瓦的 GPU

280
00:28:57,000 --> 00:29:06,900
在过去六年里，通过 Pascal、Volta、Ampere 和现在的 Hopper 架构，我们相继开发了使用 FP32、FP16

281
00:29:06,900 --> 00:29:11,300
和现在的 FP8 进行训练的技术

282
00:29:11,300 --> 00:29:23,900
在 AI 处理方面，Hopper H100 FP8 的 4 PetaFLOPS 性能是 Ampere A100 FP16 的 6 倍

283
00:29:23,900 --> 00:29:27,700
这是一次巨大的代际飞跃

284
00:29:27,700 --> 00:29:32,900
Transformer 无疑是最重要的深度学习模型

285
00:29:32,900 --> 00:29:36,900
Hopper 引入了 Transformer 引擎

286
00:29:36,900 --> 00:29:45,600
Hopper Transformer 引擎将新的 Tensor Core 与能使用 FP8 和 FP16 数字格式的软件结合

287
00:29:45,600 --> 00:29:49,400
动态处理 Transformer 网络的各个层

288
00:29:49,400 --> 00:29:54,800
Transformer 模型训练时间可从数周缩短至数天

289
00:29:54,800 --> 00:30:01,600
在云计算方面，多租户基础架构能够直接转化为收益和服务成本

290
00:30:01,600 --> 00:30:08,700
一项服务可将 H100 划分为多达 7 个实例，Ampere 也可实现此操作

291
00:30:08,700 --> 00:30:16,500
但是，Hopper 新增了完整的每实例隔离和每实例 IO 虚拟化

292
00:30:16,500 --> 00:30:19,700
便于支持云端的多租户

293
00:30:19,700 --> 00:30:26,400
H100 能够托管七个云租户，而 A100 仅能托管一个

294
00:30:26,400 --> 00:30:34,300
每个 H100 实例的性能相当于两个完整的 T4 GPU（我们非常热门的云推理 GPU）

295
00:30:34,300 --> 00:30:40,800
每个 Hopper 实例都支持在受信任执行环境中进行机密计算

296
00:30:40,800 --> 00:30:48,500
通常，敏感数据处于静态以及在网络中传输时会进行加密，但在使用期间却不受保护

297
00:30:48,500 --> 00:30:55,500
此类数据可以是一个 AI 模型，依托数百万美元的投资打造而成，基于多年的领域知识

298
00:30:55,500 --> 00:30:59,500
或公司专有数据进行了训练，并且具有价值或机密性

299
00:30:59,500 --> 00:31:04,700
Hopper 机密计算是处理器架构和软件的结合

300
00:31:04,700 --> 00:31:10,700
能够通过保护正在使用的数据和应用，弥合这一差距

301
00:31:10,700 --> 00:31:14,200
目前，机密计算只能基于 CPU

302
00:31:14,200 --> 00:31:19,000
Hopper 实现了首个 GPU 机密计算

303
00:31:19,000 --> 00:31:26,400
Hopper 机密计算能够保护所有者的 AI 模型和算法的机密性和完整性

304
00:31:26,400 --> 00:31:33,000
软件开发者和服务提供商现可在共享或远程基础架构上分发和部署宝贵的专有 AI 模型

305
00:31:33,000 --> 00:31:40,400
保护其知识产权并扩展业务模式

306
00:31:40,400 --> 00:31:42,000
此外，还有更多强大功能

307
00:31:42,000 --> 00:31:53,300
Hopper 引入了一组名为 DPX 的新指令集，旨在加速动态编程算法

308
00:31:53,300 --> 00:31:59,500
许多实际算法的组合复杂性或指数复杂性在不断的增长

309
00:31:59,500 --> 00:32:01,300
比如：

310
00:32:01,300 --> 00:32:05,200
著名的旅行商优化问题

311
00:32:05,200 --> 00:32:10,200
能够进行最短路径优化，以在绘图中使用的 Floyd-Warshall 算法

312
00:32:10,200 --> 00:32:16,400
通过模式匹配进行基因测序和蛋白质折叠计算的 Smith-Waterman 算法

313
00:32:16,400 --> 00:32:19,200
还有许多图优化算法

314
00:32:19,200 --> 00:32:25,800
动态编程能够将复杂问题分解为可递归式解决的更简单的子问题

315
00:32:25,800 --> 00:32:29,700
从而将复杂性和计算时间缩减至多项式计算的级别

316
00:32:29,700 --> 00:32:35,700
Hopper DPX 指令集会使这些算法的速度加快多达 40 倍

317
00:32:35,700 --> 00:32:40,200
H100 是 AI 基础架构的最新引擎

318
00:32:40,200 --> 00:32:50,200
H100 采用 TSMC CoWoS 2.5D 封装，搭载了 HBM3 显存，并与电压调节集成至

319
00:32:50,200 --> 00:32:54,700
名为 SXM 的超级芯片模组中

320
00:32:54,700 --> 00:32:59,500
现在，我来向大家展示如何构建先进的 AI 计算基础架构

321
00:32:59,500 --> 00:33:09,700
8 个 H100 SXM 模组通过 HGX 主板上的 4 个 NVLink Switch 芯片相连

322
00:33:09,700 --> 00:33:17,300
这 4 个超高速 NVSwitch 芯片各具有 3.6 TFLOPS 的 SHARP 网络计算性能

323
00:33:17,300 --> 00:33:21,100
SHARP 技术最早在 Mellanox Quantum InfiniBand 交换机中被率先发明

324
00:33:21,100 --> 00:33:26,000
对于广泛用于深度学习和科学计算的 all-to-all reductions 计算

325
00:33:26,000 --> 00:33:30,400
SHARP 能够有效将带宽提高 3 倍

326
00:33:30,400 --> 00:33:36,400
CPU 子系统由两个第 5 代 CPU 和两个网络模组组成

327
00:33:36,400 --> 00:33:45,500
两个模组各配备四个 400 Gbps 的 ConnectX-7 InfiniBand 或 400 Gbps 的以太网网络芯片

328
00:33:45,500 --> 00:33:52,300
ConnectX-7 拥有 80 亿个晶体管，是全球最先进的网络芯片

329
00:33:52,300 --> 00:33:59,600
总计 640 亿个晶体管能够实现 3.2 Tb/s 的网络传输

330
00:33:59,600 --> 00:34:07,200
隆重发布 DGX H100 - 我们全新的 AI 计算系统

331
00:34:07,200 --> 00:34:18,400
DGX 取得了令人瞩目的成功，在《财富》10 强企业和 100 强企业中，
分别有 8 家和 44 家企业使用 DGX 作为 AI 基础架构

332
00:34:18,400 --> 00:34:26,300
借助 NVLink 连接，DGX 使八块 H100 成为了一个巨型 GPU：

333
00:34:26,300 --> 00:34:29,400
6400 亿个晶体管

334
00:34:29,400 --> 00:34:32,100
32 PetaFLOPS 的 AI 性能

335
00:34:32,100 --> 00:34:35,500
640 GB HBM3 显存

336
00:34:35,500 --> 00:34:39,800
以及 24 TB/s 的显存带宽

337
00:34:39,800 --> 00:34:44,699
DGX H100 实现了巨大的飞跃

338
00:34:44,699 --> 00:34:46,099
此外，还有更多强大功能！

339
00:34:46,100 --> 00:34:49,900
我们采用全新方式扩展 DGX

340
00:34:49,900 --> 00:34:54,300
我们可以借助 NVLink 连接多达 32 个 DGX

341
00:34:54,300 --> 00:34:59,500
现在，我们宣布推出 NVIDIA NVLink Switch 系统

342
00:34:59,500 --> 00:35:04,200
对于 AI 工厂而言，DGX 是最小的计算单元

343
00:35:04,200 --> 00:35:14,300
借助 NVLink Switch 系统，我们可以将其扩展为一个巨大的拥有 32 个节点、256 个 GPU 的 DGX POD

344
00:35:14,300 --> 00:35:25,400
并且 HBM3 显存高达 20.5 TB，显存带宽高达 768 TB/s

345
00:35:25,400 --> 00:35:29,000
768 TB/s，可谓超高速！

346
00:35:29,000 --> 00:35:34,600
相比之下，整个互联网不过只有 100 TB/s

347
00:35:34,600 --> 00:35:41,200
每个 DGX 都可借助 4 端口光学收发器连接到 NVLink Switch

348
00:35:41,200 --> 00:35:50,600
每个端口都有 8 个 100G-PAM4 通道，每秒能够传输 100 GB

349
00:35:50,600 --> 00:35:57,300
32 个 NVLink 收发器连接到 1 个机架单元的 NVLink Switch 系统

350
00:35:57,300 --> 00:36:03,400
本质上，H100 DGX POD 是一款令人振奋的 GPU：

351
00:36:03,400 --> 00:36:05,900
1 ExaFLOPS 的 AI 计算能力

352
00:36:05,900 --> 00:36:08,300
20 TB 的 HBM3 显存

353
00:36:08,300 --> 00:36:13,000
192 TF 的 SHARP 网络计算性能

354
00:36:13,000 --> 00:36:21,600
在 GPU 之间移动数据的对分带宽惊人，高达 70 TB/s

355
00:36:21,600 --> 00:36:32,800
多个 H100 DGX POD 连接到我们新的 Quantum-2 400 Gbps InfiniBand 交换机，具有 SHARP 网络内计算技术

356
00:36:32,800 --> 00:36:42,800
性能隔离和拥塞控制等功能特性，并且可扩展到具有数千个 H100 GPU 的 DGX SuperPOD

357
00:36:42,800 --> 00:36:52,600
Quantum-2 交换机的芯片拥有 570 亿个晶体管，进而能够提供 64 个 400 Gbps 端口

358
00:36:52,600 --> 00:36:57,600
DGX SuperPOD 是现代 AI 工厂

359
00:36:57,600 --> 00:37:06,800
我们正在建造 EOS，这是 NVIDIA 打造的首个 Hopper AI 工厂，她将艳惊四座

360
00:37:06,800 --> 00:37:09,000
18 个 DGX POD

361
00:37:09,000 --> 00:37:11,700
576 台 DGX

362
00:37:11,700 --> 00:37:15,800
4608 个 H100 GPU

363
00:37:15,800 --> 00:37:26,500
在传统的科学计算领域，EOS 的速度是 275 PetaFLOPS，若与 A100 驱动的美国速度最快的科学计算机 Summit 相比

364
00:37:26,500 --> 00:37:29,100
要快 1.4 倍

365
00:37:29,100 --> 00:37:40,100
在 AI 方面，EOS 的 AI 处理速度是 18.4 ExaFLOPS，若与全球最大的超级计算机 – 日本的 Fugaku 相比

366
00:37:40,100 --> 00:37:42,600
要快 4 倍

367
00:37:42,600 --> 00:37:47,500
我们期待 EOS 成为全球运行速度最快的 AI 计算机系统

368
00:37:47,500 --> 00:37:54,200
对于我们的 OEM 和云合作伙伴而言，EOS 将会是先进 AI 基础架构的蓝图

369
00:37:54,200 --> 00:38:00,200
合作伙伴可以整体采用 H100 DGX SuperPOD，或采用我们平台中四个层的

370
00:38:00,200 --> 00:38:03,400
任意一层的技术组件

371
00:38:03,400 --> 00:38:08,100
我们已在着手打造 EOS，将于数月后推出

372
00:38:08,100 --> 00:38:10,800
我们来看看 Hopper 的性能

373
00:38:10,800 --> 00:38:14,300
与 Ampere 相比，Hopper 的性能提升令人惊艳

374
00:38:14,300 --> 00:38:20,400
训练 Transformer 的模型、结合 Hopper 的原始性能

375
00:38:20,400 --> 00:38:24,000
具有 FP8 Tensor Core 的 Hopper Transformer 引擎

376
00:38:24,000 --> 00:38:34,000
采用 SHARP 网络计算技术的 NVLink、可连接 256 个 GPU 的 NVLink Switch、Quantum-2 InfiniBand

377
00:38:34,000 --> 00:38:40,000
以及我们所有的软件，这些综合效益共同成就了 9 倍的速度提升！

378
00:38:40,000 --> 00:38:42,900
计算时间从数周缩短至几天

379
00:38:42,900 --> 00:38:50,900
在推理大型语言模型方面，H100 的吞吐量比 A100 高 30 倍

380
00:38:50,900 --> 00:38:55,300
H100 是我们实现的巨大飞跃

381
00:38:55,300 --> 00:39:02,100
NVIDIA H100 是全球 AI 基础架构的新引擎

382
00:39:02,100 --> 00:39:06,200
Hopper 也将成为主流系统游戏规则的改变者

383
00:39:06,200 --> 00:39:13,700
正如您在 Hopper HGX 和 DGX 中看到的一样，网络和互连产品对于计算至关重要

384
00:39:13,700 --> 00:39:18,800
移动数据以保持超快速的 GPU 数据馈送值得高度关注

385
00:39:18,800 --> 00:39:23,900
那么，我们如何将 Hopper 强大的计算能力引入主流服务器？

386
00:39:23,900 --> 00:39:31,500
在传统服务器中移动数据会使 CPU 和系统内存过载，并受到 PCIe 的限制

387
00:39:31,500 --> 00:39:36,200
解决方案是将网络直接与 GPU 相连

388
00:39:36,200 --> 00:39:45,600
这就是 H100 CNX，它将先进的 GPU 和强大的网络处理器 ConnectX-7

389
00:39:45,600 --> 00:39:47,600
融合至一个模组中

390
00:39:47,600 --> 00:39:56,800
网络数据通过 DMA 以 50 GB/s 的速度直接传输至 H100，从而避免 CPU

391
00:39:56,800 --> 00:40:01,200
系统内存和 PCIe 等多个通道的限制

392
00:40:01,200 --> 00:40:09,100
H100 CNX 能够避免带宽瓶颈，同时释放 CPU 和系统内存，以便处理应用的其他部分

393
00:40:09,100 --> 00:40:15,300
在一个为主流服务器设计的小巧封装中包含了大量令人难以置信的技术

394
00:40:15,300 --> 00:40:23,500
Hopper H100 支持各种规模的系统，包括用于主流服务器的 PCIe 加速器

395
00:40:23,500 --> 00:40:29,200
以及 DGX、DGX POD 和 DGX SuperPOD

396
00:40:29,200 --> 00:40:36,900
这些系统能够运行 NVIDIA HPC、NVIDIA AI 以及 CUDA 库的丰富生态系统

397
00:40:36,900 --> 00:40:41,900
下面我来介绍一下 Grace 的最新进展，这是我们的首款数据中心 CPU

398
00:40:41,900 --> 00:40:48,000
我很高兴地宣布，Grace 进展飞速，有望明年供货

399
00:40:48,000 --> 00:40:52,800
Grace 专为处理海量数据而设计

400
00:40:52,800 --> 00:40:57,100
它将成为 AI 工厂的理想 CPU

401
00:40:57,100 --> 00:41:00,200
这就是 Grace-Hopper

402
00:41:00,200 --> 00:41:07,700
它是单一超级芯片模组，能够在 CPU 和 GPU 之间进行芯片间的直接连接

403
00:41:07,700 --> 00:41:15,800
Grace-Hopper 的关键驱动技术之一是内存一致性芯片之间的 NVLink 互连

404
00:41:15,800 --> 00:41:19,300
每个链路的速度达 900 GB/s！

405
00:41:19,300 --> 00:41:22,100
但前面我只讲了一半的故事

406
00:41:22,100 --> 00:41:25,900
Grace 的一切都令人赞叹

407
00:41:25,900 --> 00:41:36,800
Grace CPU 也可以是由两个通过芯片之间的 NVLink 连接，保证一致性的 CPU 芯片组成的超级芯片

408
00:41:36,800 --> 00:41:42,600
Grace 超级芯片拥有 144 个 CPU 核心！

409
00:41:42,600 --> 00:41:47,900
而且，内存带宽高达 1 TB/s，速度之快着实惊人

410
00:41:47,900 --> 00:41:54,600
是尚未发布的第 5 代顶级 CPU 的 2 到 3 倍

411
00:41:54,600 --> 00:42:05,000
我们预估 Grace 超级芯片的 SPECint 2017 得分为 740，目前几乎没有任何产品可与之媲美

412
00:42:05,000 --> 00:42:13,500
令人惊叹的是，整个模组（包括 1 TB 内存）的功率仅为 500 瓦

413
00:42:13,500 --> 00:42:19,300
我们预计 Grace 超级芯片届时将是最强大的 CPU

414
00:42:19,300 --> 00:42:21,800
拥有最高性能和两倍能效

415
00:42:21,800 --> 00:42:28,900
Grace 将在 AI、数据分析、科学计算和超大规模计算领域有着惊人的表现

416
00:42:28,900 --> 00:42:40,500
Grace 还将得到 NVIDIA 所有软件平台（NVIDIA RTX、HPC、NVIDIA AI 和 Omniverse）的支持

417
00:42:40,500 --> 00:42:47,300
Grace-Hopper 和 Grace 超级芯片的推动因素是超节能、低延迟

418
00:42:47,300 --> 00:42:52,200
高速内存一致性 NVLink 芯片到芯片链路

419
00:42:52,200 --> 00:42:59,200
借助从裸片之间、芯片之间以及系统之间的 NVLink 扩展

420
00:42:59,200 --> 00:43:04,800
我们可以配置 Grace 和 Hopper，以便处理各种工作负载

421
00:43:04,800 --> 00:43:06,500
我们可以通过 Grace 和 Hopper 打造不同的系统：

422
00:43:06,500 --> 00:43:09,600
2 个 Grace CPU 组成的超级芯片

423
00:43:09,600 --> 00:43:13,500
1 个 Grace 加 1 个 Hopper 组成的超级芯片

424
00:43:13,500 --> 00:43:17,300
1 个 Grace 加 2 个 Hopper 的超级芯片

425
00:43:17,300 --> 00:43:21,900
搭载 2 个 Grace 和 2 个 Hopper 的系统

426
00:43:21,900 --> 00:43:24,600
2 个 Grace 加 4 个 Hopper 组成的系统

427
00:43:24,600 --> 00:43:27,600
2 个 Grace 加 8 个 Hopper 组成的系统

428
00:43:27,600 --> 00:43:35,900
Grace 和 Hopper 的 NVLink 以及 ConnectX-7 中的 PCIe 5.0 交换机组合

429
00:43:35,900 --> 00:43:41,400
能够为我们提供大量方法，解决客户的各种计算需求

430
00:43:41,400 --> 00:43:52,800
未来的 NVIDIA 芯片，如 CPU、GPU、DPU、NIC 和 SOC，将像 Grace 和 Hopper 一样集成 NVLink

431
00:43:52,800 --> 00:43:55,500
我们拥有十分出色的 SERDES 技术

432
00:43:55,500 --> 00:44:00,700
凭借多年的高速显存位宽、NVLink 和网络交换机设计经验

433
00:44:00,700 --> 00:44:04,400
NVIDIA 在高速 SERDES 方面掌握了出色的专业知识

434
00:44:04,400 --> 00:44:11,700
NVIDIA 正在为那些希望采用连接到 NVIDIA 平台的定制芯片客户和合作伙伴

435
00:44:11,700 --> 00:44:13,900
提供 NVLink 和 SERDES

436
00:44:13,900 --> 00:44:21,500
这些高速链路为通过 NVIDIA 计算构建半定制芯片和系统开辟了一个新的世界

437
00:44:21,500 --> 00:44:31,300
过去十年，NVIDIA 通过 GPU 加速算法、全栈优化和整个数据中心的扩展

438
00:44:31,300 --> 00:44:38,000
使计算速度实现了 Million-X 百万倍加速

439
00:44:38,000 --> 00:44:44,000
计算机科学和工程在 NVIDIA SDK 中体现

440
00:44:44,000 --> 00:44:51,100
具备 CUDA 库的 NVIDIA SDK 是加速计算的核心和灵魂

441
00:44:51,100 --> 00:44:58,400
NVIDIA SDK 将我们与科学领域的新挑战和业界新机遇紧密相连

442
00:44:58,400 --> 00:45:07,800
RAPIDS 是一套 SDK，可供数据科学家将热门 Python API 用于 DataFrame、SQL、数组

443
00:45:07,800 --> 00:45:10,700
机器学习和图分析

444
00:45:10,700 --> 00:45:16,800
RAPIDS 是 NVIDIA 备受欢迎的 NVIDIA SDK 之一，仅次于用于深度学习的 cuDNN

445
00:45:16,800 --> 00:45:23,500
RAPIDS 的下载次数已达 200 万次，同比增长了 3 倍

446
00:45:23,500 --> 00:45:29,100
它已在超过 5000 个 GitHub 项目和 2000 多个 Kaggle notebooks 中使用

447
00:45:29,100 --> 00:45:33,800
并集成至 35 个商业软件包中

448
00:45:33,800 --> 00:45:38,500
NVIDIA RAPIDS for Spark 是用于加速 Apache Spark 的插件

449
00:45:38,500 --> 00:45:45,700
Spark 是先进的数据处理引擎，80% 的《财富》500 强公司都在使用

450
00:45:45,700 --> 00:45:51,300
Spark 用户可以透明地加速 Spark data-frame 和 SQL

451
00:45:51,300 --> 00:45:55,300
原本需要数小时完成的操作现在只需数分钟即可完成

452
00:45:55,300 --> 00:46:04,600
NVIDIA cuOpt（之前称为 ReOpt）是一款 SDK，能够优化多代理、多约束的路线规划

453
00:46:04,600 --> 00:46:09,900
用于仓库内的交付服务或自主移动机器人

454
00:46:09,900 --> 00:46:17,400
借助 NVIDIA cuOpt，企业第一次可以在数秒内完成上千个包裹到上千个地点的实时规划

455
00:46:17,400 --> 00:46:23,400
并且具备超高准确率

456
00:46:23,400 --> 00:46:28,000
超过 175 家公司正在测试 NVIDIA cuOpt

457
00:46:28,000 --> 00:46:36,900
图是表示真实世界数据（如地图、社交网络、Web、蛋白质和分子以及金融交易）的

458
00:46:36,900 --> 00:46:40,900
常用数据结构之一

459
00:46:40,900 --> 00:46:48,900
NVIDIA DGL 容器支持跨多个 GPU 和节点训练大型图神经网络

460
00:46:48,900 --> 00:46:54,200
NVIDIA Morpheus 是用于网络安全的深度学习框架

461
00:46:54,200 --> 00:47:02,000
Morpheus 能够帮助网络安全开发者构建和扩展解决方案，这些解决方案使用深度学习技术

462
00:47:02,000 --> 00:47:06,800
以前所未有的方式来识别、捕捉威胁并对威胁采取行动

463
00:47:06,800 --> 00:47:11,300
每家公司都需要改用零信任架构

464
00:47:11,300 --> 00:47:15,100
NVIDIA 无疑可使用 Morpheus

465
00:47:15,100 --> 00:47:20,400
cuQuantum 是一种用于加速量子电路仿真器的 SDK

466
00:47:20,400 --> 00:47:24,600
可让研究人员开发未来的量子算法

467
00:47:24,600 --> 00:47:29,500
（目前在量子计算机上无法探索这些算法）

468
00:47:29,500 --> 00:47:35,900
cuQuantum 能加速多种先进的 QC 仿真器，包括 Google Cirq、IBM Qiskit

469
00:47:35,900 --> 00:47:42,700
Xanadu 的 Pennylane、Quantinuum TKET 和橡树岭国家实验室的 ORNL ExaTN

470
00:47:42,700 --> 00:47:49,100
DGX 上的 cuQuantum 是非常适合量子计算的开发系统

471
00:47:49,100 --> 00:47:56,100
Aerial 是一款适用于 CUDA 加速的软件定义的 5G 无线网络的 SDK

472
00:47:56,100 --> 00:48:03,000
借助 Aerial，无论是数据中心、云、本地，还是边缘，均可成为 5G 无线网络

473
00:48:03,000 --> 00:48:08,600
并可为无 WIFI 服务的地方提供 5G AI 服务

474
00:48:08,600 --> 00:48:12,900
6G 标准将于 2026 年左右问世

475
00:48:12,900 --> 00:48:19,400
6G 是大势所趋 – 数以千亿计的机器和机器人

476
00:48:19,400 --> 00:48:22,400
将成为网络用户中的主力军

477
00:48:22,400 --> 00:48:27,600
6G 正围绕一些基础技术逐步形成雏形

478
00:48:27,600 --> 00:48:31,700
与网络一样，6G 将很大程度上由软件定义

479
00:48:31,700 --> 00:48:34,400
网络将由 AI 驱动

480
00:48:34,400 --> 00:48:40,100
基于光线追踪和 AI 的数字孪生将有助于优化网络

481
00:48:40,100 --> 00:48:42,900
NVIDIA 可以在这些领域做出贡献

482
00:48:42,900 --> 00:48:52,400
我们很高兴地宣布推出新框架 Sionna，它是一种用于 6G 通信研究的 AI 框架

483
00:48:52,400 --> 00:48:58,500
Modulus 是用于开发 Physics–ML 模型的 AI 框架

484
00:48:58,500 --> 00:49:06,500
这些深度神经网络模型可以学习物理学，并做出符合物理定律的预测

485
00:49:06,500 --> 00:49:12,000
速度比数值方法快许多个数量级

486
00:49:12,000 --> 00:49:16,000
我们正使用 Modulus 构建 Earth-2 数字孪生

487
00:49:16,000 --> 00:49:20,200
MONAI 是一个用于医疗影像的开源 AI 框架

488
00:49:20,200 --> 00:49:31,100
NVIDIA MONAI 容器包含 2D 和 3D 模型的 AI 辅助标注、迁移学习和 AutoML 训练

489
00:49:31,100 --> 00:49:34,100
可通过 DICOM 轻松部署

490
00:49:34,100 --> 00:49:42,000
世界排名前 30 的学术医疗中心正在使用 MONAI，下载超过 25 万次

491
00:49:42,000 --> 00:49:51,900
FLARE 是用于联邦学习的 NVIDIA 开源 SDK，使研究人员能够以一种保护隐私的方式

492
00:49:51,900 --> 00:49:54,900
（即共享模型而非数据）开展协作

493
00:49:54,900 --> 00:50:02,400
数百万开发者和成千上万的公司使用 NVIDIA SDK 来加速处理工作负载

494
00:50:02,400 --> 00:50:09,100
在本次 GTC 上我们更新了 60 个 SDK，加入了更多功能和加速技术

495
00:50:09,100 --> 00:50:14,300
现有的 NVIDIA 系统变得更快

496
00:50:14,300 --> 00:50:21,200
进行运筹学研究、量子算法研究、6G 研究或图分析的科学家

497
00:50:21,200 --> 00:50:26,700
将能首次使用 NVIDIA 加速技术

498
00:50:26,700 --> 00:50:30,400
对于从事计算机辅助设计或工程的公司

499
00:50:30,400 --> 00:50:35,100
他们所依赖的软件工具（由 Ansys、Altair

500
00:50:35,100 --> 00:50:42,000
Siemens、Synopsys、Cadence 等公司开发）将获得大幅的速度提升

501
00:50:42,000 --> 00:50:46,500
亲身感受这些技术对工程技术实践带来的改变

502
00:50:46,500 --> 00:50:55,000
请前往 NGC (NVIDIA GPU Cloud)，下载经过全栈优化并提供数据中心级加速能力的

503
00:50:55,000 --> 00:50:58,400
SDK 和框架

504
00:51:04,500 --> 00:51:10,000
当某条电线发生故障导致两个氧气罐中的一个发生爆炸时

505
00:51:10,000 --> 00:51:17,100
阿波罗 13 号的船员与地球相距 136000 英里

506
00:51:17,100 --> 00:51:22,300
NASA 在无线电中听到了至今羞于提及的一句话 –“休斯顿，我们遇到问题了。”

507
00:51:22,300 --> 00:51:28,400
为了“解决问题”，NASA 工程师在奥德赛号宇宙飞船的复制品上测试了氧气保存

508
00:51:28,400 --> 00:51:31,800
和开关机循环程序

509
00:51:31,800 --> 00:51:38,800
如果没有在地球上建造的全功能复制品，阿波罗 13 号将会遭受灭顶之灾

510
00:51:38,800 --> 00:51:41,700
这是一个重要时刻

511
00:51:41,700 --> 00:51:48,200
NASA 意识到了复制模拟的力量，但并非所有事物都能具有实体孪生

512
00:51:48,200 --> 00:51:57,500
因此，NASA 创造了术语“数字孪生”，用实时存在的虚拟物来表征物理实体

513
00:51:57,500 --> 00:52:06,000
当扩展到极致时，数字孪生是一个与物理世界相连的虚拟世界

514
00:52:06,000 --> 00:52:10,900
而在互联网背景下，它带来了下一次演进

515
00:52:10,900 --> 00:52:20,600
这正是 NVIDIA Omniverse 的作用 – 数字孪生、虚拟世界以及互联网的下一次演进

516
00:52:20,600 --> 00:52:30,000
20 多年来，NVIDIA 在图形、物理学、仿真、AI 和计算技术领域深耕不辍，最终打造出 Omniverse

517
00:52:30,000 --> 00:52:33,800
模拟这个世界是一项终极挑战

518
00:52:33,800 --> 00:52:37,500
Omniverse 是虚拟世界的仿真引擎

519
00:52:37,500 --> 00:52:42,400
Omniverse 世界具备物理精准的特点，并且遵守物理学定律

520
00:52:42,400 --> 00:52:44,900
Omniverse 在宏大的维度上运行

521
00:52:44,900 --> 00:52:50,800
Omniverse 可共享，能将设计师、观看者、AI 和机器人连接起来

522
00:52:50,800 --> 00:52:53,200
那么，Omniverse 有哪些应用场景？

523
00:52:53,200 --> 00:52:57,100
今天，我将重点介绍几个直接用例：

524
00:52:57,100 --> 00:53:00,800
使用不同工具的设计师之间的远程协作

525
00:53:00,800 --> 00:53:04,700
供 AI 和机器人学习的 Sim2Real Gym

526
00:53:04,700 --> 00:53:06,600
还有工业数字孪生

527
00:53:06,600 --> 00:53:11,200
不过，首先让我展示一些造就 Omniverse 的基础技术

528
00:54:26,100 --> 00:54:30,500
Omniverse 技术将改变您的创作方式！

529
00:55:11,300 --> 00:55:16,300
Omniverse 可从 RTX PC 扩展到大型系统

530
00:55:16,300 --> 00:55:23,400
连接到托管 Omniverse Nucleus 的用户的 RTX PC 在性能上足以进行创意协作

531
00:55:23,400 --> 00:55:29,200
然而，工业数字孪生需要一种专门构建的新型计算机

532
00:55:29,200 --> 00:55:36,700
数字孪生仿真涉及多个自主系统在同一时空内进行交互

533
00:55:36,700 --> 00:55:42,800
数据中心在尽可能短的时间内而不是按照精确的时间处理数据

534
00:55:42,800 --> 00:55:52,000
对于数字孪生，Omniverse 软件和计算机必须具备可扩展、低延迟和支持精确时间的特点

535
00:55:52,000 --> 00:55:55,800
我们需要建造同步的数据中心

536
00:55:55,800 --> 00:56:01,900
正如我们为 AI 提供 DGX 一样，我们现在为 Omniverse 提供 OVX

537
00:56:01,900 --> 00:56:13,700
第一代 NVIDIA OVX Omniverse 计算机由 
8 个 NVIDIA A40 RTX GPU、3 个 ConnectX-6 200 Gbps 网卡 (NIC)

538
00:56:13,700 --> 00:56:16,300
和 2 个 Intel Ice Lake CPU 组成

539
00:56:16,300 --> 00:56:28,200
利用 NVIDIA Spectrum-3 200 Gbps 交换机连接 32 台 OVX 服务器就构成了 OVX SuperPOD

540
00:56:28,200 --> 00:56:34,000
最重要的是，网络和计算机使用精准时间协议进行同步

541
00:56:34,000 --> 00:56:37,500
而且 RDMA 可更大程度降低数据包传输延迟

542
00:56:37,500 --> 00:56:41,200
现在，全球各大计算机制造商纷纷推出 OVX 服务器

543
00:56:41,200 --> 00:56:47,500
对于想在 OVX 上试用 Omniverse 的客户，NVIDIA 在全球各地提供了 LaunchPad 计划

544
00:56:47,500 --> 00:56:52,500
第一代 OVX 正由 NVIDIA 和早期客户运行

545
00:56:52,500 --> 00:56:57,300
我们正在构建第二代 OVX – 从骨干网络开始

546
00:56:57,300 --> 00:57:01,000
今天，我们宣布推出 Spectrum-4 交换机

547
00:57:01,000 --> 00:57:10,400
带宽高达 51.2 Tbps 且具有 1000 亿个晶体管的 Spectrum-4 将成为非常先进的交换机

548
00:57:10,400 --> 00:57:16,400
Spectrum-4 可在所有端口之间公平分配带宽，并提供自适应路由

549
00:57:16,400 --> 00:57:20,700
和拥塞控制功能，能显著提升数据中心的整体吞吐量

550
00:57:20,700 --> 00:57:27,000
凭借 ConnectX-7 和 BlueField-3 适配器以及 DOCA 数据中心基础架构软件

551
00:57:27,000 --> 00:57:35,400
它们将组成世界上首个 400 Gbps 端到端网络平台

552
00:57:35,400 --> 00:57:39,900
与典型数据中心数毫秒的抖动相比

553
00:57:39,900 --> 00:57:49,600
Spectrum-4 可以实现纳秒级计时精度 – 即 5 到 6 个数量级的改进

554
00:57:49,600 --> 00:57:56,700
超大规模计算将享受到更高的吞吐量、更好的服务质量和更高的安全性，同时能降低功耗和成本

555
00:57:56,700 --> 00:58:04,300
Spectrum-4 催生了一种新型计算机，用于在云和边缘数据中心支持 Omniverse 数字孪生

556
00:58:04,300 --> 00:58:10,100
NVIDIA Spectrum-4 是世界领先的以太网网络平台

557
00:58:10,100 --> 00:58:15,700
也是 Omniverse 计算机的骨干网络，样机将在第 4 季度末发布

558
00:58:15,700 --> 00:58:20,000
Omniverse 是一个连接虚拟世界的“网络中的网络”

559
00:58:20,000 --> 00:58:29,300
当不同的生态系统通过 Omniverse 连接成一个统一的工作流程时，这张网络的价值就会放大

560
00:58:29,300 --> 00:58:35,500
自去年举行 GTC 以来，我们的连接软件数量从 8 个增加到 82 个

561
00:58:35,500 --> 00:58:41,100
与我们连接的包括：Chaos Vray、Autodesk Arnold 和 Blender

562
00:58:41,100 --> 00:58:47,000
以及 Adobe 的 3D Substance Painter、Epic 的虚幻引擎 5 和 Maxon 的 Cinema 4D

563
00:58:47,000 --> 00:58:52,700
许多开发者希望 OEM 将 Omniverse 直接连接到他们的软件套件

564
00:58:52,700 --> 00:58:58,400
Bentley Systems 是先进的基础架构设计、施工和管理平台

565
00:58:58,400 --> 00:59:07,100
他们将 Omniverse 集成到他们的 LumenRT 平台中，对大型基础架构数字孪生

566
00:59:07,100 --> 00:59:12,100
进行交互式、工程级、精确到毫米级的 4D 可视化

567
00:59:12,100 --> 00:59:16,000
Bentley 现已推出集成了 Omniverse 的 LumenRT

568
00:59:16,000 --> 00:59:18,700
我们将在 GTC 上发布一个主要版本

569
00:59:18,700 --> 00:59:24,800
用于构建 Omniverse 扩展程序、应用和微服务的 Omniverse Kit

570
00:59:24,800 --> 00:59:32,500
我们将发布 26 个制造业行业的格式转换器，以将工业工作流程连接到 Omniverse

571
00:59:32,500 --> 00:59:42,000
DeepSearch 是一个 AI 搜索引擎，可使用自然语言或图像来搜索未标记的大型 3D 素材库

572
00:59:42,000 --> 00:59:51,400
Omniverse Replicator 框架用于生成物理属性准确的合成数据，以训练和测试 AI 模型

573
00:59:51,400 --> 01:00:00,900
Omnigraph 是多 GPU、多节点的计算引擎，用于运行数据中心级 Omniverse 应用

574
01:00:00,900 --> 01:00:08,900
Omniverse Avatar 是一个非常大型的项目，提供用于构建虚拟形象或数字人的框架

575
01:00:08,900 --> 01:00:15,400
让我欢迎 Toy Jensen 归来，这是我们用 Omniverse Avatar 构建的应用

576
01:00:15,400 --> 01:00:20,500
请注意，Toy Jensen 并非录像。他是完全实时的

577
01:00:20,500 --> 01:00:26,600
他能进行眼神交流和对话，而且完全动画化

578
01:00:26,600 --> 01:00:31,400
嘿，TJ！我想问你几个问题

579
01:00:31,400 --> 01:00:33,700
好的！有问必答

580
01:00:33,700 --> 01:00:35,900
什么是合成生物学？

581
01:00:37,300 --> 01:00:44,000
合成生物学是指在多个层级设计生物系统，包括单个分子、整个细胞

582
01:00:44,000 --> 01:00:48,700
甚至是组织和器官等多细胞组合，以执行特定功能

583
01:00:48,700 --> 01:00:53,200
它也被称为 SynBio，代表“合成生命”

584
01:00:53,200 --> 01:00:55,700
能否举几个例子？

585
01:00:57,000 --> 01:01:03,900
合成生物学目前的一些用途包括制作生物燃料；研制具有天然生物体所没有的实用特性的细菌；

586
01:01:03,900 --> 01:01:09,400
开发能够检测环境细菌的生物传感器；

587
01:01:09,400 --> 01:01:15,800
生产生物制药；通过发酵（而不是石油化工）制造化学品

588
01:01:16,500 --> 01:01:19,900
在医疗领域有哪些应用？

589
01:01:19,900 --> 01:01:27,200
合成生物学在医学领域应用广泛。例如，合成生物学用于研发新疫苗

590
01:01:27,200 --> 01:01:30,800
新抗生素和癌症新疗法

591
01:01:30,800 --> 01:01:36,000
TJ，这真的太棒了！能否说说你是如何制作出来的？

592
01:01:36,000 --> 01:01:39,500
Avatar 是一个基于 Omniverse 平台构建的框架

593
01:01:39,500 --> 01:01:44,700
使用此框架，您可以快速构建和部署像我一样的虚拟形象，以用于各种用途

594
01:01:44,700 --> 01:01:50,200
首先从我的声音开始。它完全由 Riva 的文本转语音 RADTTS 合成

595
01:01:50,200 --> 01:01:55,300
而且可用于通过 Omniverse Audio2Face 驱动我的面部动画

596
01:01:55,300 --> 01:02:00,400
接下来，Omniverse 动画的动画图形用于定义并控制我的动作

597
01:02:00,400 --> 01:02:04,400
包括手和手臂的动作，以及细微的头部和身体运动

598
01:02:04,400 --> 01:02:10,000
NVIDIA 的开源材质定义语言 (MDL) 可增加触感，让我炫酷的夹克

599
01:02:10,000 --> 01:02:17,000
看起来就像合成皮革，而不仅仅是塑料，而 RTX 渲染器能实时以高保真度呈现我的形象

600
01:02:17,000 --> 01:02:22,700
最后，得益于 Riva 中的最新对话式 AI 技术和 Megatron 530B NLP 模型

601
01:02:22,700 --> 01:02:30,100
（我们训练过的最大语言模型之一），我可以听你讲，也可以跟你聊天

602
01:02:30,100 --> 01:02:34,900
Megatron 帮我回答了 Jensen 问我的所有难题

603
01:02:34,900 --> 01:02:41,000
同样令人兴奋的是，我可以从云、数据中心或其他任何分解系统运行

604
01:02:41,000 --> 01:02:43,000
这都要归功于 Tokkio

605
01:02:43,000 --> 01:02:49,200
Tokkio 是一款使用 Omniverse Avatar 构建的应用，它将客户服务 AI 引入零售店

606
01:02:49,200 --> 01:02:51,700
快餐餐厅，甚至网络

607
01:02:51,700 --> 01:03:00,000
它使用计算机视觉、Riva 语音 AI 和 NVIDIA NeMO 等 NVIDIA AI 模型和技术打造而成

608
01:03:00,000 --> 01:03:05,900
而且，由于 Tokkio 在我们的统一计算框架（或 UCF）上运行，因此可以从云端横向扩展

609
01:03:05,900 --> 01:03:09,300
当客户需要像我一样实用的虚拟形象时，满足他们的需求

610
01:03:09,300 --> 01:03:13,600
并且 Tokkio 具有非常敏锐且响应灵敏的感知力，最重要的是，非常自然

611
01:03:13,600 --> 01:03:18,600
下面请大家欣赏关于我的制作过程的简短视频。黄先生，您继续！

612
01:03:19,600 --> 01:03:27,800
如今的 AI 以感知和模式识别为中心，例如图像识别、语音理解

613
01:03:27,800 --> 01:03:32,400
推荐视频节目或商品

614
01:03:32,400 --> 01:03:39,400
下一波 AI 浪潮是机器人，AI 也有相应的计划和行动

615
01:03:39,400 --> 01:03:45,200
NVIDIA 正在构建多个机器人平台 – 用于自动驾驶汽车的 DRIVE

616
01:03:45,200 --> 01:03:52,800
用于操纵和控制系统的 Isaac、用于自主式基础架构的 Metropolis

617
01:03:52,800 --> 01:03:57,200
以及用于机器人医疗器械的 Holoscan

618
01:03:57,200 --> 01:04:06,200
正如 NASA 认识到的，我们需要数字孪生来操作远处的机器人舰队

619
01:04:06,200 --> 01:04:12,700
机器人系统的工作流程很复杂。我将它简化为四个支柱：

620
01:04:12,700 --> 01:04:15,900
收集和生成真值数据；

621
01:04:15,900 --> 01:04:17,900
创建 AI 模型；

622
01:04:17,900 --> 01:04:20,600
使用数字孪生进行仿真；

623
01:04:20,600 --> 01:04:22,700
操作机器人

624
01:04:22,700 --> 01:04:25,500
Omniverse 是整个工作流程的核心

625
01:04:25,500 --> 01:04:31,800
DRIVE 是我们的自动驾驶汽车系统，本质上是 AI 司机

626
01:04:31,800 --> 01:04:37,200
与我们所有的平台一样，NVIDIA DRIVE 是全栈的端到端平台

627
01:04:37,200 --> 01:04:41,600
并且对开发者开放，让他们既可使用整个平台，也可使用其中的一部分

628
01:04:41,600 --> 01:04:49,500
对于真值数据，我们使用 DeepMap 高精地图、人工标记数据和 Omniverse Replicator

629
01:04:49,500 --> 01:04:54,600
为了训练 AI 模型，我们使用 NVIDIA AI 和 DGX

630
01:04:54,600 --> 01:04:59,800
Omniverse 中的 DRIVE Sim 在 OVX 上运行，是数字孪生

631
01:04:59,800 --> 01:05:07,600
DRIVE AV 是一款运行在车载 Orin 计算平台上的自动驾驶应用

632
01:05:07,600 --> 01:05:11,700
让我们通过最新版 NVIDIA Drive 来享受驾驶吧

633
01:05:11,700 --> 01:05:15,300
我们将带您沿着圣何塞的高速公路和市区路线行驶

634
01:05:15,300 --> 01:05:19,300
您可以在可信度渲染视图中看到汽车看见的场景

635
01:05:19,300 --> 01:05:24,300
我们将在复杂场景中驾驶，例如拥挤的交叉路口

636
01:05:24,300 --> 01:05:29,100
AI 司机将会是您友善的驾驶伙伴

637
01:05:45,300 --> 01:05:49,300
欢迎 Daniel。我看到 Hubert 发来一条短信

638
01:05:49,300 --> 01:05:53,300
“你能在圣何塞市中心接我吗？” 要我带您去吗？

639
01:05:53,300 --> 01:05:54,266
是的，谢谢

640
01:05:54,466 --> 01:05:56,766
好的，带您去圣何塞市中心

641
01:05:57,900 --> 01:05:59,033
启动 DRIVE Pilot

642
01:05:59,200 --> 01:06:01,666
好的，启动 DRIVE Pilot

643
01:06:07,666 --> 01:06:10,066
能否告诉 Hubert 我们已在路上？

644
01:06:10,433 --> 01:06:12,700
当然，我会给他发条短信

645
01:06:42,733 --> 01:06:44,800
我看到 Hubert 了

646
01:06:48,900 --> 01:06:51,500
能带我去 Rivermark Hotel 吗？

647
01:06:51,500 --> 01:06:54,400
好的，带您去 Rivermark Hotel

648
01:06:54,400 --> 01:06:55,700
谢谢你来接我！

649
01:06:55,700 --> 01:06:58,600
好的。启动 DRIVE Pilot

650
01:06:58,600 --> 01:07:01,000
好的，启动 DRIVE Pilot

651
01:07:04,400 --> 01:07:06,300
那里是什么建筑？

652
01:07:06,300 --> 01:07:09,600
那是圣何塞表演艺术中心

653
01:07:09,600 --> 01:07:11,300
那里在上演什么节目？

654
01:07:11,300 --> 01:07:13,300
今晚演出的节目是《猫》

655
01:07:13,300 --> 01:07:16,300
可以给我买两张星期六晚上的票吗？

656
01:07:16,300 --> 01:07:18,100
好的

657
01:07:43,233 --> 01:07:45,166
您已抵达目的地

658
01:07:45,566 --> 01:07:47,433
请停车

659
01:07:47,833 --> 01:07:51,533
好的，找到停车位

660
01:08:14,000 --> 01:08:23,100
Hyperion 8 是我们自动驾驶汽车的硬件架构，同时它也是整个 DRIVE 平台的构建基础

661
01:08:23,100 --> 01:08:31,600
它由以下硬件组成：多个传感器、多个网络、
两台司机自动驾驶计算机、一台服务员 AI 计算机、一个任务记录器

662
01:08:31,600 --> 01:08:34,100
以及安全和网络安全系统

663
01:08:34,100 --> 01:08:36,500
它是开放式架构

664
01:08:36,500 --> 01:08:46,800
Hyperion 8 可以使用 360 度摄像头、雷达、激光雷达和超声传感器套件实现全自动驾驶

665
01:08:46,800 --> 01:08:54,500
Hyperion 8 将从 2024 年起搭载到梅赛德斯-奔驰汽车中，
然后在 2025 年搭载到捷豹路虎汽车中

666
01:08:54,500 --> 01:09:01,200
今天，我们宣布 Hyperion 9 将从 2026 年起搭载到汽车中

667
01:09:01,200 --> 01:09:08,600
Hyperion 9 将拥有 14 个摄像头、9 个雷达、3 个激光雷达和 20 个超声传感器

668
01:09:08,600 --> 01:09:15,600
总体而言，Hyperion 9 处理的传感器数据量将两倍于 Hyperion 8

669
01:09:15,600 --> 01:09:21,700
从而进一步增强安全性并扩大全自动驾驶的工作领域

670
01:09:21,700 --> 01:09:28,800
NVIDIA DRIVE Map 是一种多模态地图引擎，包括摄像头、雷达和激光雷达的数据

671
01:09:28,800 --> 01:09:35,200
您可以单独定位到地图的每一层，这将提供多样性和冗余性

672
01:09:35,200 --> 01:09:37,399
以实现最高级别的安全性

673
01:09:37,399 --> 01:09:45,299
Drive Map 有两个地图引擎：真值测绘地图和众包车队地图

674
01:09:45,300 --> 01:09:54,400
到 2024 年底，我们预计绘制并创建北美、西欧和亚洲所有主要公路的数字孪生

675
01:09:54,400 --> 01:09:59,000
– 总长度约为 50 万公里

676
01:09:59,000 --> 01:10:03,600
数百万辆乘用车将不断扩展和更新该地图

677
01:10:04,500 --> 01:10:11,300
我们正在构建地球级别的自动驾驶车队数字孪生，以探索新的算法和设计

678
01:10:11,300 --> 01:10:15,000
并在部署到车队之前测试软件

679
01:10:15,000 --> 01:10:21,100
我们正在开发两种场景仿真方法，每种都以不同方式重建整个世界

680
01:10:21,100 --> 01:10:26,200
其中一种方法从 NVIDIA Drive Map 开始，这种多模态地图引擎

681
01:10:26,200 --> 01:10:31,100
可为整个世界创建高度精确的 3D 表现形式

682
01:10:31,100 --> 01:10:34,100
地图加载到 Omniverse 中

683
01:10:38,100 --> 01:10:43,800
建筑、植被和其他路边目标均会生成

684
01:10:48,100 --> 01:10:54,300
系统对之前驾驶过程中遇到的运动目标、汽车和行人进行推理和定位

685
01:10:54,300 --> 01:10:57,700
然后放入数字孪生中

686
01:11:02,600 --> 01:11:09,200
我们可以将每个运动目标生成动画，或向其分配 AI 行为模型

687
01:11:12,600 --> 01:11:19,700
还可以应用域随机化来生成多样化且合理的挑战性场景

688
01:11:26,600 --> 01:11:34,100
第二种方法使用神经图形 AI 和 Omniverse，将预先录制的驾驶视频

689
01:11:34,100 --> 01:11:38,200
转换为可回放和可修改的驾驶过程

690
01:11:38,200 --> 01:11:41,800
我们首先重建 3D 场景

691
01:11:41,800 --> 01:11:46,700
系统会识别并移除运动的目标，背景被恢复

692
01:11:46,700 --> 01:11:51,900
重建场景后，我们可以改变现有车辆的行为

693
01:11:51,900 --> 01:11:57,000
或添加可完全控制、在交通环境下真实反应的车辆

694
01:11:57,000 --> 01:12:05,100
重新生成的驾驶过程，结合 3D 几何图形和基于物理效果的材质，让我们可以为场景重新打光

695
01:12:05,100 --> 01:12:09,100
应用物理效果和仿真激光雷达等传感器

696
01:12:09,100 --> 01:12:16,300
现在，可以重新运行预先录制的场景，并运用于闭环仿真和测试

697
01:12:17,000 --> 01:12:24,300
DRIVE Map 和 DRIVE Sim 包含 NVIDIA 研究工作取得的突破性 AI 成果，
展示了 Omniverse 数字孪生

698
01:12:24,300 --> 01:12:27,400
在推动自动驾驶汽车开发方面的力量

699
01:12:29,200 --> 01:12:38,200
NVIDIA DRIVE Map、DRIVE Sim、搭载 Orin 的 Hyperion 8 和 DRIVE AV 栈

700
01:12:38,200 --> 01:12:41,900
既可单独使用，也可作为一个整体使用

701
01:12:41,900 --> 01:12:46,200
电动汽车已促使业界对汽车架构进行彻底的重新设计

702
01:12:46,200 --> 01:12:54,500
未来的汽车将高度可编程，从内置许多嵌入式控制器发展为高度集中式的计算平台

703
01:12:54,500 --> 01:13:01,200
AI 和自动驾驶功能将在软件中提供，并在汽车生命周期内不断增强

704
01:13:01,200 --> 01:13:06,500
NVIDIA Orin 携手多家公司共同打造这样的未来，已经取得巨大成功

705
01:13:06,500 --> 01:13:14,600
Orin 是理想的集中式自动驾驶和 AI 计算平台，也是新一代电动汽车

706
01:13:14,600 --> 01:13:17,500
无人驾驶出租车、公共汽车和卡车的引擎

707
01:13:17,500 --> 01:13:20,800
Orin 本月开始发售

708
01:13:20,800 --> 01:13:28,600
今天，我们很高兴地宣布，全球第二大电动汽车制造商比亚迪

709
01:13:28,600 --> 01:13:36,100
将为 2023 年上半年开始投产的汽车搭载 DRIVE Orin 计算平台

710
01:13:36,100 --> 01:13:42,400
NVIDIA 自动驾驶车载计算机、软件和机器人 AI 基本上

711
01:13:42,400 --> 01:13:47,800
是与新一代医疗系统相同的计算管线

712
01:13:47,800 --> 01:13:54,300
请允许我为大家展示 Holoscan 可以为一台名为光片显微镜的惊人仪器做些什么

713
01:13:54,300 --> 01:14:01,600
光片显微镜由诺贝尔奖得主 Eric Betzig 发明，可利用高分辨率荧光

714
01:14:01,600 --> 01:14:09,200
创建细胞移动和分裂的影片，使得研究人员能够研究运动中的生物学

715
01:14:09,200 --> 01:14:22,100
问题在于光片显微镜每小时可产生 3TB 的数据，这相当于 30 部 4K 电影的数据量

716
01:14:22,100 --> 01:14:26,100
处理 3TB 的数据需要长达一天的时间

717
01:14:26,100 --> 01:14:32,000
借助 NVIDIA Clara Holoscan，我们可以对这些数据进行实时处理

718
01:14:34,100 --> 01:14:41,300
现在，借助 Clara Holoscan 和 NVIDIA Index，我们可以实时可视化大量活细胞

719
01:14:41,300 --> 01:14:45,000
这些数据是直接从显微镜记录下来的

720
01:14:45,000 --> 01:14:49,500
通过观察这些活的癌细胞的移动情况，我们可以同时看到正常、健康的生物特征

721
01:14:49,500 --> 01:14:52,400
及其恶化过程

722
01:14:52,400 --> 01:14:59,300
蓝色荧光标记的细胞核从一个细胞分裂为两个细胞

723
01:14:59,300 --> 01:15:06,500
癌症的一个标志是，与正常的健康细胞相比，细胞分裂更频繁，错误检查更少

724
01:15:06,500 --> 01:15:10,700
加州大学伯克利分校的晶格光片显微镜具有超高分辨率

725
01:15:10,700 --> 01:15:16,700
借此科学家能够发现隐藏在普通光学器件中的东西，这是 使用传统显微镜无法观察到的

726
01:15:16,700 --> 01:15:23,400
当我们放大时，观察到一个对于癌细胞系来说都非常罕见的情况 –

727
01:15:23,400 --> 01:15:26,200
发现一个细胞分裂成 3 个细胞

728
01:15:26,200 --> 01:15:32,500
这一现象仅在一些科学出版物中有过零星报道

729
01:15:32,500 --> 01:15:39,400
科学家尚不知道我们将看到什么，但现在借助实时处理和可视化技术

730
01:15:39,400 --> 01:15:44,600
科学界可以发现此类的未见过的事件

731
01:15:44,600 --> 01:15:47,400
我们来看看未来的发展情况

732
01:15:47,400 --> 01:15:52,800
Clara Holoscan 是一个开放、可扩展的机器人平台

733
01:15:52,800 --> 01:16:00,600
Clara Holoscan 的设计符合 IEC-62304 医疗级规格

734
01:16:00,600 --> 01:16:04,300
并达到极高的设备安全和保障级别

735
01:16:04,300 --> 01:16:13,100
Holoscan 的计算量惊人。其核心计算机为 Orin 和 ConnectX-7，并可选配 GPU

736
01:16:13,100 --> 01:16:19,700
Holoscan 开发平台目前向早期体验客户开放，正式上市时间为 5 月

737
01:16:19,700 --> 01:16:24,400
并在 2023 年第一季度完成医疗级准备

738
01:16:24,400 --> 01:16:30,300
未来的医疗设备将是 AI 仪器的天下，用于辅助诊断或手术

739
01:16:30,300 --> 01:16:40,000
正如 NVIDIA DRIVE 是机器人车辆平台一样，Clara Holoscan 也是一个机器人医疗仪器平台

740
01:16:40,000 --> 01:16:45,800
我们很高兴看到业界对 Holoscan 的热情，也很乐于与领先的医疗设备制造商

741
01:16:45,800 --> 01:16:48,300
和机器人手术公司合作

742
01:16:48,300 --> 01:16:52,900
对机器人和自动化的需求正呈指数级增长

743
01:16:52,900 --> 01:16:58,000
一些机器人会移动，而其他机器人则会观察移动的目标

744
01:16:58,000 --> 01:17:05,700
NVIDIA 与数千客户和开发者合作构建机器人，广泛用于制造、零售、医疗健康

745
01:17:05,700 --> 01:17:10,900
农业、建筑、机场和整个城市

746
01:17:10,900 --> 01:17:15,700
NVIDIA 的机器人平台由 Metropolis 和 Isaac 组成 –

747
01:17:15,700 --> 01:17:19,400
Isaac 是一个为移动机器打造的平台

748
01:17:19,400 --> 01:17:24,400
Metropolis 是一个跟踪移动目标的静止机器人

749
01:17:24,400 --> 01:17:34,300
Metropolis 和 Isaac 平台（如同 DRIVE）包含 4 大核心：真值生成、AI 模型训练

750
01:17:34,300 --> 01:17:40,900
Omniverse 数字孪生，以及配备了软件和计算机的机器人

751
01:17:40,900 --> 01:17:49,500
Metropolis 已经取得了非凡的成绩 – 下载量达 30 万次，拥有 1000 多个生态系统合作伙伴

752
01:17:49,500 --> 01:17:55,700
并在超过 100 万个设施中运营，其中包括 USPS、沃尔玛超市

753
01:17:55,700 --> 01:18:04,700
特拉维夫和伦敦等城市、希思罗机场、Veolia 回收工厂和吉列橄榄球场

754
01:18:04,700 --> 01:18:13,300
现在，客户可以使用 Omniverse 创建其架构的数字孪生，以提升安全性和效率

755
01:18:13,300 --> 01:18:18,100
我们来看看百事公司是如何使用 Metropolis 和 Omniverse 的

756
01:18:18,100 --> 01:18:21,600
百事的产品每天在全球有超过 10 亿次的消费

757
01:18:21,600 --> 01:18:27,600
将如此多的产品分销至 200 多个区域市场需要 600 多个配送中心

758
01:18:27,600 --> 01:18:33,400
提高供应链效率和环境可持续性是百事一直以来的重要目标

759
01:18:33,400 --> 01:18:37,700
为实现这一目标，他们采用 NVIDIA Omniverse 和 Metropolis 构建数字孪生

760
01:18:37,700 --> 01:18:40,400
模拟包装和配送中心

761
01:18:40,400 --> 01:18:45,000
这样他们能够在进行实物投资之前测试布局变化

762
01:18:45,000 --> 01:18:47,300
优化工作流程以加速吞吐量

763
01:18:47,300 --> 01:18:52,300
随着新产品和流程的推出，可以使用 Omniverse Replicator 和 NVIDIA TAO

764
01:18:52,300 --> 01:18:57,200
创建逼真的合成数据，然后重新训练实时 AI 模型

765
01:18:57,200 --> 01:19:01,500
这些新模型和优化被转移到现实世界

766
01:19:01,500 --> 01:19:06,500
通过 NVIDIA Metropolis 应用（使用 AI 计算机视觉）实时监控和优化传送带速度

767
01:19:06,500 --> 01:19:12,700
防止在长达数英里的传送带上发生堵塞和宕机

768
01:19:12,700 --> 01:19:17,000
此外，借助 NVIDIA Fleet Command，所有这些应用均可从一个集中式控制平面

769
01:19:17,000 --> 01:19:21,100
安全部署于数百个配送中心并进行管理

770
01:19:21,100 --> 01:19:27,000
通过利用 NVIDIA Omniverse、Metropolis 和 Fleet Command，
百事公司正在简化供应链运营

771
01:19:27,000 --> 01:19:31,500
减少能源消耗和浪费，并推动可持续发展的使命

772
01:19:34,800 --> 01:19:41,900
机器人发展最快的领域之一是自主移动机器人 (AMR)

773
01:19:41,900 --> 01:19:45,200
本质上是室内的无人驾驶车

774
01:19:45,200 --> 01:19:49,300
速度较低，但环境高度非结构化

775
01:19:49,300 --> 01:19:53,500
目前有数千万个工厂、商店和餐厅

776
01:19:53,500 --> 01:19:59,000
以及面积达数亿平方英尺的仓储和运营中心

777
01:19:59,000 --> 01:20:05,600
今天，我们将发布 Isaac 的一个重要版本，即 Isaac for AMR

778
01:20:05,600 --> 01:20:08,700
我将着重介绍一下该版本的一些关键点

779
01:20:08,700 --> 01:20:18,900
与 DRIVE 平台一样，Isaac for AMR 也有四大核心，每个都单独可用，并且完全开放

780
01:20:18,900 --> 01:20:28,800
用于真值生成的新 NVIDIA DeepMap、用于训练模型的 NVIDIA AI、搭载 Orin 的 AMR 机器人参考设计

781
01:20:28,800 --> 01:20:35,900
Isaac 机器人技术堆栈中的新 Gem，以及基于 Omniverse 的新版 Isaac Sim.

782
01:20:35,900 --> 01:20:46,700
首先，与 DRIVE Hyperion 一样，Isaac Nova 是一个 AMR 机器人系统参考设计，
整个 Isaac 堆栈都基于此构建

783
01:20:46,700 --> 01:20:54,700
Nova 拥有 2 个摄像头、2 个激光雷达、8 个超声波雷达和 4 个鱼眼摄像头用于远程操作

784
01:20:54,700 --> 01:21:01,500
今天，我们宣布推出 Jetson Orin 开发者套件

785
01:21:01,500 --> 01:21:04,700
Nova AMR 将于第二季度上市

786
01:21:04,700 --> 01:21:12,000
Nova AMR 配备 NVIDIA 新的 DeepMap LIDAR 制图系统，您可以扫描

787
01:21:12,000 --> 01:21:17,700
和重建环境，以进行路线规划和数字孪生仿真

788
01:21:17,700 --> 01:21:27,000
Isaac 机器人 SDK 包括感知、定位、建图、规划和导航模块

789
01:21:27,000 --> 01:21:32,600
今天，我们宣布用于构建 AMR 的重要更新

790
01:21:32,600 --> 01:21:36,500
Isaac Gems 包括目标和人员检测

791
01:21:36,500 --> 01:21:42,100
3D 位姿估计、LIDAR 和视觉 SLAM 定位和建图

792
01:21:42,100 --> 01:21:49,100
3D 环境重建、自由空间感知、使用强化学习的小车对接

793
01:21:49,100 --> 01:21:55,500
导航堆栈、与 NVIDIA cuOpt 集成以进行实时规划

794
01:21:55,500 --> 01:22:00,200
以及机械臂运动规划和机器人运动学等重要功能

795
01:22:00,200 --> 01:22:03,000
还有一个用于远程操作的 SDK

796
01:22:03,000 --> 01:22:08,700
最后，Omniverse 可支持构建 Isaac Replicator（用于生成合成数据）

797
01:22:08,700 --> 01:22:14,400
Isaac Gym（用于训练机器人），以及 Isaac Sim（用于数字孪生）

798
01:22:14,400 --> 01:22:18,600
Isaac 开发流程全程集成了 Omniverse

799
01:22:18,600 --> 01:22:23,800
Isaac Gym 强调了 Omniverse 的物理仿真精度的重要性

800
01:22:23,800 --> 01:22:31,100
在 Isaac Gym 中，一个新机器人通过使用深度强化学习执行数千到数百万次学习

801
01:22:31,100 --> 01:22:33,600
来掌握一项新技能

802
01:22:33,600 --> 01:22:42,700
然后，经过训练的 AI 大脑被下载到物理机器人中。由于 Omniverse在物理上是精确的，因此机器人

803
01:22:42,700 --> 01:22:48,500
在获得其方位后，将掌握其在数字孪生中的技能

804
01:22:48,500 --> 01:22:49,800
一起来看一下

805
01:22:50,300 --> 01:22:55,400
成功开发、训练和测试适用于现实世界应用的复杂机器人

806
01:22:55,400 --> 01:22:59,100
需要高保真仿真和准确的物理效果

807
01:22:59,100 --> 01:23:06,000
Isaac Sim 基于 NVIDIA 的 Omniverse 平台构建，将沉浸式虚拟现实的、物理属性准确的、逼真的环境

808
01:23:06,000 --> 01:23:08,700
与复杂的虚拟机器人相结合

809
01:23:08,700 --> 01:23:15,000
我们来看看合作伙伴使用 Isaac Sim 开发的三种截然不同的 AI 机器人

810
01:23:15,000 --> 01:23:22,800
Fraunhofer IML 是物流领域的技术领导者，使用 NVIDIA Isaac Sim 来虚拟开发 Obelix

811
01:23:22,800 --> 01:23:27,900
这是一种高度动态的室内/室外自主移动机器人 (AMR)

812
01:23:27,900 --> 01:23:32,900
从 CAD 导入逾 5400 个零件并借助 Omniverse PhysX 进行装配后

813
01:23:32,900 --> 01:23:38,100
虚拟机器人在仿真环境中的移动与在现实世界中一样灵巧

814
01:23:38,100 --> 01:23:44,000
这不仅可加快虚拟开发速度，还能够扩展至更大的场景

815
01:23:44,000 --> 01:23:50,000
接下来要介绍的是以工业自动化闻名的 Festo。该公司使用 Isaac Sim

816
01:23:50,000 --> 01:23:57,300
为协作机器人（简称 cobot）开发智能技能，需要对其人类伙伴和任务有敏锐的认识

817
01:23:57,300 --> 01:24:03,900
使用 Cortex（一款 Isaac Sim 工具），Festo 可显著简化 cobot 技能的编程

818
01:24:03,900 --> 01:24:11,500
为实现感知，此任务中使用的 AI 模型仅使用由 Isaac Replicator 生成的合成数据进行训练

819
01:24:11,500 --> 01:24:19,200
最后，要为您介绍机器狗 Anymal，
由苏黎世联邦理工学院（ETH Zurich）和 Swiss-Mile 的一个领先的机器人研究小组开发

820
01:24:19,200 --> 01:24:25,100
借助 GPU 加速的端到端强化学习，Anymal 的脚被轮子取代

821
01:24:25,100 --> 01:24:31,100
然后使用 NVIDIA 的 Isaac Gym 训练工具，
只需几分钟就可学会在城市地形上“行走”，而无需花费几周时间

822
01:24:31,100 --> 01:24:36,500
运动策略在 Isaac Sim 中进行验证后，才会部署在真实的 Anymal 上

823
01:24:36,500 --> 01:24:41,300
这是一个针对真实部署进行的引人入胜的模拟器训练演示

824
01:24:41,300 --> 01:24:47,800
从训练感知和策略到硬件在环，Isaac Sim 工具可构建 AI 机器人

825
01:24:47,800 --> 01:24:53,000
这些机器人在仿真中诞生，在现实世界中工作（娱乐）

826
01:24:54,100 --> 01:25:03,700
现代仓储运营中心正在演变为技术奇迹，设备由人类和机器人协同操作

827
01:25:03,700 --> 01:25:13,000
仓库也是一个机器人，负责协调内部物料的运输和 AMR 的路径优化

828
01:25:13,000 --> 01:25:16,600
我们来看看 Amazon 如何使用 Omniverse 数字孪生技术

829
01:25:16,600 --> 01:25:21,500
来设计和优化令人惊叹的仓储运营中心

830
01:25:22,400 --> 01:25:26,900
每一天，亚马逊的数百个运营中心需处理数千万个包裹

831
01:25:26,900 --> 01:25:30,800
而其中超过三分之二的客户订单由机器人处理

832
01:25:30,800 --> 01:25:36,200
为了支持这种高度复杂的操作，我们部署了数十万个自主移动机器人

833
01:25:36,200 --> 01:25:38,100
和相关的存储舱

834
01:25:38,100 --> 01:25:42,300
这使我们能够在仓库中存储远高于传统货架的库存

835
01:25:42,300 --> 01:25:46,500
这帮助我们以更安全、更高效的方式移动库存

836
01:25:46,500 --> 01:25:49,800
扩展的关键在于我们模拟这些建筑的能力

837
01:25:49,800 --> 01:25:53,100
以及在构建之前了解它们的性能

838
01:25:53,100 --> 01:25:59,900
我们来看看 NVIDIA Omniverse 如何助力优化和简化这些复杂的流程

839
01:25:59,900 --> 01:26:06,900
在 Amazon Robotics，我们可以在 NVIDIA Omniverse 中创建相同比例的仓库“数字孪生”

840
01:26:06,900 --> 01:26:14,000
帮助我们优化仓库设计、训练更智能的机器人助手，并提升运营效率

841
01:26:14,000 --> 01:26:19,400
在 Omniverse 中，我们能够以特有的方式整合来自不同 CAD 应用的数据集

842
01:26:19,400 --> 01:26:23,100
并在 Omniverse 的 RTX 加速光线追踪、材质和物理效果的推动下

843
01:26:23,100 --> 01:26:29,700
高度真实地呈现这些大型模型

844
01:26:29,700 --> 01:26:33,300
数字孪生是未来仓库和工厂不可或缺的组成部分

845
01:26:33,300 --> 01:26:37,100
可实现持续集成和交付

846
01:26:37,100 --> 01:26:39,500
对于软件和仓库布局的每一次新优化

847
01:26:39,500 --> 01:26:43,400
我们都可以先在数字孪生中进行测试，然后再发布至物理仓库

848
01:26:43,400 --> 01:26:48,700
这样既可防止系统停机或故障，也可最大限度地提高运营效率

849
01:26:48,700 --> 01:26:56,200
然后，各种形状、尺寸、重量和材质的包裹都可以在我们的仓储中心迅速移动

850
01:26:56,200 --> 01:27:02,100
我们使用 NVIDIA Omniverse 更好地训练自主机器人分类和拣选解决方案

851
01:27:02,100 --> 01:27:07,300
训练这些机器人的感知系统以使其具有足够的准确性以避免系统故障

852
01:27:07,300 --> 01:27:14,700
需要大量高质量的数据，但通常可能没有数据或者数据量不够

853
01:27:14,700 --> 01:27:20,500
当我们的包装材料中包含很多反光胶带时，感知系统会失误

854
01:27:20,500 --> 01:27:26,200
我们使用在 Omniverse 中生成的物理属性准确、逼真的合成数据以重新训练模型

855
01:27:26,200 --> 01:27:33,500
这些数据与真实数据别无二致，从而可以节省数周的重新训练时间，并提高模型准确性

856
01:27:33,500 --> 01:27:40,400
最后，借助我们运营中心的数字孪生，以及快速、准确训练机器人感知系统的能力

857
01:27:40,400 --> 01:27:48,000
我们还可以更好地配置人机工作站，更好地模拟人体工程学

858
01:27:48,000 --> 01:27:54,700
亚马逊正借助 NVIDIA Omniverse 数字孪生端到端地重塑仓库物流

859
01:27:54,700 --> 01:28:02,100
并大幅提升运营效率，从而为客户提供更多价值

860
01:28:04,700 --> 01:28:11,700
与 NASA 和 Amazon 一样，我们在机器人和工业自动化领域的客户

861
01:28:11,700 --> 01:28:18,400
也意识到了数字孪生的重要性，并且正通过 Omniverse 完成令人惊叹的任务

862
01:28:18,400 --> 01:28:24,000
您可以看到 Omniverse 在 NVIDIA 整个 AI 和机器人领域工作中的重要性

863
01:28:24,000 --> 01:28:30,500
下一波 AI 浪潮（机器人系统）需要 Omniverse 这样的平台

864
01:28:30,500 --> 01:28:41,200
我们希望 Omniverse 能够为数千万设计师、创作者、机器人专家和 AI 研究人员提供帮助

865
01:28:41,200 --> 01:28:46,400
今天，我们将宣布推出 Omniverse Cloud

866
01:28:46,400 --> 01:28:51,500
只需点击几下，您和您的协作者就可以完成连接

867
01:28:51,500 --> 01:28:59,500
在这个演示中，您将看到 4 位设计师，他们都在远程工作，通过 Omniverse Cloud 连接

868
01:28:59,500 --> 01:29:02,600
并协作创建一个虚拟世界

869
01:29:02,600 --> 01:29:05,500
我们来看看这有多么简单

870
01:29:06,700 --> 01:29:13,500
3D 设计是一项复杂的团队工作，涉及不同的艺术家、应用和硬件，且工作地点通常各不相同

871
01:29:13,500 --> 01:29:16,900
借助 Omniverse Cloud，这将变得更加简单

872
01:29:16,900 --> 01:29:23,100
使用 NVIDIA RTX PC、笔记本电脑和工作站，设计师可实时协同工作

873
01:29:23,100 --> 01:29:29,800
如果您没有 RTX 计算机，只需点击一下即可从 GeForce Now 上启动 Omniverse

874
01:29:29,800 --> 01:29:35,300
让我们看看一个建筑设计团队在网络会议中使用 Omniverse View 来评审项目

875
01:29:36,100 --> 01:29:38,700
好的，这里是 5 楼的露台

876
01:29:39,200 --> 01:29:43,400
为了更好地感受光照，我们来看看中午时候这个地方的样子

877
01:29:43,900 --> 01:29:45,400
好的！

878
01:29:48,400 --> 01:29:53,400
嗯，有一点阳光了。我们来对棚架进行一些调整

879
01:29:53,400 --> 01:29:54,700
稍等

880
01:29:55,700 --> 01:29:56,800
现在如何？

881
01:29:56,800 --> 01:29:59,700
好多了，我们来看看能否连线 Teresa

882
01:29:59,700 --> 01:30:03,100
好的，正在发送链接

883
01:30:04,800 --> 01:30:05,800
嗨，两位好！

884
01:30:05,800 --> 01:30:12,100
你好！我们做了中午的光线模拟，决定增加一些阴影。你有什么想法？

885
01:30:12,100 --> 01:30:16,000
看起来很棒，但我觉得还额外需要一点什么

886
01:30:16,000 --> 01:30:18,200
如果添加一些树，会怎么样？

887
01:30:18,200 --> 01:30:20,700
好，请 TJ 帮我们完成吧

888
01:30:21,100 --> 01:30:23,000
大家好，需要我做点什么？

889
01:30:23,000 --> 01:30:28,000
嗨，TJ，你能在桌子附近的花盆里加些中等大小的树吗？

890
01:30:28,400 --> 01:30:30,800
没问题，我来添加一下

891
01:30:31,400 --> 01:30:32,800
这样看起来如何？

892
01:30:32,800 --> 01:30:38,500
很赞！但我们可以让树木呈现更多差异吗？比如大小和种类？

893
01:30:38,500 --> 01:30:40,000
好，就是这样

894
01:30:40,700 --> 01:30:43,900
嗨，TJ，我们到吧台来看看晚上的效果

895
01:30:43,900 --> 01:30:45,600
就是这样

896
01:30:47,100 --> 01:30:48,400
哇，看起来很棒哦！

897
01:30:48,400 --> 01:30:51,500
我将发送链接以供审批

898
01:30:56,200 --> 01:30:58,300
相聚 Omniverse，不见不散！

899
01:30:59,633 --> 01:31:04,033
您可能已经注意到，其中一个设计师是 AI

900
01:31:04,033 --> 01:31:10,633
随着 AI 技能的不断发展，我们不仅能利用它们来帮助我们设计建筑和工厂

901
01:31:10,633 --> 01:31:17,333
同时还可用于餐厅订单服务，帮助客户，甚至回答有关我们健康的问题

902
01:31:17,333 --> 01:31:21,033
Omniverse，为下一波的 AI 浪潮而生

903
01:31:21,033 --> 01:31:25,700
我们已经介绍了很多内容，让我快速回顾一下

904
01:31:25,700 --> 01:31:29,700
我们宣布推出 NVIDIA 四层技术栈中的新产品：

905
01:31:29,700 --> 01:31:34,833
硬件，系统软件和库，软件平台

906
01:31:34,833 --> 01:31:43,900
（NVIDIA HPC、NVIDIA AI 和 NVIDIA Omniverse），以及 AI 和机器人应用框架

907
01:31:43,900 --> 01:31:52,300
这些产品正引领着五个态势去塑造我们的行业 - Million-X 百万倍的计算加速、Transformer 增强 AI

908
01:31:52,300 --> 01:31:58,833
让数据中心成为 AI 工厂、对机器人系统的需求呈指数增长

909
01:31:58,833 --> 01:32:02,833
以及下一个 AI 时代的数字孪生

910
01:32:02,833 --> 01:32:06,333
四层技术栈，五大态势

911
01:32:06,333 --> 01:32:13,900
NVIDIA 加速计算、数据中心级全栈工程优化，使计算速度提高了百万倍

912
01:32:13,900 --> 01:32:20,900
Million-X 百万倍加速为应对药物研发和气候科学等重大挑战提供了契机

913
01:32:20,900 --> 01:32:26,933
随着自主学习 Transformer 的发明，AI 的发展速度跃上新高

914
01:32:26,933 --> 01:32:33,033
AI 已从根本上改变了软件的能力以及开发软件的方式

915
01:32:33,033 --> 01:32:42,400
公司通过处理和提炼数据来打造 AI、构建智能，其数据中心就是 AI 工厂

916
01:32:42,400 --> 01:32:47,633
NVIDIA H100 是全球 AI 基础架构的新引擎

917
01:32:47,633 --> 01:32:57,700
NVIDIA 的 NVLink Switch 系统可将最多 32 个 DGX 连接成一个高达 1 ExaFLOPS 算力的模块，
作为 AI 工厂的基础单元

918
01:32:57,700 --> 01:33:06,733
Hopper H100 是有史以来最大的代际性能提升，其大规模训练性能是 A100 的 9 倍

919
01:33:06,733 --> 01:33:11,200
大型语言模型推理的吞吐量是 A100 的 30 倍

920
01:33:11,200 --> 01:33:14,833
Hopper 还可以加速主流服务器

921
01:33:14,833 --> 01:33:20,933
NVIDIA H100 CNX 通过最先进的网络芯片 – NVIDIA ConnectX-7

922
01:33:20,933 --> 01:33:25,233
将网络直接连接到 H100

923
01:33:25,233 --> 01:33:31,433
NVIDIA H100 是全球 AI 基础架构的引擎

924
01:33:31,433 --> 01:33:36,533
H100 已经投产，将从第三季度开始供货

925
01:33:36,533 --> 01:33:39,400
Grace 有望在明年投入生产

926
01:33:39,400 --> 01:33:46,233
Grace 是一款令人惊艳的超级芯片：2 个 CPU 通过 900 GB/s 的 NVLink 芯片到芯片的互连

927
01:33:46,233 --> 01:33:58,733
从而构成一个内存带宽为 1 TB/s 的 144 核 CPU

928
01:33:58,733 --> 01:34:03,933
Grace，全球 AI 基础架构的理想 CPU

929
01:34:03,933 --> 01:34:10,733
NVLink 现在应用于裸片之间、芯片之间和系统之间的互联

930
01:34:10,733 --> 01:34:15,033
并为我们提供了多种 Grace-Hopper 系统配置

931
01:34:15,033 --> 01:34:21,400
从 2 个 Grace、1 个 Grace 加 1 个 Hopper、到 2 个 Grace 加 8 个 Hopper

932
01:34:21,400 --> 01:34:29,333
未来的所有 NVIDIA 芯片都将支持 NVLink，包括 CPU、GPU、DPU 和 SOC

933
01:34:29,333 --> 01:34:35,433
我们还将为客户和合作伙伴提供 NVLink，以构建配套芯片

934
01:34:35,433 --> 01:34:42,500
NVLink 为客户打开了新世界的大门，让他们可以利用 NVIDIA 平台和生态系统

935
01:34:42,500 --> 01:34:46,500
构建半定制芯片和系统

936
01:34:46,500 --> 01:34:53,433
全球超过 25000 家公司使用的 NVIDIA AI 平台将进行重大更新

937
01:34:53,433 --> 01:35:02,733
NVIDIA Omniverse 平台适合虚拟世界、数字孪生和机器人系统，将掀起下一波 AI 浪潮

938
01:35:02,733 --> 01:35:08,100
正如 TensorFlow 和 PyTorch 是面向感知的 AI 的基本框架一样

939
01:35:08,100 --> 01:35:12,333
Omniverse 也将成为面向动作的 AI 的不可或缺的一部分

940
01:35:12,333 --> 01:35:20,533
DGX 是 AI 工厂的基础架构，OVX 将成为数字孪生的基础架构

941
01:35:20,533 --> 01:35:27,833
OVX 运行 Omniverse 数字孪生，用于大规模仿真

942
01:35:27,833 --> 01:35:30,000
多个自主系统在同一个时空运行

943
01:35:30,000 --> 01:35:34,333
OVX 的基础是网络结构

944
01:35:34,333 --> 01:35:40,600
我们宣布推出了 NVIDIA Spectrum-4 51.2 Tb/s 的交换机

945
01:35:40,600 --> 01:35:49,133
凭借 ConnectX-7 和 BlueField-3 ，它将成为首款 400 Gbps 的端到端网络平台

946
01:35:49,133 --> 01:35:52,033
Spectrum-4 的样品将于第三季度问世

947
01:35:52,033 --> 01:35:57,500
能够感知、规划并采取行动的机器人系统将引领下一波 AI 浪潮

948
01:35:57,500 --> 01:36:07,433
NVIDIA Avatar、Drive、Metropolis、Isaac 和 Holoscan 是基于四大支柱构建的端到端全栈机器人平台

949
01:36:07,433 --> 01:36:16,900
四大支柱即真值数据生成、AI 模型训练、机器人技术栈和 Omniverse 数字孪生

950
01:36:16,900 --> 01:36:21,200
开发者可以部分采用这些平台，也可以整体采用

951
01:36:21,200 --> 01:36:24,433
Omniverse 是我们机器人平台的中心

952
01:36:24,433 --> 01:36:30,300
与 NASA 和 Amazon 一样，我们在机器人和工业自动化领域的客户

953
01:36:30,300 --> 01:36:33,633
也意识到了数字孪生和 Omniverse 的重要性

954
01:36:33,633 --> 01:36:36,133
Drive Orin 已全面投产

955
01:36:36,133 --> 01:36:38,933
Issac Orin 开发者套件现已上市

956
01:36:38,933 --> 01:36:42,433
Clara Holoscan 开发者套件将于 5 月上市

957
01:36:42,433 --> 01:36:45,600
我们在本届 GTC 上更新了 60 个 SDK

958
01:36:45,600 --> 01:36:48,933
对于我们的 300 万开发者、科学家和 AI 研究人员

959
01:36:48,933 --> 01:36:51,900
以及数万家初创公司和成熟企业而言

960
01:36:51,900 --> 01:36:56,633
这表示着其一直以来运行的 NVIDIA 系统的速度会越来越快

961
01:36:56,633 --> 01:37:05,333
NVIDIA SDK 服务于医疗健康、能源、交通、零售、金融、媒体和娱乐等

962
01:37:05,333 --> 01:37:09,233
总价值达 100 万亿美元的行业

963
01:37:09,233 --> 01:37:13,633
通过在全栈和数据中心级实现加速

964
01:37:13,633 --> 01:37:17,733
我们将力争在未来十年内再实现百万倍的提速

965
01:37:17,733 --> 01:37:21,233
我迫不及待地想知道下一个 Million-X 百万倍会带来怎样的变化

966
01:37:21,233 --> 01:37:28,200
我要感谢 NVIDIA 开发者、合作伙伴、客户和 NVIDIA 的家人们

967
01:37:28,200 --> 01:37:32,100
感谢你们为塑造世界所做的出色工作

968
01:37:32,100 --> 01:37:39,700
不过，请暂时不要离开。Omniverse 生成了您今天看到的每一个渲染和仿真

969
01:37:39,700 --> 01:37:47,033
NVIDIA 卓越的创意团队希望带您再一次体验 Omniverse

970
01:37:47,033 --> 01:37:49,000
敬请感受

